{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1704d4-a65d-4f34-985c-9bfb121c3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime as dt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "# Load models together\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from src.torch_utils import load_model_full\n",
    "from src.utils import get_class_initcode_keys\n",
    "from torch.utils.data import SequentialSampler\n",
    "from src.datasets import *\n",
    "from src.models import *\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, add_median_labels, get_palette\n",
    "from src.sim_utils import make_dist_matrix\n",
    "from src.torch_utils import save_checkpoint, load_checkpoint\n",
    "from src.train_eval import predict_model, train_eval_loops\n",
    "from src.models import FullTCRVAE, TwoStageVAECLF\n",
    "from src.conv_models import CNNVAE, TwoStageCNNVAECLF\n",
    "from src.metrics import reconstruction_accuracy, compute_cosine_distance\n",
    "from src.cluster_utils import *\n",
    "from src.networkx_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663ec6b-ec01-473d-bd41-f9a28e5a4f29",
   "metadata": {},
   "source": [
    "# Check the \"best\" model for NOTRIPLET VAEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b5618-6122-43f3-86be-121de5c6392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pipeline_here(runs, title=None, fn=None, palette='tab10', add_clustersize=False, \n",
    "                       figsize=(9,9), legend=True, outdir = None):\n",
    "    # plotting options\n",
    "    sns.set_palette(palette, n_colors=len(runs.input_type.unique()))\n",
    "    f, a = plt.subplots(1, 1, figsize=figsize)\n",
    "    a.set_xlim([0, 1])\n",
    "    a.set_ylim([0, 1])\n",
    "    a.set_xlabel('Retention', fontweight='semibold', fontsize=14)\n",
    "    a.set_ylabel('Mean Purity', fontweight='semibold', fontsize=14)\n",
    "    # Setting major ticks\n",
    "    major_ticks = np.arange(0, 1.1, 0.1)\n",
    "    a.set_xticks(major_ticks)\n",
    "    a.set_yticks(major_ticks)\n",
    "    # Setting minor ticks\n",
    "    minor_ticks = np.arange(0, 1.1, 0.05)\n",
    "    a.set_xticks(minor_ticks, minor=True)\n",
    "    a.set_yticks(minor_ticks, minor=True)\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    if add_clustersize:\n",
    "        ax2 = a.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_yscale('log', base=2)\n",
    "        ax2.set_ylabel('Mean Cluster Size (Log2)', fontweight='semibold', fontsize=14)\n",
    "    for input_type in runs.input_type.unique():\n",
    "        query = runs.query('input_type==@input_type')\n",
    "        retentions = query['retention'][1:-1].values\n",
    "        purities = query['mean_purity'][1:-1].values\n",
    "        if add_clustersize:\n",
    "            cluster_sizes = query['mean_cluster_size'].values[1:-1]\n",
    "            \n",
    "        if input_type == \"TBCRalign\":\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls=':', c='g', lw=1)\n",
    "            if add_clustersize:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='x', lw=0.25, s=6, c='g')\n",
    "\n",
    "        elif input_type == \"tcrdist3\":\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls=':', c='m', lw=1)\n",
    "            if add_clustersize:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='.', lw=0.25, s=6, c='m')\n",
    "\n",
    "        else:\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls='--', lw=1.1)\n",
    "            if add_clustersize:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='*', lw=0.25, s=6)\n",
    "\n",
    "\n",
    "    a.axhline(0.6, label='60% purity cut-off', ls=':', lw=.75, c='m')\n",
    "    a.axhline(0.7, label='70% purity cut-off', ls=':', lw=.75, c='c')\n",
    "    a.axhline(0.8, label='80% purity cut-off', ls=':', lw=.75, c='y')\n",
    "    if legend:\n",
    "        a.legend(title='distance matrix', title_fontproperties={'size': 14, 'weight': 'semibold'},\n",
    "             prop={'weight': 'semibold', 'size': 12}, loc='lower left')\n",
    "    f.suptitle(f'{title}', fontweight='semibold', fontsize=15)\n",
    "    f.tight_layout()\n",
    "    if fn is not None:\n",
    "        if outdir is not None:\n",
    "            mkdirs(outdir)\n",
    "            fn = f'{outdir}{fn}'\n",
    "        f.savefig(f'{fn}.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b3c19-b74e-43e2-8af3-a957b534e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(main_folder):\n",
    "    train = pd.read_csv(glob.glob(f'{main_folder}*train*.csv')[0])\n",
    "    valid = pd.read_csv(glob.glob(f'{main_folder}*valid*.csv')[0])\n",
    "    test = pd.read_csv(glob.glob(f'{main_folder}*test*.csv')[0])\n",
    "    return train, valid, test\n",
    "    \n",
    "def results_pipeline(main_folder, title=None, fn=None, palette='tab10', add_clustersize=False, figsize=(9, 9), legend=True, outdir=None):\n",
    "    \"\"\"\n",
    "    Takes the train,test,valid curves ; Gets the best in terms of valid RP p70_r35_AUC (top 3)\n",
    "    And plot those curves for all 3 plots and compare\n",
    "    \"\"\"\n",
    "    train, valid, test = read_results(main_folder)\n",
    "    top3_valid = get_all_inputs_rpauc(valid.query('not input_type.str.contains(\"agg\") and not input_type.str.contains(\"tcrdist\") and not input_type.str.contains(\"TBCR\")')).head(3)\n",
    "    rankings = {k:f' (Top {i+1})' for i, k in enumerate(top3_valid.index)}\n",
    "    train_plot = train.query('input_type in @top3_valid.index or input_type in [\"TBCRalign\", \"tcrdist3\"]')\n",
    "    train_plot['name'] = train_plot['input_type'].map(rankings).replace(np.nan, '')\n",
    "    train_plot['input_type'] = train_plot.apply(lambda x: x['input_type'] + x['name'], axis=1)\n",
    "    valid_plot = valid.query('input_type in @top3_valid.index or input_type in [\"TBCRalign\", \"tcrdist3\"]')\n",
    "    valid_plot['name'] = valid_plot['input_type'].map(rankings).replace(np.nan, '')\n",
    "    valid_plot['input_type'] = valid_plot.apply(lambda x: x['input_type'] + x['name'], axis=1)\n",
    "    test_plot = test.query('input_type in @top3_valid.index or input_type in [\"TBCRalign\", \"tcrdist3\"]')\n",
    "    test_plot['name'] = test_plot['input_type'].map(rankings).replace(np.nan, '')\n",
    "    test_plot['input_type'] = test_plot.apply(lambda x: x['input_type'] + x['name'], axis=1)\n",
    "    plot_pipeline_here(train_plot.query('not (retention>0.98 and mean_purity>0.3)'),\n",
    "                       f'{title}\\nTrain set ; Selected best validation epochs', f'{fn}_top3ValEpochs_train_plot', palette, add_clustersize, figsize, legend, outdir)\n",
    "    \n",
    "    plot_pipeline_here(valid_plot.query('not (retention>0.98 and mean_purity>0.3)'),\n",
    "                       f'{title}\\nValid set ; Selected best validation epochs', f'{fn}_top3ValEpochs_valid_plot', palette, add_clustersize, figsize, legend, outdir)\n",
    "    \n",
    "    plot_pipeline_here(test_plot.query('not (retention>0.98 and mean_purity>0.3)'),\n",
    "                       f'{title}\\ntest set ; Selected best validation epochs', f'{fn}_top3ValEpochs_test_plot', palette, add_clustersize, figsize, legend, outdir)\n",
    "    \n",
    "    return train_plot, valid_plot, test_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec25a9-ade0-4502-9adb-ec6370852e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['CNNVAE 128 NO TRP ; Binders filtered - Top 17 peps',\n",
    "         'CNNVAE 128 NO TRP ; TCRBase filtered - Top 78 peps',\n",
    "         'TwoStage CNNVAE 128 NO TRP ; Binders filtered - Top 17 peps',\n",
    "         'TwoStage CNNVAE 128 NO TRP ; TCRBase filtered - Top 78 peps']\n",
    "filenames = ['CNNVAE_128_Top17peps_NoTrp', \n",
    "             'CNNVAE_128_Top78peps_NoTrp', \n",
    "             'TwoStage_128_Top17peps_NoTrp', \n",
    "             'TwoStage_128_Top78peps_NoTrp']\n",
    "files = sorted(glob.glob('../output/240618_NestedKCV_CNNVAE/clustering/*NOTRIPLET*/'))\n",
    "\n",
    "for name, filename, main_folder in zip(names, filenames, files):\n",
    "    results_pipeline(main_folder, title=name, fn=filename, outdir='../output/240618_NestedKCV_CNNVAE/figs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978e79c-3a3d-4f8a-bda0-7441c7016a76",
   "metadata": {},
   "source": [
    "# TCRbase detour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55a278-d538-418d-997a-1e4752e46052",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_swap = pd.read_csv('../data/filtered/240326_nettcr_exp_paired_withswaps.csv')\n",
    "old_swap = pd.read_csv('../data/filtered/231205_nettcr_old_26pep_with_swaps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765050e-b0ff-48af-b93f-4a914c53181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from src.metrics import get_metrics\n",
    "def read_tcrbase_results(peptide, original_df, partition=0, dir='../output/TCRBASE/tcrbase_expanded_ALL_swapped/'):\n",
    "    cols = ['xx', 'xy', 'id_query'] + [f'q_{x}' for x in ['A1','A2','A3','B1','B2','B3']] + ['bs1', 'hit', 'id_db'] + [f'db_{x}' for x in ['A1','A2','A3','B1','B2','B3']] + ['score', 'bs2']\n",
    "    df = pd.read_csv(f'{dir}{peptide}_p{partition}.txt', comment='#', sep='\\s', header=None, names=cols)\n",
    "    df['q_seq'] = df['q_A1']+df['q_A2']+df['q_A3']+df['q_B1']+df['q_B2']+df['q_B3']\n",
    "    original_df = original_df.query('peptide==@peptide and partition==@partition')\n",
    "    original_df['q_seq'] = original_df['A1']+original_df['A2']+original_df['A3']+original_df['B1']+original_df['B2']+original_df['B3']\n",
    "    results = pd.merge(df.set_index('q_seq')[['score', 'id_db']+[f'db_{x}' for x in ['A1','A2','A3','B1','B2','B3']]],\n",
    "                       original_df.set_index('q_seq')[['partition','binder', 'peptide', 'A1','A2','A3','B1','B2','B3']],\n",
    "                       left_index=True, right_index=True)\n",
    "    print(peptide, round(roc_auc_score(results['binder'], results['score']),4))\n",
    "    tcrbase_metrics = {'peptide':peptide, \n",
    "                       'method':'tcrbase',\n",
    "                       'n_pos':len(original_df.query('original_peptide==@peptide and partition==@partition'))}\n",
    "    tcrbase_metrics.update(get_metrics(results['binder'], results['score'], round_digit=5))\n",
    "    print(tcrbase_metrics)\n",
    "    return tcrbase_metrics, results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d932b8-9d47-45dd-a585-f0da86e0909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_exp=[]\n",
    "total_old=[]\n",
    "for partition in range(5):\n",
    "    exp_results = []\n",
    "    for p in exp_swap.peptide.unique():\n",
    "        x, _ = read_tcrbase_results(p, exp_swap, partition=partition, dir='../output/TCRBASE/tcrbase_expanded_ALL_swapped/')\n",
    "        exp_results.append(x)    \n",
    "    exp_results = pd.DataFrame(exp_results)\n",
    "    \n",
    "    old_results = []\n",
    "    for p in old_swap.peptide.unique():\n",
    "        x, _ = read_tcrbase_results(p, old_swap, partition=partition, dir='../output/TCRBASE/tcrbase_old_ALL_swapped/')\n",
    "        old_results.append(x)    \n",
    "    old_results = pd.DataFrame(old_results)\n",
    "    total_exp.append(exp_results.assign(partition=partition))\n",
    "    total_old.append(old_results.assign(partition=partition))\n",
    "    exp_results.sort_values('n_pos', ascending=False).to_csv(f'../output/TCRBASE/results_exp_partition_p{partition}.csv', index=False)\n",
    "    old_results.sort_values('n_pos', ascending=False).to_csv(f'../output/TCRBASE/results_old_partition_p{partition}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ceb789-f9a0-4e80-a0a4-8f42ea85beed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat(total_exp).drop(columns=['method']).groupby('peptide').mean().sort_values('n_pos',ascending=False).to_csv(f'../output/TCRBASE/total_mean_exp_results.csv', index=True)\n",
    "pd.concat(total_old).drop(columns=['method']).groupby('peptide').mean().sort_values('n_pos',ascending=False).to_csv(f'../output/TCRBASE/total_mean_old_results.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3b398-3792-4145-bbf5-3bb87a01929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_exp = pd.concat(total_exp).drop(columns=['method']).groupby('peptide').mean()\n",
    "total_old = pd.concat(total_old).drop(columns=['method']).groupby('peptide').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d295549-650e-4eaa-bc97-f63862f9f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_filt = total_exp.query('n_pos>=75').sort_values('auc',ascending=False).head(17).index\n",
    "total_exp.query('n_pos>75').sort_values('auc',ascending=False).head(17).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e935c7d-ff7f-4291-ba44-2ecf0f5adce0",
   "metadata": {},
   "source": [
    "# inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994b6a0-7cc2-4b07-8fdf-cbbb95f50705",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('../data/multimodal/240311_nettcr_pairedAB_expanded_noswap.csv')\n",
    "exp78 = pd.read_csv('../data/filtered/240507_nettcr_exp_pruned_noswap_78peps.csv')\n",
    "exp17 = pd.read_csv('../data/filtered/240418_nettcr_expanded_20binders_17pep_POSONLY.csv')\n",
    "old_df = pd.read_csv('../data/filtered/240416_nettcr_old_26pep_no_swaps.csv')\n",
    "old15 = pd.read_csv('../data/filtered/240416_nettcr_old_top15peps_no_swaps.csv')\n",
    "old20 = pd.read_csv('../data/filtered/240507_nettcr_old_pruned_noswap_20peps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472ecf8-9c22-428d-b6cd-de34fa6be140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_matrix(dm_vae, dm_base, index_col='raw_index', cols = ('peptide', 'original_peptide','raw_index', 'binder', 'partition')):\n",
    "    if not all([x==y for x,y in zip(dm_vae[index_col].values, dm_base[index_col].values)]):\n",
    "        dm_base, values_base = resort_baseline(dm_base, dm_vae, index_col)\n",
    "    else:\n",
    "        values_base = None\n",
    "    values_vae = dm_vae.iloc[:len(dm_vae), :len(dm_vae)].values\n",
    "    if values_base is None:\n",
    "        values_base = dm_base.iloc[:len(dm_base), :len(dm_base)].values\n",
    "    assert all([x==y for x,y in zip(dm_vae[index_col].values, dm_base[index_col].values)]) and len(dm_vae)==len(dm_base)\n",
    "    agg_values = 1-np.multiply(1-values_vae, 1-values_base)\n",
    "    agg_dm = pd.DataFrame(agg_values)\n",
    "    agg_dm[list(cols)] = dm_vae[list(cols)].values\n",
    "    return agg_dm, agg_dm.iloc[:len(agg_dm), :len(agg_dm)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bff426-408f-4880-85f4-ba3249384a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_tbcr = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/2404XX_OUTPUT_tbcralign_distmatrix_140peps_labeled.csv', index_col=0)\n",
    "dm_tcrdist = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/tcrdist3_distmatrix_140peps_new_labeled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060ea16-9f44-4836-8ed3-1a035c6886ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ts128 = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj/epoch_5000_interval_checkpoint__kcv_fold_00_Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj.pt',\n",
    "                              '../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj/checkpoint_best_kcv_fold_00_Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj_JSON_kwargs.json',\n",
    "                              map_location='cpu', verbose=False)\n",
    "model_os128 = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1607_ER8wJ/checkpoint_best_fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1607_ER8wJ.pt',\n",
    "                              '../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1607_ER8wJ/checkpoint_best_fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1607_ER8wJ_JSON_kwargs.json',\n",
    "                              map_location='cpu', verbose=False)\n",
    "model_os256 = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_latent_256_kld_1e-2_ExpData_KFold_0_240618_1607_vnN02/epoch_8000_interval_checkpoint__fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_latent_256_kld_1e-2_ExpData_KFold_0_240618_1607_vnN02.pt',\n",
    "                              '../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_latent_256_kld_1e-2_ExpData_KFold_0_240618_1607_vnN02/checkpoint_best_fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_latent_256_kld_1e-2_ExpData_KFold_0_240618_1607_vnN02_JSON_kwargs.json',\n",
    "                              map_location='cpu', verbose=False)\n",
    "\n",
    "model_ts128_notrp = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1232_ph8wm/epoch_4000_interval_checkpoint__kcv_fold_00_Nested_TwoStageCNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1232_ph8wm.pt',\n",
    "                                    '../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1232_ph8wm/checkpoint_best_kcv_fold_00_Nested_TwoStageCNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1232_ph8wm_JSON_kwargs.json',\n",
    "                                    map_location='cpu', verbose=False)\n",
    "model_os128_notrp = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1501_6omni/checkpoint_best_fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1501_6omni.pt',\n",
    "                                    '../output/240618_NestedKCV_CNNVAE/Nested_CNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1501_6omni/checkpoint_best_fold00_kcv_240618_nettcr_exp_nested_posonly_train_p0234_f00_Nested_CNNVAE_NOTRIPLET_ld128_kld_1e-2_ExpData_KFold_0_240730_1501_6omni_JSON_kwargs.json',\n",
    "                              map_location='cpu', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748ea18-99f9-464c-80b0-5053d5b50f75",
   "metadata": {},
   "source": [
    "# MST & cuts - Redo filtered runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed639062-5600-4b40-b600-a841c327b531",
   "metadata": {},
   "source": [
    "## Test set, Subsampled + Filtered to some peps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8f61c-1044-4b94-adaf-d84979fd5eef",
   "metadata": {},
   "source": [
    "### Data reading and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f205cb-1703-4516-a79c-fb53031cddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "# See TCRBase detour for exp_filt\n",
    "print(exp_filt)\n",
    "df = exp17.query('peptide in @exp_filt and partition==1')\n",
    "testset_subsample = []\n",
    "for p in exp_filt:\n",
    "    tmp = df.query('peptide==@p')\n",
    "    testset_subsample.append(tmp.sample(min(len(tmp), random.randint(70,90)), random_state=seed))\n",
    "df = pd.concat(testset_subsample)\n",
    "df_idx = df['raw_index'].unique()\n",
    "df.groupby('peptide').agg(count=('A1','count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26cb91-15a6-431e-a1f3-de8ff8cda8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model picked on validation performance\n",
    "latent_ts128 = get_latent_df(model_ts128, df)\n",
    "latent_os128 = get_latent_df(model_os128, df)\n",
    "latent_os256 = get_latent_df(model_os256, df)\n",
    "dm_ts128, values_ts128, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_ts128, index_col='raw_index')\n",
    "dm_os128, values_os128, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os128, index_col='raw_index')\n",
    "dm_os256, values_os256, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os256, index_col='raw_index')\n",
    "# Assert all index are in the same order prior to refiltering+resorting the baselines\n",
    "assert all(dm_os128.raw_index == dm_os256.raw_index) and all(dm_ts128.raw_index == dm_os256.raw_index) and all(dm_ts128.raw_index == dm_os128.raw_index), 'wtf'\n",
    "# re-get the baseline and re-filter based on the subset test set\n",
    "dm_tbcr_testset = dm_tbcr.query('raw_index in @df_idx')\n",
    "dm_tcrdist_testset = dm_tcrdist.query('raw_index in @df_idx')\n",
    "# Resort it just so that we can re-use the labels and indices in the same order\n",
    "dm_tbcr_testset, values_tbcr_testset = resort_baseline(dm_tbcr_testset, dm_ts128, 'raw_index')\n",
    "dm_tcrdist_testset, values_tcrdist_testset = resort_baseline(dm_tcrdist_testset, dm_ts128, 'raw_index')\n",
    "print(len(dm_tbcr_testset), len(dm_tcrdist_testset), len(dm_ts128), len(dm_os128), len(dm_os256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9da54-19a4-4bb1-b833-af34827e240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the \"best\" model which is the two-stage 128 and the TBCRalign matrix\n",
    "dm_agg, values_agg = get_agg_matrix(dm_ts128, dm_tbcr_testset)\n",
    "print(len(dm_tbcr_testset), len(dm_tcrdist_testset), len(dm_ts128), len(dm_os128), len(dm_os256), len(dm_agg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e1dc4-fd7e-4e09-a28a-ce3561d13346",
   "metadata": {},
   "source": [
    "### dist matrix plotting detour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1dc93-04fa-4ceb-808d-c2b9d4b870e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dm(dm, cols=('peptide','partition','binder','origin','raw_index','original_peptide')):\n",
    "    return dm.sort_values('peptide', ascending=True)[list(dm.sort_values('peptide',ascending=True).index)+list(cols)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af98494-fad3-4758-8239-15b86e23ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dm_ts128 = sort_dm(dm_ts128)\n",
    "sorted_values_ts128 = sorted_dm_ts128.iloc[:len(sorted_dm_ts128), :len(sorted_dm_ts128)].values\n",
    "sorted_dm_os128 = sort_dm(dm_os128)\n",
    "sorted_values_os128 = sorted_dm_os128.iloc[:len(sorted_dm_os128), :len(sorted_dm_os128)].values\n",
    "sorted_dm_os256 = sort_dm(dm_os256)\n",
    "sorted_values_os256 = sorted_dm_os256.iloc[:len(sorted_dm_os256), :len(sorted_dm_os256)].values\n",
    "sorted_dm_tbcr_testset, sorted_values_tbcr_testset = resort_baseline(dm_tbcr_testset, sorted_dm_ts128, 'raw_index')\n",
    "sorted_dm_tcrdist_testset, sorted_values_tcrdist_testset = resort_baseline(dm_tcrdist_testset, sorted_dm_ts128, 'raw_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad234f-376c-4157-9c99-1992b069d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dm_ts128_notrp = sort_dm(dm_ts128_notrp)\n",
    "sorted_values_ts128_notrp = sorted_dm_ts128_notrp.iloc[:len(sorted_dm_ts128_notrp), :len(sorted_dm_ts128_notrp)].values\n",
    "\n",
    "sorted_dm_os128_notrp = sort_dm(dm_os128_notrp)\n",
    "sorted_values_os128_notrp = sorted_dm_os128_notrp.iloc[:len(sorted_dm_ts128_notrp), :len(sorted_dm_ts128_notrp)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3fd76-8b99-4ec8-9a49-d0e9c94c21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pepmap = sorted_dm_ts128_notrp.groupby('peptide').agg(count=('raw_index','count'))\n",
    "pepmap['idx']=pepmap['count'].cumsum()\n",
    "pepmap['tick']=pepmap['idx']-pepmap['count'].iloc[0]+3\n",
    "tickmarks = pepmap['tick'].to_dict() \n",
    "idxs = pepmap['idx'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83559b5e-1e78-4898-b20d-40bfb3cbbf6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8926a-a9a4-49ff-97e2-1c08d9dcffea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(16,16), width_ratios=(16.5/17, 0.5/17))\n",
    "ax = ax.ravel()\n",
    "ax, cbar_ax = ax[0], ax[1]\n",
    "sns.heatmap(sorted_values_ts128_notrp, ax=ax, square=True, cbar_ax=cbar_ax)\n",
    "ax.set_xticks(list(tickmarks.values()))\n",
    "ax.set_yticks(list(tickmarks.values()))\n",
    "\n",
    "ax.set_xticklabels(list(tickmarks.keys()), ha='center', fontweight='semibold', fontsize=15)\n",
    "ax.set_yticklabels(list(tickmarks.keys()), va='center', fontweight='semibold', fontsize=15)\n",
    "for k,v in idxs.items():\n",
    "    ax.axhline(v, ls='--', lw=.9, c='b')\n",
    "    ax.axvline(v, ls='--', lw=.9, c='b')\n",
    "# Rotate the tick labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "ax.set_title('Two Stage VAE dist matrix', fontweight='semibold', fontsize=17)\n",
    "f.tight_layout()\n",
    "f.savefig('../output/240618_NestedKCV_CNNVAE/notebook_figs/240729_ts128_NOTRP_test_distmatrix.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f4b5b-f678-4283-8e7b-d20ef4ef7c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(16,16), width_ratios=(16.5/17, 0.5/17))\n",
    "ax = ax.ravel()\n",
    "ax, cbar_ax = ax[0], ax[1]\n",
    "sns.heatmap(sorted_values_os128_notrp, ax=ax, square=True, cbar_ax=cbar_ax)\n",
    "ax.set_xticks(list(tickmarks.values()))\n",
    "ax.set_yticks(list(tickmarks.values()))\n",
    "\n",
    "ax.set_xticklabels(list(tickmarks.keys()), ha='center', fontweight='semibold', fontsize=15)\n",
    "ax.set_yticklabels(list(tickmarks.keys()), va='center', fontweight='semibold', fontsize=15)\n",
    "for k,v in idxs.items():\n",
    "    ax.axhline(v, ls='--', lw=.9, c='b')\n",
    "    ax.axvline(v, ls='--', lw=.9, c='b')\n",
    "# Rotate the tick labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "ax.set_title('Two Stage VAE dist matrix', fontweight='semibold', fontsize=17)\n",
    "f.tight_layout()\n",
    "f.savefig('../output/240618_NestedKCV_CNNVAE/notebook_figs/240729_os128_NOTRP_test_distmatrix.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed49235-4849-4b6a-9bb3-6859025f25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(16,16), width_ratios=(16.5/17, 0.5/17))\n",
    "ax = ax.ravel()\n",
    "ax, cbar_ax = ax[0], ax[1]\n",
    "sns.heatmap(sorted_values_ts128, ax=ax, square=True, cbar_ax=cbar_ax)\n",
    "ax.set_xticks(list(tickmarks.values()))\n",
    "ax.set_yticks(list(tickmarks.values()))\n",
    "\n",
    "ax.set_xticklabels(list(tickmarks.keys()), ha='center', fontweight='semibold', fontsize=15)\n",
    "ax.set_yticklabels(list(tickmarks.keys()), va='center', fontweight='semibold', fontsize=15)\n",
    "for k,v in idxs.items():\n",
    "    ax.axhline(v, ls='--', lw=.9, c='b')\n",
    "    ax.axvline(v, ls='--', lw=.9, c='b')\n",
    "# Rotate the tick labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "ax.set_title('Two Stage VAE dist matrix', fontweight='semibold', fontsize=17)\n",
    "f.tight_layout()\n",
    "f.savefig('../output/240618_NestedKCV_CNNVAE/notebook_figs/240729_ts128_test_distmatrix.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3e7c8-d4ff-428d-8d35-ef86a116f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(16,16), width_ratios=(16.5/17, 0.5/17))\n",
    "ax = ax.ravel()\n",
    "ax, cbar_ax = ax[0], ax[1]\n",
    "sns.heatmap(sorted_values_tbcr_testset, ax=ax, square=True, cbar_ax=cbar_ax)\n",
    "ax.set_xticks(list(tickmarks.values()))\n",
    "ax.set_yticks(list(tickmarks.values()))\n",
    "\n",
    "ax.set_xticklabels(list(tickmarks.keys()), ha='center', fontweight='semibold', fontsize=15)\n",
    "ax.set_yticklabels(list(tickmarks.keys()), va='center', fontweight='semibold', fontsize=15)\n",
    "for k,v in idxs.items():\n",
    "    ax.axhline(v, ls='--', lw=.9, c='b')\n",
    "    ax.axvline(v, ls='--', lw=.9, c='b')\n",
    "# Rotate the tick labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "ax.set_title('TBCRalign dist matrix', fontweight='semibold', fontsize=17)\n",
    "f.tight_layout()\n",
    "f.savefig('../output/240618_NestedKCV_CNNVAE/notebook_figs/240729_tbcr_test_distmatrix.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b87ad-5fc5-4151-9429-d13b52070925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(dm_tbcr_testset.query('peptide in [\"ELAGIGILTV\", \"GILGFVFTL\"]').iloc[:len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff3e2a-d948-4b9d-af8c-5a85eac1320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd=dm_tbcr_testset.query('peptide in [\"ELAGIGILTV\", \"GILGFVFTL\"]')\n",
    "xd = xd[[str(x) for x in xd.index]].values\n",
    "sns.heatmap(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82945cc-91bb-4cc5-90ba-6a54d19b5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf=sorted_dm_tbcr_testset.query('peptide in [\"ELAGIGILTV\", \"GILGFVFTL\"]')\n",
    "wtf = wtf[[str(x) for x in wtf.index]+['peptide','raw_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a386b-0e0b-403e-9255-54c209da4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf.iloc[40:80, 40:82]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c41c2-0b32-411a-b021-10c76ebea258",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236114c-d401-40ac-8fcd-5594c059d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cut_threshold=1\n",
    "initial_cut_method='top'\n",
    "filename='240715_8peps_subsampled_partition1_test_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c2c74-f141-457f-8780-9d8bbf87934f",
   "metadata": {},
   "source": [
    "### Running the algos for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de7e1c-ccc9-4b90-a9d1-48c7a462ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBCRALIGN\n",
    "\n",
    "G, tree, dist_matrix, values_tbcr_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_tbcr_testset, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, tbcr_it_scores, tbcr_it_purities, tbcr_it_rets = iterative_size_cut(values_tbcr_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, tbcr_sh_scores, tbcr_sh_purities, tbcr_sh_rets = iterative_topn_cut(values_tbcr_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n",
    "\n",
    "# Running TCRdist distmatrix\n",
    "G, tree, dist_matrix, values_tcrdist_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_tcrdist_testset, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, tcrdist_it_scores, tcrdist_it_purities, tcrdist_it_rets = iterative_size_cut(values_tcrdist_testset, tree, \n",
    "                                                                                                                                 initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                                 initial_cut_method=initial_cut_method, \n",
    "                                                                                                                                 top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, tcrdist_sh_scores, tcrdist_sh_purities, tcrdist_sh_rets = iterative_topn_cut(values_tcrdist_testset, tree, \n",
    "                                                                                                                                            initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                                            initial_cut_method=initial_cut_method, \n",
    "                                                                                                                                            top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                                            verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e5c5e-ca67-45a4-8654-fc0b9f3f53b6",
   "metadata": {},
   "source": [
    "### Running for VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d2272-e198-439e-a338-9536a2357124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Two-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_ts128_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_ts128, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_ts128, it_purities_ts128, it_rets_ts128 = iterative_size_cut(values_ts128_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_ts128, sh_purities_ts128, sh_rets_ts128 = iterative_topn_cut(values_ts128_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0876f-527d-4a70-a8c2-6379ffc21ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os128_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os128, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os128, it_purities_os128, it_rets_os128 = iterative_size_cut(values_os128_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os128, sh_purities_os128, sh_rets_os128 = iterative_topn_cut(values_os128_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3bccd-bdac-442e-ae0e-cdc034d01cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os256_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os256, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os256, it_purities_os256, it_rets_os256 = iterative_size_cut(values_os256_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os256, sh_purities_os256, sh_rets_os256 = iterative_topn_cut(values_os256_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c7be43-6caf-4a72-be8c-8fa82325b492",
   "metadata": {},
   "source": [
    "### Run the aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca976e-2b79-484a-b5af-5ce769269280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_agg_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_agg, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_agg, it_purities_agg, it_rets_agg = iterative_size_cut(values_agg_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_agg, sh_purities_agg, sh_rets_agg = iterative_topn_cut(values_agg_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe316f48-1ea8-44c1-a6b2-fede1f19ea9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msize_clusters\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'size_clusters' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2402ff0-d196-4af6-8131-b9e6d2833fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts128_cluster_testset = cluster_all_thresholds(values_ts128_testset, values_ts128_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os128_cluster_testset = cluster_all_thresholds(values_os128_testset, values_os128_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os256_cluster_testset = cluster_all_thresholds(values_os256_testset, values_os256_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "tcrdist_cluster_testset = cluster_all_thresholds(values_tcrdist_testset, values_tcrdist_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "tbcr_cluster_testset = cluster_all_thresholds(values_tbcr_testset, values_tbcr_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "agg_cluster_testset = cluster_all_thresholds(values_agg_testset, values_agg_testset, labels, encoded_labels, label_encoder, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bd0b2-4111-455f-ad0a-a3483608c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering = pd.concat([ts128_cluster_testset.assign(dist_matrix='ts128', method='agglomerative'), \n",
    "                                os128_cluster_testset.assign(dist_matrix='os128', method='agglomerative'), \n",
    "                                os256_cluster_testset.assign(dist_matrix='os256', method='agglomerative'), \n",
    "                                tcrdist_cluster_testset.assign(dist_matrix='tcrdist', method='agglomerative'), \n",
    "                                tbcr_cluster_testset.assign(dist_matrix='tbcr', method='agglomerative'), \n",
    "                                agg_cluster_testset.assign(dist_matrix='agg', method='agglomerative')])\n",
    "test_clustering = pd.concat([test_clustering, \n",
    "           pd.concat([pd.DataFrame(np.array([sh_rets_ts128, sh_purities_ts128, sh_scores_ts128]).T, \n",
    "             columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='ts128', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_os128, sh_purities_os128, sh_scores_os128]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os128', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_os256, sh_purities_os256, sh_scores_os256]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os256', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_agg, sh_purities_agg, sh_scores_agg]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='agg', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([tbcr_sh_rets, tbcr_sh_purities, tbcr_sh_scores]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='tbcr', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([tcrdist_sh_rets, tcrdist_sh_purities, tcrdist_sh_scores]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='tcrdist', method='MST_size_cut')])]).assign(dataset='8peps', partition='test', fold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcb690-c34d-464a-9f39-d5da5e5b366e",
   "metadata": {},
   "source": [
    "### silhouette score plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4d8b9-21a2-49fa-b3c5-2871649d8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning ; Using Top-5 as initial cut ; distance-weighted betweenness\\nTBCR comparison of size-cut and top-1 (silhouette) cut')\n",
    "\n",
    "a.plot(range(len(tbcr_it_purities)), tbcr_it_purities, lw=.75, ls=':', c='m',\n",
    "       label='TBCR size(4)-cut avg purity')\n",
    "a.plot(range(len(tbcr_it_rets)), tbcr_it_rets, lw=.75, ls='-', c='m',\n",
    "       label='TBCR size(4)-cut avg retention')\n",
    "a2.plot(range(len(tbcr_it_scores)), tbcr_it_scores, lw=.75, ls='--', c='m',\n",
    "       label='TBCR size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(tbcr_sh_purities)), tbcr_sh_purities, lw=1, ls=':', c='g',\n",
    "       label='TBCR Top1-cut avg purity')\n",
    "a.plot(range(len(tbcr_sh_rets)), tbcr_sh_rets, lw=.75, ls='-', c='g',\n",
    "       label='TBCR Top1-cut avg retention')\n",
    "a2.plot(range(len(tbcr_sh_scores)), tbcr_sh_scores, lw=.8, ls='--', c='g',\n",
    "       label='TBCR Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.88))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}TBCR_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97eabad-7b72-4908-9958-e2ae6d7e7fad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning ; Using Top-5 as initial cut ; distance-weighted betweenness\\ntcrdist3 comparison of size-cut and top-1 (silhouette) cut')\n",
    "\n",
    "a.plot(range(len(tcrdist_it_purities)), tcrdist_it_purities, lw=.75, ls=':', c='c',\n",
    "       label='tcrdist3 size(4)-cut avg purity')\n",
    "a.plot(range(len(tcrdist_it_rets)), tcrdist_it_rets, lw=.75, ls='-', c='c',\n",
    "       label='tcrdist3 size(4)-cut avg retention')\n",
    "a2.plot(range(len(tcrdist_it_scores)), tcrdist_it_scores, lw=.75, ls='--', c='c',\n",
    "       label='tcrdist3 size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(tcrdist_sh_purities)), tcrdist_sh_purities, lw=1, ls=':', c='y',\n",
    "       label='tcrdist3 Top1-cut avg purity')\n",
    "a.plot(range(len(tcrdist_sh_rets)), tcrdist_sh_rets, lw=.75, ls='-', c='y',\n",
    "       label='tcrdist3 Top1-cut avg retention')\n",
    "a2.plot(range(len(tcrdist_sh_scores)), tcrdist_sh_scores, lw=.8, ls='--', c='y',\n",
    "       label='tcrdist3 Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.88))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}tcrdist3_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7626989-7a77-4e00-8d57-680c8e16aae3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning TwoStage 128 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_ts128)), it_purities_ts128, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_ts128)), it_rets_ts128, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_ts128)), it_scores_ts128, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_ts128)), sh_purities_ts128, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_ts128)), sh_rets_ts128, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_ts128)), sh_scores_ts128, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_ts128_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328cb8c-22aa-40c5-b53d-84af63259f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning OneStage 128 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_os128)), it_purities_os128, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_os128)), it_rets_os128, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_os128)), it_scores_os128, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_os128)), sh_purities_os128, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_os128)), sh_rets_os128, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_os128)), sh_scores_os128, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_os128_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22caac0c-be7f-43c0-b013-5b618291cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning OneStage 256 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_os256)), it_purities_os256, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_os256)), it_rets_os256, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_os256)), it_scores_os256, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_os256)), sh_purities_os256, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_os256)), sh_rets_os256, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_os256)), sh_scores_os256, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_os256_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d7723-0ee5-4f25-a37e-7b218dae3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning Aggregate ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_agg)), it_purities_agg, lw=1, ls=':', c='b',\n",
    "       label='AggDM size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_agg)), it_rets_agg, lw=.75, ls='-', c='b',\n",
    "       label='AggDM size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_agg)), it_scores_agg, lw=.8, ls='--', c='b',\n",
    "       label='AggDM size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_agg)), sh_purities_agg, lw=.75, ls=':', c='r',\n",
    "       label='AggDM Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_agg)), sh_rets_agg, lw=.75, ls='-', c='r',\n",
    "       label='AggDM Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_agg)), sh_scores_agg, lw=.75, ls='--', c='r',\n",
    "       label='AggDM Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_agg_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71461bfe-fb94-4218-9d1c-09d8c60f1eba",
   "metadata": {},
   "source": [
    "### retpur curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7c348-f3da-41c0-b611-7e1e1046d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best point (based on Silhouette score) for each of the 4 conditions and add them as scatter points\n",
    "best_sh_ts128 = sh_rets_ts128[np.argmax(sh_scores_ts128)], sh_purities_ts128[np.argmax(sh_scores_ts128)]\n",
    "best_it_ts128 = it_rets_ts128[np.argmax(it_scores_ts128)], it_purities_ts128[np.argmax(it_scores_ts128)]\n",
    "best_sh_os128 = sh_rets_os128[np.argmax(sh_scores_os128)], sh_purities_os128[np.argmax(sh_scores_os128)]\n",
    "best_it_os128 = it_rets_os128[np.argmax(it_scores_os128)], it_purities_os128[np.argmax(it_scores_os128)]\n",
    "best_sh_os256 = sh_rets_os256[np.argmax(sh_scores_os256)], sh_purities_os256[np.argmax(sh_scores_os256)]\n",
    "best_it_os256 = it_rets_os256[np.argmax(it_scores_os256)], it_purities_os256[np.argmax(it_scores_os256)]\n",
    "best_sh_agg = sh_rets_agg[np.argmax(sh_scores_agg)], sh_purities_agg[np.argmax(sh_scores_agg)]\n",
    "best_it_agg = it_rets_agg[np.argmax(it_scores_agg)], it_purities_agg[np.argmax(it_scores_agg)]\n",
    "best_tbcr_sh = tbcr_sh_rets[np.argmax(tbcr_sh_scores)], tbcr_sh_purities[np.argmax(tbcr_sh_scores)]\n",
    "best_tbcr_it = tbcr_it_rets[np.argmax(tbcr_it_scores)], tbcr_it_purities[np.argmax(tbcr_it_scores)]\n",
    "best_tcrdist_sh = tcrdist_sh_rets[np.argmax(tcrdist_sh_scores)], tcrdist_sh_purities[np.argmax(tcrdist_sh_scores)]\n",
    "best_tcrdist_it = tcrdist_it_rets[np.argmax(tcrdist_it_scores)], tcrdist_it_purities[np.argmax(tcrdist_it_scores)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573d4c2-14ba-4d12-b1e7-e6bd00488498",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette=get_palette('cool', 3)\n",
    "sns.palplot(palette)\n",
    "c_ts128 = palette[0]\n",
    "c_os128 = palette[1]\n",
    "c_os256 = palette[2]\n",
    "c_agg = 'r'\n",
    "c_tbcr='g'\n",
    "c_tcrdist='y'\n",
    "f,a = plt.subplots(1,1, figsize=(10,10))\n",
    "lw=.75\n",
    "marker_size=12\n",
    "marker='*'\n",
    "# TBCRalign\n",
    "a.plot(tbcr_cluster_testset['retention'].values[1:-1], tbcr_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'TBCRalign + Agglomerative Clustering', lw=0.5, ls='-', c=c_tbcr)\n",
    "a.plot(tbcr_sh_rets, tbcr_sh_purities, label = 'TBCRalign MST + Top 1 Cut', lw = lw, ls='--', c=c_tbcr)\n",
    "a.scatter(best_tbcr_sh[0], best_tbcr_sh[1], c=c_tbcr, label = 'Best (Silhouette) TBCRalign MST + Top 1 Cut', s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# tcrdist3\n",
    "a.plot(tcrdist_cluster_testset['retention'].values[1:-1], tcrdist_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'tcrdist + Agglomerative Clustering', lw=0.5, ls='-', c=c_tcrdist)\n",
    "a.plot(tcrdist_sh_rets, tcrdist_sh_purities, label = 'tcrdist3 MST + Top 1 Cut', lw = lw, ls='--', c=c_tcrdist)\n",
    "a.scatter(best_tcrdist_sh[0], best_tcrdist_sh[1], c=c_tcrdist, label = 'Best (Silhouette) tcrdist3 MST + Top 1 Cut', s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "\n",
    "# TS128\n",
    "a.plot(ts128_cluster_testset['retention'].values[1:-1], ts128_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'TS128 + Agglomerative Clustering', lw=0.5, ls='-', c=c_ts128)\n",
    "a.plot(sh_rets_ts128, sh_purities_ts128, label = 'TS128 MST + Top 1 Cut', lw = lw, ls='--', c=c_ts128)\n",
    "a.scatter(best_sh_ts128[0], best_sh_ts128[1], c=c_ts128, label = 'Best (Silhouette) TS128 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# OS128\n",
    "a.plot(os128_cluster_testset['retention'].values[1:-1], os128_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'OS128 + Agglomerative Clustering', lw=0.5, ls='-', c=c_os128)\n",
    "\n",
    "a.plot(sh_rets_os128, sh_purities_os128, label = 'OS128 MST + Top 1 Cut', lw = lw, ls='--', c=c_os128)\n",
    "a.scatter(best_sh_os128[0], best_sh_os128[1], c=c_os128, label = 'Best (Silhouette) OS128 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# OS256\n",
    "a.plot(os256_cluster_testset['retention'].values[1:-1], os256_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'OS256 + Agglomerative Clustering', lw=0.5, ls='-', c=c_os256)\n",
    "\n",
    "a.plot(sh_rets_os256, sh_purities_os256, label = 'OS256 MST + Top 1 Cut', lw = lw, ls='--', c=c_os256)\n",
    "a.scatter(best_sh_os256[0], best_sh_os256[1], c=c_os256, label = 'Best (Silhouette) OS256 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# Aggregated\n",
    "a.plot(agg_cluster_testset['retention'].values[1:-1], agg_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'AggDM + Agglomerative Clustering', lw=0.5, ls='-', c=c_agg)\n",
    "\n",
    "a.plot(sh_rets_agg, sh_purities_agg, label = 'AggDM MST + Top 1 Cut', lw = lw, ls='--', c=c_agg)\n",
    "a.scatter(best_sh_agg[0], best_sh_agg[1], c=c_agg, label = 'Best (Silhouette) AggDM MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "a.legend()\n",
    "a.set_ylim([.5,1.])\n",
    "a.set_xlim([.5,1.])\n",
    "a.set_xlabel('Retention', fontsize=12, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=12, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for test set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting ; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a041306-a74c-4686-bcde-ad4d9ad3c0cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For the test set, check per peptide correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009fc88-64c3-48a0-a423-75329fb0ed5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os128_testset, labels,\\\n",
    "    encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os128, label_col='peptide',\n",
    "                                                                                 index_col='raw_index', algorithm='kruskal')\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed,\\\n",
    "    sh_scores_os128, sh_purities_os128, sh_rets_os128 = iterative_topn_cut(values_os128_testset, tree, \n",
    "                                                                           initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                           initial_cut_method=initial_cut_method, \n",
    "                                                                           top_n=1, which='edge', weighted=True, \n",
    "                                                                           verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]),\n",
    "      np.mean([x['purity'] for x in topn_clusters]), \n",
    "      np.sum([x['cluster_size'] for x in topn_clusters])/len(dm_os128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c25421-2228-4c6e-9105-e3054ed29638",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb2f6a-3611-4dd1-b32a-8e38933fce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in singletons if x[0] in nodes_removed]), len(nodes_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cbfb6-0117-4e35-a772-cbc2d910d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "in_clusters = [x for members in topn_clusters for x in members['members']]\n",
    "singletons = [x for x in tree.nodes(data=True) if x[0] not in in_clusters]\n",
    "my_list = [x[1]['peptide'] for x in singletons]\n",
    "occurrences = Counter(my_list)\n",
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c28012-6d43-4f86-8232-af56dfd0fad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75268fb-4ad5-4ee3-9ffc-ac7f1b541185",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.merge(df.groupby('peptide').agg(count=('B3','count')), \n",
    "         pd.DataFrame(dict(occurrences), index=[0]).T.rename(columns={0:'n_singletons'}),\n",
    "        left_index=True,right_index=True)\n",
    "res['percent_singletons'] = (res['n_singletons']/res['count']).round(4) * 100\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a98111-bca4-4eb8-997a-e0fe34254c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.DataFrame(topn_clusters)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7879bb-a092-42c4-99f2-65ccf3854c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.groupby(['majority_label']).agg(mean_purity=('purity','mean'), \n",
    "                                           mean_size=('cluster_size','mean'),\n",
    "                                           n_clusters=('cluster_size','count'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2097e-5d23-4321-bf36-d04ec9054953",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.query('cluster_size==3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b281e8-0804-4c6d-ad98-6004d74d205b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(topn_clusters).query('purity<0.6').counts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a392c-49a5-4bdc-91a8-a674d4f8a626",
   "metadata": {},
   "source": [
    "## Valid set, Subsampled + Filtered to some peps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97331bdd-7453-4d31-ad17-b51ace32577c",
   "metadata": {},
   "source": [
    "### Data reading and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b45b23-905c-4281-b5e5-1d3ca98818f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "# See TCRBase detour for exp_filt\n",
    "print(exp_filt)\n",
    "df = exp17.query('peptide in @exp_filt and partition==0')\n",
    "testset_subsample = []\n",
    "for p in exp_filt:\n",
    "    tmp = df.query('peptide==@p')\n",
    "    testset_subsample.append(tmp.sample(min(len(tmp), random.randint(70,90)), random_state=seed))\n",
    "df = pd.concat(testset_subsample)\n",
    "df_idx = df['raw_index'].unique()\n",
    "df.groupby('peptide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a433305-3466-4aef-b797-47614c5386c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model picked on validation performance\n",
    "latent_ts128 = get_latent_df(model_ts128, df)\n",
    "latent_os128 = get_latent_df(model_os128, df)\n",
    "latent_os256 = get_latent_df(model_os256, df)\n",
    "dm_ts128, values_ts128, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_ts128, index_col='raw_index')\n",
    "dm_os128, values_os128, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os128, index_col='raw_index')\n",
    "dm_os256, values_os256, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os256, index_col='raw_index')\n",
    "# Assert all index are in the same order prior to refiltering+resorting the baselines\n",
    "assert all(dm_os128.raw_index == dm_os256.raw_index) and all(dm_ts128.raw_index == dm_os256.raw_index) and all(dm_ts128.raw_index == dm_os128.raw_index), 'wtf'\n",
    "# re-get the baseline and re-filter based on the subset test set\n",
    "dm_tbcr_testset = dm_tbcr.query('raw_index in @df_idx')\n",
    "dm_tcrdist_testset = dm_tcrdist.query('raw_index in @df_idx')\n",
    "# Resort it just so that we can re-use the labels and indices in the same order\n",
    "dm_tbcr_testset, values_tbcr_testset = resort_baseline(dm_tbcr_testset, dm_ts128, 'raw_index')\n",
    "dm_tcrdist_testset, values_tcrdist_testset = resort_baseline(dm_tcrdist_testset, dm_ts128, 'raw_index')\n",
    "print(len(dm_tbcr_testset), len(dm_tcrdist_testset), len(dm_ts128), len(dm_os128), len(dm_os256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708d995-bfeb-4cdc-8161-859c5079e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the \"best\" model which is the two-stage 128 and the TBCRalign matrix\n",
    "dm_agg, values_agg = get_agg_matrix(dm_ts128, dm_tbcr_testset)\n",
    "print(len(dm_tbcr_testset), len(dm_tcrdist_testset), len(dm_ts128), len(dm_os128), len(dm_os256), len(dm_agg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f29d42-ce24-47c8-98bf-07f246a25f4d",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35ee82-2a27-4c11-9582-d89141a1f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cut_threshold=1\n",
    "initial_cut_method='top'\n",
    "filename='240715_8peps_subsampled_partition0_validation_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8edd84-b659-451a-a12d-75788af86369",
   "metadata": {},
   "source": [
    "### Running the algos for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70611d5e-d9cd-4e95-aea1-e77dd8629a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBCRALIGN\n",
    "\n",
    "G, tree, dist_matrix, values_tbcr_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_tbcr_testset, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, tbcr_it_scores, tbcr_it_purities, tbcr_it_rets = iterative_size_cut(values_tbcr_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, tbcr_sh_scores, tbcr_sh_purities, tbcr_sh_rets = iterative_topn_cut(values_tbcr_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n",
    "\n",
    "# Running TCRdist distmatrix\n",
    "G, tree, dist_matrix, values_tcrdist_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_tcrdist_testset, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, tcrdist_it_scores, tcrdist_it_purities, tcrdist_it_rets = iterative_size_cut(values_tcrdist_testset, tree, \n",
    "                                                                                                                                 initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                                 initial_cut_method=initial_cut_method, \n",
    "                                                                                                                                 top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, tcrdist_sh_scores, tcrdist_sh_purities, tcrdist_sh_rets = iterative_topn_cut(values_tcrdist_testset, tree, \n",
    "                                                                                                                                            initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                                            initial_cut_method=initial_cut_method, \n",
    "                                                                                                                                            top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                                            verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd6e67-5d16-4e8e-816e-8564696a29e3",
   "metadata": {},
   "source": [
    "### Running for VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421235c-c02d-48a5-80df-bf4bd290ae36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Two-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_ts128_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_ts128, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_ts128, it_purities_ts128, it_rets_ts128 = iterative_size_cut(values_ts128_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_ts128, sh_purities_ts128, sh_rets_ts128 = iterative_topn_cut(values_ts128_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79591b76-116d-4e9d-858f-0d2a21fbad17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os128_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os128, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os128, it_purities_os128, it_rets_os128 = iterative_size_cut(values_os128_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os128, sh_purities_os128, sh_rets_os128 = iterative_topn_cut(values_os128_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415159f-74f4-4e32-9243-cbc88f3d870c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os256_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os256, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os256, it_purities_os256, it_rets_os256 = iterative_size_cut(values_os256_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os256, sh_purities_os256, sh_rets_os256 = iterative_topn_cut(values_os256_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215af34-2521-44d3-b06d-e30818f19bba",
   "metadata": {},
   "source": [
    "### Run the aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d235fee-99ca-4c55-bec1-77d33d5c1452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_agg_testset, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_agg, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_agg, it_purities_agg, it_rets_agg = iterative_size_cut(values_agg_testset, tree, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_agg, sh_purities_agg, sh_rets_agg = iterative_topn_cut(values_agg_testset, tree, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36642f-aacb-4b06-85bb-5092aa0bc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts128_cluster_testset = cluster_all_thresholds(values_ts128_testset, values_ts128_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os128_cluster_testset = cluster_all_thresholds(values_os128_testset, values_os128_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os256_cluster_testset = cluster_all_thresholds(values_os256_testset, values_os256_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "tcrdist_cluster_testset = cluster_all_thresholds(values_tcrdist_testset, values_tcrdist_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "tbcr_cluster_testset = cluster_all_thresholds(values_tbcr_testset, values_tbcr_testset, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "agg_cluster_testset = cluster_all_thresholds(values_agg_testset, values_agg_testset, labels, encoded_labels, label_encoder, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750744c6-2e87-4865-a6a8-378037182021",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clustering = pd.concat([ts128_cluster_testset.assign(dist_matrix='ts128', method='agglomerative'), \n",
    "                                os128_cluster_testset.assign(dist_matrix='os128', method='agglomerative'), \n",
    "                                os256_cluster_testset.assign(dist_matrix='os256', method='agglomerative'), \n",
    "                                tcrdist_cluster_testset.assign(dist_matrix='tcrdist', method='agglomerative'), \n",
    "                                tbcr_cluster_testset.assign(dist_matrix='tbcr', method='agglomerative'), \n",
    "                                agg_cluster_testset.assign(dist_matrix='agg', method='agglomerative')])\n",
    "valid_clustering = pd.concat([valid_clustering, \n",
    "           pd.concat([pd.DataFrame(np.array([sh_rets_ts128, sh_purities_ts128, sh_scores_ts128]).T, \n",
    "             columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='ts128', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_os128, sh_purities_os128, sh_scores_os128]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os128', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_os256, sh_purities_os256, sh_scores_os256]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os256', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([sh_rets_agg, sh_purities_agg, sh_scores_agg]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='agg', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([tbcr_sh_rets, tbcr_sh_purities, tbcr_sh_scores]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='tbcr', method='MST_size_cut'),\n",
    "           pd.DataFrame(np.array([tcrdist_sh_rets, tcrdist_sh_purities, tcrdist_sh_scores]).T, \n",
    "                        columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='tcrdist', method='MST_size_cut')])]).assign(dataset='8peps', partition='valid', fold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88a599-e5ac-4dd7-870c-b293933bda67",
   "metadata": {},
   "source": [
    "### silhouette score plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d607f7-b2c4-453d-9582-27119f7c981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning ; Using Top-5 as initial cut ; distance-weighted betweenness\\nTBCR comparison of size-cut and top-1 (silhouette) cut')\n",
    "\n",
    "a.plot(range(len(tbcr_it_purities)), tbcr_it_purities, lw=.75, ls=':', c='m',\n",
    "       label='TBCR size(4)-cut avg purity')\n",
    "a.plot(range(len(tbcr_it_rets)), tbcr_it_rets, lw=.75, ls='-', c='m',\n",
    "       label='TBCR size(4)-cut avg retention')\n",
    "a2.plot(range(len(tbcr_it_scores)), tbcr_it_scores, lw=.75, ls='--', c='m',\n",
    "       label='TBCR size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(tbcr_sh_purities)), tbcr_sh_purities, lw=1, ls=':', c='g',\n",
    "       label='TBCR Top1-cut avg purity')\n",
    "a.plot(range(len(tbcr_sh_rets)), tbcr_sh_rets, lw=.75, ls='-', c='g',\n",
    "       label='TBCR Top1-cut avg retention')\n",
    "a2.plot(range(len(tbcr_sh_scores)), tbcr_sh_scores, lw=.8, ls='--', c='g',\n",
    "       label='TBCR Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.88))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}TBCR_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b13400-6629-41a6-b7b2-22ed63feb51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning ; Using Top-5 as initial cut ; distance-weighted betweenness\\ntcrdist3 comparison of size-cut and top-1 (silhouette) cut')\n",
    "\n",
    "a.plot(range(len(tcrdist_it_purities)), tcrdist_it_purities, lw=.75, ls=':', c='c',\n",
    "       label='tcrdist3 size(4)-cut avg purity')\n",
    "a.plot(range(len(tcrdist_it_rets)), tcrdist_it_rets, lw=.75, ls='-', c='c',\n",
    "       label='tcrdist3 size(4)-cut avg retention')\n",
    "a2.plot(range(len(tcrdist_it_scores)), tcrdist_it_scores, lw=.75, ls='--', c='c',\n",
    "       label='tcrdist3 size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(tcrdist_sh_purities)), tcrdist_sh_purities, lw=1, ls=':', c='y',\n",
    "       label='tcrdist3 Top1-cut avg purity')\n",
    "a.plot(range(len(tcrdist_sh_rets)), tcrdist_sh_rets, lw=.75, ls='-', c='y',\n",
    "       label='tcrdist3 Top1-cut avg retention')\n",
    "a2.plot(range(len(tcrdist_sh_scores)), tcrdist_sh_scores, lw=.8, ls='--', c='y',\n",
    "       label='tcrdist3 Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.88))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}tcrdist3_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2ca33-6924-4a45-8ec0-d87c447f8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning TwoStage 128 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_ts128)), it_purities_ts128, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_ts128)), it_rets_ts128, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_ts128)), it_scores_ts128, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_ts128)), sh_purities_ts128, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_ts128)), sh_rets_ts128, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_ts128)), sh_scores_ts128, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_ts128_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97070c-99ee-4720-bb33-699610f9f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning OneStage 128 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_os128)), it_purities_os128, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_os128)), it_rets_os128, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_os128)), it_scores_os128, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_os128)), sh_purities_os128, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_os128)), sh_rets_os128, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_os128)), sh_scores_os128, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_os128_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd7f3e-6a49-4859-8dad-a4933a37d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning OneStage 256 ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_os256)), it_purities_os256, lw=1, ls=':', c='b',\n",
    "       label='VAE size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_os256)), it_rets_os256, lw=.75, ls='-', c='b',\n",
    "       label='VAE size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_os256)), it_scores_os256, lw=.8, ls='--', c='b',\n",
    "       label='VAE size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_os256)), sh_purities_os256, lw=.75, ls=':', c='r',\n",
    "       label='VAE Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_os256)), sh_rets_os256, lw=.75, ls='-', c='r',\n",
    "       label='VAE Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_os256)), sh_scores_os256, lw=.75, ls='--', c='r',\n",
    "       label='VAE Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_os256_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a22138-934b-4982-8e7e-0cced419ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(7,4))\n",
    "a2 = a.twinx()\n",
    "a.set_title('No initial pruning Aggregate ; Using Top-5 as initial cut ; distance-weighted betweenness\\nVAE comparison of size-cut and top-1 (silhouette) cut')\n",
    "a.plot(range(len(it_purities_agg)), it_purities_agg, lw=1, ls=':', c='b',\n",
    "       label='AggDM size(4)-cut avg purity')\n",
    "a.plot(range(len(it_rets_agg)), it_rets_agg, lw=.75, ls='-', c='b',\n",
    "       label='AggDM size(4)-cut avg retention')\n",
    "a2.plot(range(len(it_scores_agg)), it_scores_agg, lw=.8, ls='--', c='b',\n",
    "       label='AggDM size(4)-cut silhouette score')\n",
    "\n",
    "a.plot(range(len(sh_purities_agg)), sh_purities_agg, lw=.75, ls=':', c='r',\n",
    "       label='AggDM Top1-cut avg purity')\n",
    "a.plot(range(len(sh_rets_agg)), sh_rets_agg, lw=.75, ls='-', c='r',\n",
    "       label='AggDM Top1-cut avg retention')\n",
    "a2.plot(range(len(sh_scores_agg)), sh_scores_agg, lw=.75, ls='--', c='r',\n",
    "       label='AggDM Top1-cut silhouette score')\n",
    "\n",
    "# Align the tick marks\n",
    "a.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from primary y-axis\n",
    "a2.yaxis.set_tick_params(which='both', length=0)  # Remove tick marks from secondary y-axis\n",
    "# Align the gridlines\n",
    "a.grid(True)\n",
    "a2.grid(False)  # Disable secondary y-axis gridlines\n",
    "a.set_ylabel('Retention // Purity (%)')\n",
    "a2.set_ylabel('Silhouette score')\n",
    "a2.set_ylim([-0.11,0.16])\n",
    "a2.legend(bbox_to_anchor=(1.62,.25))\n",
    "a.set_xlabel('iteration')\n",
    "a.legend(bbox_to_anchor=(1.62,.8))\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_agg_silhouette.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8e857-5dc0-4887-9734-c1cae97fccfb",
   "metadata": {},
   "source": [
    "### retpur curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a904ea-d0e5-4dbf-a801-cf67098110c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best point (based on Silhouette score) for each of the 4 conditions and add them as scatter points\n",
    "best_sh_ts128 = sh_rets_ts128[np.argmax(sh_scores_ts128)], sh_purities_ts128[np.argmax(sh_scores_ts128)]\n",
    "best_it_ts128 = it_rets_ts128[np.argmax(it_scores_ts128)], it_purities_ts128[np.argmax(it_scores_ts128)]\n",
    "best_sh_os128 = sh_rets_os128[np.argmax(sh_scores_os128)], sh_purities_os128[np.argmax(sh_scores_os128)]\n",
    "best_it_os128 = it_rets_os128[np.argmax(it_scores_os128)], it_purities_os128[np.argmax(it_scores_os128)]\n",
    "best_sh_os256 = sh_rets_os256[np.argmax(sh_scores_os256)], sh_purities_os256[np.argmax(sh_scores_os256)]\n",
    "best_it_os256 = it_rets_os256[np.argmax(it_scores_os256)], it_purities_os256[np.argmax(it_scores_os256)]\n",
    "best_sh_agg = sh_rets_agg[np.argmax(sh_scores_agg)], sh_purities_agg[np.argmax(sh_scores_agg)]\n",
    "best_it_agg = it_rets_agg[np.argmax(it_scores_agg)], it_purities_agg[np.argmax(it_scores_agg)]\n",
    "best_tbcr_sh = tbcr_sh_rets[np.argmax(tbcr_sh_scores)], tbcr_sh_purities[np.argmax(tbcr_sh_scores)]\n",
    "best_tbcr_it = tbcr_it_rets[np.argmax(tbcr_it_scores)], tbcr_it_purities[np.argmax(tbcr_it_scores)]\n",
    "best_tcrdist_sh = tcrdist_sh_rets[np.argmax(tcrdist_sh_scores)], tcrdist_sh_purities[np.argmax(tcrdist_sh_scores)]\n",
    "best_tcrdist_it = tcrdist_it_rets[np.argmax(tcrdist_it_scores)], tcrdist_it_purities[np.argmax(tcrdist_it_scores)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99a232-3878-4d9d-9101-5299f0070113",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette=get_palette('cool', 3)\n",
    "sns.palplot(palette)\n",
    "c_ts128 = palette[0]\n",
    "c_os128 = palette[1]\n",
    "c_os256 = palette[2]\n",
    "c_agg = 'r'\n",
    "c_tbcr='g'\n",
    "c_tcrdist='y'\n",
    "f,a = plt.subplots(1,1, figsize=(10, 10))\n",
    "lw=.75\n",
    "marker_size=12\n",
    "marker='*'\n",
    "# TBCRalign\n",
    "a.plot(tbcr_cluster_testset['retention'].values[1:-1], tbcr_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'TBCRalign + Agglomerative Clustering', lw=0.5, ls='-', c=c_tbcr)\n",
    "a.plot(tbcr_sh_rets, tbcr_sh_purities, label = 'TBCRalign MST + Top 1 Cut', lw = lw, ls='--', c=c_tbcr)\n",
    "a.scatter(best_tbcr_sh[0], best_tbcr_sh[1], c=c_tbcr, label = 'Best (Silhouette) TBCRalign MST + Top 1 Cut', s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# tcrdist3\n",
    "a.plot(tcrdist_cluster_testset['retention'].values[1:-1], tcrdist_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'tcrdist + Agglomerative Clustering', lw=0.5, ls='-', c=c_tcrdist)\n",
    "a.plot(tcrdist_sh_rets, tcrdist_sh_purities, label = 'tcrdist3 MST + Top 1 Cut', lw = lw, ls='--', c=c_tcrdist)\n",
    "a.scatter(best_tcrdist_sh[0], best_tcrdist_sh[1], c=c_tcrdist, label = 'Best (Silhouette) tcrdist3 MST + Top 1 Cut', s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "\n",
    "# TS128\n",
    "a.plot(ts128_cluster_testset['retention'].values[1:-1], ts128_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'TS128 + Agglomerative Clustering', lw=0.5, ls='-', c=c_ts128)\n",
    "a.plot(sh_rets_ts128, sh_purities_ts128, label = 'TS128 MST + Top 1 Cut', lw = lw, ls='--', c=c_ts128)\n",
    "a.scatter(best_sh_ts128[0], best_sh_ts128[1], c=c_ts128, label = 'Best (Silhouette) TS128 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# OS128\n",
    "a.plot(os128_cluster_testset['retention'].values[1:-1], os128_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'OS128 + Agglomerative Clustering', lw=0.5, ls='-', c=c_os128)\n",
    "\n",
    "a.plot(sh_rets_os128, sh_purities_os128, label = 'OS128 MST + Top 1 Cut', lw = lw, ls='--', c=c_os128)\n",
    "a.scatter(best_sh_os128[0], best_sh_os128[1], c=c_os128, label = 'Best (Silhouette) OS128 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# OS256\n",
    "a.plot(os256_cluster_testset['retention'].values[1:-1], os256_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'OS256 + Agglomerative Clustering', lw=0.5, ls='-', c=c_os256)\n",
    "\n",
    "a.plot(sh_rets_os256, sh_purities_os256, label = 'OS256 MST + Top 1 Cut', lw = lw, ls='--', c=c_os256)\n",
    "a.scatter(best_sh_os256[0], best_sh_os256[1], c=c_os256, label = 'Best (Silhouette) OS256 MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "# Aggregated\n",
    "a.plot(agg_cluster_testset['retention'].values[1:-1], agg_cluster_testset['mean_purity'].values[1:-1], \n",
    "       label = 'AggDM + Agglomerative Clustering', lw=0.5, ls='-', c=c_agg)\n",
    "\n",
    "a.plot(sh_rets_agg, sh_purities_agg, label = 'AggDM MST + Top 1 Cut', lw = lw, ls='--', c=c_agg)\n",
    "a.scatter(best_sh_agg[0], best_sh_agg[1], c=c_agg, label = 'Best (Silhouette) AggDM MST + Top 1 Cut', \n",
    "          s=marker_size, marker=marker, lw=lw)\n",
    "\n",
    "a.legend()\n",
    "a.set_ylim([.5,1.])\n",
    "a.set_xlim([.5,1.])\n",
    "a.set_xlabel('Retention', fontsize=12, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=12, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for valid set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting ; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/{filename}_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07e593-d964-4b8d-95cf-a197597bf14c",
   "metadata": {},
   "source": [
    "# Leiden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904a2ca-9dc0-446b-82fa-50427907865e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Do intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ecede-fd33-4e1d-9ead-d4d7f256c5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "# See TCRBase detour for exp_filt\n",
    "print(exp_filt)\n",
    "df = exp17.query('peptide in @exp_filt')\n",
    "testset_subsample = []\n",
    "validset_subsample = []\n",
    "for p in exp_filt:\n",
    "    tmp_test = df.query('peptide==@p')\n",
    "    testset_subsample.append(tmp_test.sample(min(len(tmp_test), random.randint(70,90)), random_state=seed))\n",
    "    tmp_valid = df.query('peptide==@p')\n",
    "    validset_subsample.append(tmp_valid.sample(min(len(tmp_valid), random.randint(70,90)), random_state=seed))\n",
    "    \n",
    "test_df = pd.concat(testset_subsample)\n",
    "test_idx = test_df['raw_index'].unique()\n",
    "test_df.groupby('peptide').count()\n",
    "valid_df = pd.concat(validset_subsample)\n",
    "valid_idx = valid_df['raw_index'].unique()\n",
    "valid_df.groupby('peptide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785c78b-ee87-435c-a9ce-336d18ff6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model picked on validation performance\n",
    "model = load_model_full('../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj/epoch_5000_interval_checkpoint__kcv_fold_00_Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj.pt',\n",
    "                        '../output/240618_NestedKCV_CNNVAE/Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj/checkpoint_best_kcv_fold_00_Nested_TwoStageCNNVAE_latent_128_kld_1e-2_ExpData_KFold_0_240618_1608_pDQhj_JSON_kwargs.json',\n",
    "                        map_location='cpu')\n",
    "latent_test = get_latent_df(model, test_df)\n",
    "latent_valid = get_latent_df(model, valid_df)\n",
    "dm_test, values_test, feats_test, labels_test, enc_labels_test, lab_enc_test = get_distances_labels_from_latent(latent_test, index_col='raw_index')\n",
    "dm_valid, values_valid, feats_valid, labels_valid, enc_labels_valid, lab_enc_valid = get_distances_labels_from_latent(latent_valid, index_col='raw_index')\n",
    "# re-get the baseline and re-filter based on the subset test set\n",
    "dm_tbcr_test = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/2404XX_OUTPUT_tbcralign_distmatrix_140peps_labeled.csv', index_col=0).query('raw_index in @test_idx')\n",
    "dm_tcrdist_test = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/tcrdist3_distmatrix_140peps_new_labeled.csv', index_col=0).query('raw_index in @test_idx')\n",
    "dm_tbcr_valid = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/2404XX_OUTPUT_tbcralign_distmatrix_140peps_labeled.csv', index_col=0).query('raw_index in @valid_idx')\n",
    "dm_tcrdist_valid = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/tcrdist3_distmatrix_140peps_new_labeled.csv', index_col=0).query('raw_index in @valid_idx')\n",
    "# Resort it just so that we can re-use the labels and indices in the same order\n",
    "dm_tbcr_test, values_tbcr_test = resort_baseline(dm_tbcr_test, dm_test, 'raw_index')\n",
    "dm_tcrdist_test, values_tcrdist_test = resort_baseline(dm_tcrdist_test, dm_test, 'raw_index')\n",
    "dm_tbcr_valid, values_tbcr_valid = resort_baseline(dm_tbcr_valid, dm_valid, 'raw_index')\n",
    "dm_tcrdist_valid, values_tcrdist_valid = resort_baseline(dm_tcrdist_valid, dm_valid, 'raw_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40f781-d4d1-42c9-88f1-ec0460f0b430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import leidenalg\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "def get_leiden_single(dist_threshold, values, dist_matrix):\n",
    "    thresholded = values<dist_threshold# quantile\n",
    "    thresholded = thresholded * values\n",
    "    t_graph = nx.Graph(thresholded)\n",
    "    labels = dist_matrix['peptide'].values\n",
    "    raw_indices = dist_matrix['raw_index'].values\n",
    "    \n",
    "    for i, node in enumerate(t_graph.nodes()):\n",
    "        t_graph.nodes[node]['peptide'] = labels[i]\n",
    "        t_graph.nodes[node]['raw_index'] = raw_indices[i]\n",
    "        \n",
    "    # Get igGraph\n",
    "    edges = [(u,v, data['weight']) for u,v ,data in t_graph.edges(data=True)]\n",
    "    nodes = [(n, data) for n, data in t_graph.nodes(data=True)]\n",
    "    t_ig_graph = ig.Graph.from_networkx(t_graph)\n",
    "    # Adding node information\n",
    "    for idx, (node, attr) in enumerate(nodes):\n",
    "        t_ig_graph.vs[idx][\"name\"] = node\n",
    "        t_ig_graph.vs[idx][\"peptide\"] = attr['peptide']\n",
    "        t_ig_graph.vs[idx][\"raw_index\"] = attr['raw_index']\n",
    "    try:\n",
    "        partition = leidenalg.find_partition(t_ig_graph, leidenalg.ModularityVertexPartition,\n",
    "                                             n_iterations=5, weights='weight')\n",
    "        # print(max(partition.membership))\n",
    "        # print(partition.membership)\n",
    "        q_resdf = []\n",
    "        # Print node attributes with their community assignments\n",
    "        for idx, node in enumerate(t_ig_graph.vs):\n",
    "            # print(f\"Node {node['name']} (peptide: {node['peptide']}) is in community {partition.membership[idx]}\")\n",
    "            q_resdf.append({'node':node['name'], 'label':node['peptide'], 'pred':partition.membership[idx]})\n",
    "        q_resdf=pd.DataFrame(q_resdf)\n",
    "        q_results=[]\n",
    "        for p in q_resdf.pred.unique():\n",
    "            tmp = q_resdf.query('pred==@p')\n",
    "            d=tmp.groupby('label').agg(count=('node','count')).to_dict()['count']\n",
    "            sorted_d={k:v for k,v in sorted(d.items(), key=lambda x: x[1], reverse=True)}\n",
    "            top_label = list(sorted_d.keys())[0]\n",
    "            purity = sorted_d[top_label] / sum(sorted_d.values())\n",
    "            q_results.append({'pred':p, 'label':top_label, 'purity':purity, 'cluster_size':sum(sorted_d.values())})\n",
    "        q_results = pd.DataFrame(q_results).sort_values(['cluster_size','purity'], ascending=False).rename(columns={'label':'majority_label'}).sort_values('majority_label')\n",
    "        try:\n",
    "            silhouette = silhouette_score(values, partition.membership, metric='precomputed')\n",
    "        except:\n",
    "            silhouette = np.nan\n",
    "        # excep\n",
    "        \n",
    "        # print(round(dist_threshold, 3), '\\t---\\t', round(q_results.query('cluster_size>1').purity.mean(), 4), '\\t---\\t', round(q_results.query('cluster_size>1').cluster_size.sum()/len(t_graph),4))\n",
    "        return {'threshold':dist_threshold, \n",
    "                'mean_purity':q_results.query('cluster_size>1').purity.mean(),\n",
    "                'retention':q_results.query('cluster_size>1').cluster_size.sum()/len(values),\n",
    "                'silhouette':silhouette}\n",
    "    except:\n",
    "        return {'threshold':dist_threshold,\n",
    "                'mean_purity':np.nan, 'retention':np.nan, 'silhouette':np.nan}\n",
    "\n",
    "def get_leiden_all(values, dist_matrix, n_points=500, n_jobs=8):\n",
    "    threshold_range = tqdm(np.linspace(values[values!=0].min(), values.max(), n_points), position=0, leave=False)\n",
    "    wrapper = partial(get_leiden_single, values=values, dist_matrix=dist_matrix)\n",
    "    results = Parallel(n_jobs)(delayed(wrapper)(dist_threshold=t) for t in threshold_range)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6b571-7e03-427e-afa8-e88182b633be",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_test = get_leiden_all(values_test, dm_test).assign(dist_matrix='ts128', method='leiden', dataset='8peps', partition='test', fold=1)\n",
    "leiden_valid = get_leiden_all(values_valid, dm_valid).assign(dist_matrix='ts128', method='leiden', dataset='8peps', partition='valid', fold=0)\n",
    "leiden_tbcr_test = get_leiden_all(values_tbcr_test, dm_tbcr_test).assign(dist_matrix='tbcr', method='leiden', dataset='8peps', partition='test', fold=1)\n",
    "leiden_tbcr_valid = get_leiden_all(values_tbcr_valid, dm_tbcr_valid).assign(dist_matrix='tbcr', method='leiden', dataset='8peps', partition='valid', fold=0)\n",
    "leiden_tcrdist_test = get_leiden_all(values_tcrdist_test, dm_tcrdist_test).assign(dist_matrix='tcrdist', method='leiden', dataset='8peps', partition='test', fold=1)\n",
    "leiden_tcrdist_valid = get_leiden_all(values_tcrdist_valid, dm_tcrdist_valid).assign(dist_matrix='tcrdist', method='leiden', dataset='8peps', partition='valid', fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c03a5-950f-4935-8b58-e59f318cb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering = pd.concat([test_clustering, leiden_test, leiden_tbcr_test, leiden_tcrdist_test]).replace({'MST_size_cut':'MST_top1_cut'})\n",
    "valid_clustering = pd.concat([valid_clustering.query('method!=\"leiden\"'), leiden_valid, leiden_tbcr_valid, leiden_tcrdist_valid]).replace({'MST_size_cut':'MST_top1_cut'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf70b1-fda3-466f-a6e1-1769ff87042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd995ef-02c3-4a22-854d-b059f81f172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33650b1-247a-48b2-a827-ec1a8e9f21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering.to_csv('../output/240618_NestedKCV_CNNVAE/240723_test_clustering.csv')\n",
    "valid_clustering.to_csv('../output/240618_NestedKCV_CNNVAE/240723_valid_clustering.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428af88-fc71-419a-879f-a1251cebc6f0",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2abab-5ea1-4707-91f9-d61f4a536759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(10,10))\n",
    "lw=.75\n",
    "marker_size=12\n",
    "for dm, color in zip(['tbcr', 'tcrdist', 'ts128'], ['g', 'y', 'b']):\n",
    "    for method, ls, marker in zip(['agglomerative', 'MST_top1_cut', 'leiden'], ['-', '--', ':'], ['*', 'x', 'o']):\n",
    "        tmp = test_clustering.query('dist_matrix==@dm and method==@method')\n",
    "        max_id = tmp.iloc[tmp['silhouette'].argmax()]\n",
    "        a.plot(tmp['retention'].values[1:-1], tmp['mean_purity'].values[1:-1], ls=ls, lw=lw, c=color, label= f'{dm} - {method}')\n",
    "        a.scatter(max_id['retention'], max_id['mean_purity'], c=color, s=marker_size, marker=marker,\n",
    "                  lw=lw, label=f'Best Silh ; {dm} - {method}')\n",
    "\n",
    "a.legend()\n",
    "a.set_ylim([.5,1.])\n",
    "a.set_xlim([.5,1.])\n",
    "a.set_xlabel('Retention', fontsize=12, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=12, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for test set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting vs Leiden; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/8peps_test_subsampled_WithLeiden_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17022ac-1d16-410c-99a3-2d240e066674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(10,10))\n",
    "lw=.75\n",
    "marker_size=12\n",
    "for dm, color in zip(['tbcr', 'tcrdist', 'ts128'], ['g', 'y', 'b']):\n",
    "    for method, ls, marker in zip(['agglomerative', 'MST_top1_cut', 'leiden'], ['-', '--', ':'], ['*', 'x', 'o']):\n",
    "        tmp = valid_clustering.query('dist_matrix==@dm and method==@method')\n",
    "        max_id = tmp.iloc[tmp['silhouette'].argmax()]\n",
    "        a.plot(tmp['retention'].values[1:-1], tmp['mean_purity'].values[1:-1], ls=ls, lw=lw, c=color, label= f'{dm} - {method}')\n",
    "        a.scatter(max_id['retention'], max_id['mean_purity'], c=color, s=marker_size, marker=marker,\n",
    "                  lw=lw, label=f'Best Silh ; {dm} - {method}')\n",
    "\n",
    "a.legend()\n",
    "a.set_ylim([.5,1.])\n",
    "a.set_xlim([.5,1.])\n",
    "a.set_xlabel('Retention', fontsize=12, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=12, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for valid set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting vs Leiden; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/8peps_valid_subsampled_WithLeiden_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf3c5f-9d70-4b95-823e-a600db299e8e",
   "metadata": {},
   "source": [
    "# After re-reading the various curves, load the No Triplet loss models and re-run the appropriate curves \n",
    "\n",
    "(train, valid, filtered to 8 peps + subsampled, running AggClst, Cuts, Leiden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea58fc8-1b14-48c7-84fd-3e1a51f1ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering = pd.read_csv('../output/240618_NestedKCV_CNNVAE/240723_test_clustering.csv')\n",
    "valid_clustering = pd.read_csv('../output/240618_NestedKCV_CNNVAE/240723_valid_clustering.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f896c2-ec23-42cb-9799-3f978b3ea16a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## valid set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df097903-9b1b-47d4-b1fb-34b8fd09aa7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da614ab4-c8dc-4010-9075-c8e06e908c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "# See TCRBase detour for exp_filt\n",
    "print(exp_filt)\n",
    "df = exp17.query('peptide in @exp_filt and partition==0')\n",
    "testset_subsample = []\n",
    "for p in exp_filt:\n",
    "    tmp = df.query('peptide==@p')\n",
    "    testset_subsample.append(tmp.sample(min(len(tmp), random.randint(70,90)), random_state=seed))\n",
    "df = pd.concat(testset_subsample)\n",
    "df_idx = df['raw_index'].unique()\n",
    "df.groupby('peptide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08d341-aca3-49e1-b464-893bc77b034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model picked on validation performance\n",
    "latent_ts128_notrp = get_latent_df(model_ts128_notrp, df)\n",
    "latent_os128_notrp = get_latent_df(model_os128_notrp, df)\n",
    "dm_ts128_notrp, values_ts128_notrp, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_ts128_notrp, index_col='raw_index')\n",
    "dm_os128_notrp, values_os128_notrp, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os128_notrp, index_col='raw_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb1d75-3616-45c5-9269-cc0e4aff2b79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MST cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19434804-e615-4da0-b043-69ac10b006d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os128_notrp, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os128_notrp, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os128, it_purities_os128, it_rets_os128 = iterative_size_cut(values_os128_notrp, tree, \n",
    "                                                                                                         initial_cut_threshold=1, \n",
    "                                                                                                         initial_cut_method='top', \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os128, sh_purities_os128, sh_rets_os128 = iterative_topn_cut(values_os128_notrp, tree, \n",
    "                                                                                                                    initial_cut_threshold=1, \n",
    "                                                                                                                    initial_cut_method='top', \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98531d0b-4fdd-4323-8626-9c89e2ee97e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_ts128_notrp, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_ts128_notrp, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_ts128, it_purities_ts128, it_rets_ts128 = iterative_size_cut(values_ts128_notrp, tree, \n",
    "                                                                                                         initial_cut_threshold=1, \n",
    "                                                                                                         initial_cut_method='top', \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_ts128, sh_purities_ts128, sh_rets_ts128 = iterative_topn_cut(values_ts128_notrp, tree, \n",
    "                                                                                                                    initial_cut_threshold=1, \n",
    "                                                                                                                    initial_cut_method='top', \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d7fd0-bd68-4bd3-9caa-62bc834d3033",
   "metadata": {},
   "source": [
    "### Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a5eb5-f2f7-4b76-bbde-5beb87710de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiden\n",
    "leiden_ts128_notrp = get_leiden_all(values_ts128_notrp, dm_ts128_notrp).assign(dist_matrix='ts128_notrp', method='leiden', dataset='8peps', partition='valid', fold=0)\n",
    "leiden_os128_notrp = get_leiden_all(values_os128_notrp, dm_os128_notrp).assign(dist_matrix='os128_notrp', method='leiden', dataset='8peps', partition='valid', fold=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abd02e-4d2d-4895-a994-44e89a8aa1af",
   "metadata": {},
   "source": [
    "### Agglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b8adb-fe29-424a-a845-d1075d7c2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts128_cluster_notrp = cluster_all_thresholds(values_ts128_notrp, values_ts128_notrp, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os128_cluster_notrp = cluster_all_thresholds(values_os128_notrp, values_os128_notrp, labels, encoded_labels, label_encoder, n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c53364-882c-43b9-8d6c-be646a3daa3f",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14281a-90c7-4c1d-895e-775eb1835c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clustering = pd.concat([valid_clustering, \n",
    "                              ts128_cluster_notrp.assign(dist_matrix='ts128_notrp', method='agglomerative'), \n",
    "                              os128_cluster_notrp.assign(dist_matrix='os128_notrp', method='agglomerative'),\n",
    "                              pd.DataFrame(np.array([sh_rets_ts128, sh_purities_ts128, sh_scores_ts128]).T, columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='ts128_notrp', method='MST_top1_cut'),\n",
    "                              pd.DataFrame(np.array([sh_rets_os128, sh_purities_os128, sh_scores_os128]).T, columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os128_notrp', method='MST_top1_cut'),\n",
    "                              leiden_ts128_notrp, \n",
    "                              leiden_os128_notrp]).assign(dataset='8peps', partition='valid', fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0656c0f-56e8-4f25-9645-f95898885b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_clustering.groupby(['dist_matrix','method']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c883162-7f37-48c6-b0d8-a02c3e4072e0",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413efd3-3437-4d65-957d-36df3a3dcc23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "# See TCRBase detour for exp_filt\n",
    "print(exp_filt)\n",
    "df = exp17.query('peptide in @exp_filt and partition==1')\n",
    "testset_subsample = []\n",
    "for p in exp_filt:\n",
    "    tmp = df.query('peptide==@p')\n",
    "    testset_subsample.append(tmp.sample(min(len(tmp), random.randint(70,90)), random_state=seed))\n",
    "df = pd.concat(testset_subsample)\n",
    "df_idx = df['raw_index'].unique()\n",
    "df.groupby('peptide').agg(count=('A1','count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b6ceb-8d80-4435-b17e-d48fcd02663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model picked on validation performance\n",
    "latent_ts128_notrp = get_latent_df(model_ts128_notrp, df)\n",
    "latent_os128_notrp = get_latent_df(model_os128_notrp, df)\n",
    "dm_ts128_notrp, values_ts128_notrp, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_ts128_notrp, index_col='raw_index')\n",
    "dm_os128_notrp, values_os128_notrp, feats, labels, enc_labels, lab_enc = get_distances_labels_from_latent(latent_os128_notrp, index_col='raw_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb242a1-0ed7-4ff9-9c7a-993db9335c94",
   "metadata": {},
   "source": [
    "### MST cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42338c-5670-4331-aed7-7b5d64fcf85e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_os128_notrp, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_os128_notrp, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_os128, it_purities_os128, it_rets_os128 = iterative_size_cut(values_os128_notrp, tree, \n",
    "                                                                                                         initial_cut_threshold=1, \n",
    "                                                                                                         initial_cut_method='top', \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_os128, sh_purities_os128, sh_rets_os128 = iterative_topn_cut(values_os128_notrp, tree, \n",
    "                                                                                                                    initial_cut_threshold=1, \n",
    "                                                                                                                    initial_cut_method='top', \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f3b8f-050c-45cf-930e-62284272c46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G, tree, dist_matrix, values_ts128_notrp, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(dm_ts128_notrp, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "tree_cut, subgraphs, size_clusters, edges_cut, nodes_cut, it_scores_ts128, it_purities_ts128, it_rets_ts128 = iterative_size_cut(values_ts128_notrp, tree, \n",
    "                                                                                                         initial_cut_threshold=1, \n",
    "                                                                                                         initial_cut_method='top', \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "tree_cut, subgraphs, topn_clusters, edges_removed, nodes_removed, sh_scores_ts128, sh_purities_ts128, sh_rets_ts128 = iterative_topn_cut(values_ts128_notrp, tree, \n",
    "                                                                                                                    initial_cut_threshold=1, \n",
    "                                                                                                                    initial_cut_method='top', \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in topn_clusters]), np.mean([x['cluster_size'] for x in size_clusters]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c7c41-f092-454d-8105-687e54a1c719",
   "metadata": {},
   "source": [
    "### Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4eb5eb-2f4c-476e-b37c-a6c258a1d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiden\n",
    "leiden_ts128_notrp = get_leiden_all(values_ts128_notrp, dm_ts128_notrp).assign(dist_matrix='ts128_notrp', method='leiden', dataset='8peps', partition='test', fold=1)\n",
    "leiden_os128_notrp = get_leiden_all(values_os128_notrp, dm_os128_notrp).assign(dist_matrix='os128_notrp', method='leiden', dataset='8peps', partition='test', fold=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a158449-b27c-49aa-9978-7cb8c3868c4c",
   "metadata": {},
   "source": [
    "### Agglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c320b6-5ebe-4f9d-90ed-902f33c6e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts128_cluster_notrp = cluster_all_thresholds(values_ts128_notrp, values_ts128_notrp, labels, encoded_labels, label_encoder, n_jobs=8)\n",
    "os128_cluster_notrp = cluster_all_thresholds(values_os128_notrp, values_os128_notrp, labels, encoded_labels, label_encoder, n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bececce-d2a8-46f9-a42c-3728db48d028",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ea95f-74eb-4289-8446-3c9a239b1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering = pd.concat([test_clustering, \n",
    "                              ts128_cluster_notrp.assign(dist_matrix='ts128_notrp', method='agglomerative'), \n",
    "                              os128_cluster_notrp.assign(dist_matrix='os128_notrp', method='agglomerative'),\n",
    "                              pd.DataFrame(np.array([sh_rets_ts128, sh_purities_ts128, sh_scores_ts128]).T, columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='ts128_notrp', method='MST_top1_cut'),\n",
    "                              pd.DataFrame(np.array([sh_rets_os128, sh_purities_os128, sh_scores_os128]).T, columns = ['retention', 'mean_purity', 'silhouette']).assign(dist_matrix='os128_notrp', method='MST_top1_cut'),\n",
    "                              leiden_ts128_notrp, \n",
    "                              leiden_os128_notrp]).assign(dataset='8peps', partition='test', fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa65fb-bc44-43e7-8d10-bd918bdfe1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering.groupby(['dist_matrix','method']).agg(count=('retention','count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2735ca-50ff-4af5-8bc3-da3ef122a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering.to_csv('../output/240618_NestedKCV_CNNVAE/240801_8peps_subsampled_test_clustering_with_notrp.csv')\n",
    "valid_clustering.to_csv('../output/240618_NestedKCV_CNNVAE/240801_8peps_subsampled_valid_clustering_with_notrp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c5c5a-d870-4ff6-8051-8e738f628c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(15.5,15.5))\n",
    "lw=.85\n",
    "marker_size=14\n",
    "for dm, color in zip(['tbcr', 'tcrdist', 'ts128', 'ts128_notrp', 'os128_notrp'], ['g', 'y', 'b', 'r', 'c']):\n",
    "    for method, ls, marker in zip(['agglomerative', 'MST_top1_cut'],#, 'leiden'], \n",
    "                                  [':', '-.'],#, ':'], \n",
    "                                  ['*', 'x']):#, 'o']):\n",
    "        tmp = test_clustering.query('dist_matrix==@dm and method==@method')\n",
    "        max_id = tmp.iloc[tmp['silhouette'].argmax()]\n",
    "        a.plot(tmp['retention'].values[1:-1], tmp['mean_purity'].values[1:-1], ls=ls, lw=lw, c=color, label= f'{dm} - {method}')\n",
    "        a.scatter(max_id['retention'], max_id['mean_purity'], c=color, s=marker_size, marker=marker,\n",
    "                  lw=lw, label=f'Best Silh ; {dm} - {method}')\n",
    "\n",
    "a.legend(prop={'weight':'semibold','size':14})\n",
    "a.set_ylim([0,1.])\n",
    "a.set_xlim([0,1.])\n",
    "a.set_xlabel('Retention', fontsize=14, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=14, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for test set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting vs Leiden; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/240802_8peps_test_subsampled_NoLeiden_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4620366-0512-422a-a97d-22cfa0e5eb46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,1, figsize=(15.5,15.5))\n",
    "lw=.85\n",
    "marker_size=14\n",
    "for dm, color in zip(['tbcr', 'tcrdist', 'ts128', 'ts128_notrp', 'os128_notrp'], ['g', 'y', 'b', 'r', 'c']):\n",
    "    for method, ls, marker in zip(['agglomerative', 'MST_top1_cut'],#'leiden'], \n",
    "                                  [':', '-.'],#':'], \n",
    "                                  ['*', 'x']):#'o']):\n",
    "        tmp = valid_clustering.query('dist_matrix==@dm and method==@method')\n",
    "        max_id = tmp.iloc[tmp['silhouette'].argmax()]\n",
    "        a.plot(tmp['retention'].values[1:-1], tmp['mean_purity'].values[1:-1], ls=ls, lw=lw, c=color, label= f'{dm} - {method}')\n",
    "        a.scatter(max_id['retention'], max_id['mean_purity'], c=color, s=marker_size, marker=marker,\n",
    "                  lw=lw, label=f'Best Silh ; {dm} - {method}')\n",
    "\n",
    "a.legend(prop={'weight':'semibold','size':14})\n",
    "a.set_ylim([0,1.])\n",
    "a.set_xlim([0,1.])\n",
    "a.set_xlabel('Retention', fontsize=14, fontweight='semibold')\n",
    "a.set_ylabel('Mean purity', fontsize=14, fontweight='semibold')\n",
    "a.set_title('Purity Retention curves for valid set, Filtered (8peps) and subsampled\\n Agglomerative vs MST cutting vs Leiden; Retention/Purity range : (0.5-1.0)', fontweight='semibold', fontsize=14)\n",
    "f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/240802_8peps_valid_subsampled_NoLeiden_retpur_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64bd8e-6743-449c-807f-92f1b7513493",
   "metadata": {},
   "source": [
    "# Check silhouette / MST cut with fake perfect or noisy distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca0695-a8fc-4034-b639-8a84511ed05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4346bdf-6b27-493c-ab83-96ed42f95c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do 400 datapoints and 5 classes with slightly different sizes\n",
    "fake_labels = np.array([0]*75+[1]*60+[2]*70+[3]*115+[4]*80)\n",
    "# Perf matrix is a binary matrix\n",
    "perf_values = np.ones((400, 400))\n",
    "# Noisy matrix simulates a distance matrix\n",
    "noisy_values = np.ones((400, 400)) * np.random.uniform(low=0.9, high=1.25, size=(400,400))\n",
    "new_values = copy.deepcopy(noisy_values)\n",
    "\n",
    "for label in range(5):\n",
    "    idxs = np.where(fake_labels==label)[0]\n",
    "    size = idxs[-1]-idxs[0] +1\n",
    "    for matrix in [perf_values, noisy_values]:\n",
    "        perf_values[idxs[0]:idxs[-1]+1, idxs[0]:idxs[-1]+1] = 0.05\n",
    "    \n",
    "        noisy_values[idxs[0]:idxs[-1]+1, idxs[0]:idxs[-1]+1] = np.clip(np.random.normal(0.15, 0.1, size =(size,size)), 0.02575, 1)\n",
    "        noisy_values = np.clip(noisy_values, 0,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a81d5-f537-448f-bd1a-d1cac06c02ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# Create one more matrix which is \"kinda\" connected between the classes\n",
    "fake_labels = np.array([0]*75+[1]*60+[2]*70+[3]*115+[4]*80)\n",
    "new_values = copy.deepcopy(noisy_values)\n",
    "# Use the perfect matrix as an indexing mask\n",
    "a,b = np.where(perf_values!=0.05)\n",
    "new_values[a, b] = np.clip(np.random.normal(0.25, 0.15, size=new_values[a,b].shape), 0.08, 0.7)\n",
    "new_values = np.clip(new_values, a_min=-1.5, a_max=1.5)\n",
    "new_values = (new_values * (1-np.eye(400,400))).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927b9b2-47e4-490a-b87e-a20d340bf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(new_values, 0)\n",
    "np.fill_diagonal(noisy_values, 0)\n",
    "np.fill_diagonal(perf_values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3bb8f-07a5-4259-97a9-78a649208c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {k:v for k,v in zip(range(5), ['pep_a', 'pep_b', 'pep_c', 'pep_d', 'pep_e'])}\n",
    "columns = [f'{mapping[x]}_{i}' for i,x in enumerate(fake_labels)]\n",
    "noisy_matrix = pd.DataFrame(noisy_values, columns = columns, index=columns)\n",
    "noisy_matrix['peptide'] = [mapping[x] for x in fake_labels]\n",
    "noisy_matrix['raw_index'] = [f'seq_{i}' for i in range(len(noisy_matrix))]\n",
    "perf_matrix = pd.DataFrame(perf_values, columns = columns, index=columns)\n",
    "perf_matrix['peptide'] = [mapping[x] for x in fake_labels]\n",
    "perf_matrix['raw_index'] = [f'seq_{i}' for i in range(len(perf_matrix))]\n",
    "new_matrix = pd.DataFrame(new_values, columns = columns, index=columns)\n",
    "new_matrix['peptide'] = [mapping[x] for x in fake_labels]\n",
    "new_matrix['raw_index'] = [f'seq_{i}' for i in range(len(new_matrix))]\n",
    "f,ax=plt.subplots(1,3, figsize=(22,6))\n",
    "ax = ax.ravel()\n",
    "sns.heatmap(perf_values,ax=ax[0],  square=True, xticklabels=False, yticklabels=False)\n",
    "ax[0].set_title('perf_values')\n",
    "sns.heatmap(noisy_values, ax=ax[1], square=True, vmax=1.5, vmin=0, xticklabels=False, yticklabels=False)\n",
    "ax[1].set_title('noisy_values')\n",
    "sns.heatmap(new_values, ax=ax[2], square=True, vmax=1.5, vmin=0, xticklabels=False, yticklabels=False)\n",
    "ax[2].set_title('noisier_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa017e1-3cbf-44be-9e10-c3c60239c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(fake_labels)\n",
    "perf_values = perf_matrix.iloc[:len(perf_matrix), :len(perf_matrix)].values\n",
    "noisy_values = noisy_matrix.iloc[:len(noisy_matrix), :len(noisy_matrix)].values\n",
    "initial_cut_threshold=1\n",
    "initial_cut_method='top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333d6ae-f8fe-4cd0-a39c-6f83bb910f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G_perf, tree_perf, perf_matrix, perf_values, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(perf_matrix, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "size_tree_cut_perf, size_subgraphs_perf, size_clusters_perf, \\\n",
    "size_edges_cut_perf, size_nodes_cut_perf, size_scores_perf, size_purities_perf, size_rets_perf = iterative_size_cut(perf_values, tree_perf, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "top1_tree_cut_perf, top1_subgraphs_perf, top1_clusters_perf, \\\n",
    "    top1_edges_cut_perf, top1_nodes_cut_perf, top1_scores_perf, top1_purities_perf, top1_rets_perf = iterative_topn_cut(perf_values, tree_perf, \n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in top1_clusters_perf]), np.mean([x['cluster_size'] for x in size_clusters_perf]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ae68a-0dab-482b-b989-fbb92514103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G_noisy, tree_noisy, noisy_matrix, noisy_values, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(noisy_matrix, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "size_tree_cut_noisy, size_subgraphs_noisy, size_clusters_noisy, size_edges_cut_noisy,\\\n",
    "        size_nodes_cut_noisy, size_scores_noisy, size_purities_noisy, size_rets_noisy = iterative_size_cut(noisy_values, tree_noisy, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "top1_tree_cut_noisy, top1_subgraphs_noisy, top1_clusters_noisy, \\\n",
    "    top1_edges_cut_noisy, top1_nodes_cut_noisy, top1_scores_noisy, top1_purities_noisy, top1_rets_noisy = iterative_topn_cut(noisy_values, tree_noisy,\n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in top1_clusters_noisy]), np.mean([x['cluster_size'] for x in size_clusters_noisy]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158e97d-1b06-4577-9075-874c452f4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-Stage 128\n",
    "# Same starting point as usual : Create a graph, mst, then prune it by distance (that might or might not just be useless)\n",
    "G_new, tree_new, new_matrix, new_values, labels, encoded_labels, label_encoder, raw_indices = create_mst_from_distance_matrix(new_matrix, label_col='peptide',\n",
    "                                                                                                                   index_col='raw_index', algorithm='kruskal')\n",
    "# NO INITIAL PRUNING\n",
    "size_tree_cut_new, size_subgraphs_new, size_clusters_new, size_edges_cut_new,\\\n",
    "        size_nodes_cut_new, size_scores_new, size_purities_new, size_rets_new = iterative_size_cut(new_values, tree_new, \n",
    "                                                                                                         initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                         initial_cut_method=initial_cut_method, \n",
    "                                                                        top_n=1, which='edge', weighted=True, verbose=0, max_size=4)\n",
    "\n",
    "top1_tree_cut_new, top1_subgraphs_new, top1_clusters_new, \\\n",
    "    top1_edges_cut_new, top1_nodes_cut_new, top1_scores_new, top1_purities_new, top1_rets_new = iterative_topn_cut(new_values, tree_new,\n",
    "                                                                                                                    initial_cut_threshold=initial_cut_threshold, \n",
    "                                                                                                                    initial_cut_method=initial_cut_method, \n",
    "                                                                                                                    top_n=1, which='edge', weighted=True, \n",
    "                                                                                                                    verbose=0, score_threshold=.5)\n",
    "print(np.mean([x['cluster_size'] for x in top1_clusters_new]), np.mean([x['cluster_size'] for x in size_clusters_new]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da9db8-5704-4a41-baf3-399d1f25549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top1_clusters_perf), len(top1_clusters_new), len(top1_clusters_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df70b09-17a9-44ad-9c18-dc66fcc88ef4",
   "metadata": {},
   "source": [
    "# random detour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00671a8-0818-4870-8522-d990fc0f2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "num_pca=64\n",
    "pca = PCA(n_components=num_pca)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(latent_ts128['peptide'].values)\n",
    "vals = latent_ts128_notrp[[z for z in latent_ts128_notrp.columns if z.startswith('z_')]].values\n",
    "pca_vals = pca.fit_transform(vals)\n",
    "\n",
    "exp_var = sum(pca.explained_variance_ratio_)\n",
    "print(f'{exp_var} of variance is captured in {num_pca} PCs.')\n",
    "print(pca.explained_variance_ratio_[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c770c4c-eec0-4590-99b2-a8758e51f17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_dims = (7, 6)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sc = ax.scatter(pca_vals[:,0], pca_vals[:,1], c=labels, marker='.')\n",
    "ax.set_xlabel('PCA first principal component')\n",
    "ax.set_ylabel('PCA second principal component')\n",
    "plt.colorbar(sc, label='peplabel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b86ad9-33f4-4da7-8c61-14d70da293c4",
   "metadata": {},
   "source": [
    "## pruned heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3087e-f3d1-45bb-9cb5-241a4263d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dm(dm, cols=('peptide','partition','binder','origin','raw_index','original_peptide')):\n",
    "    return dm.sort_values('peptide', ascending=True)[list(dm.sort_values('peptide',ascending=True).index)+list(cols)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d0e7d-8b73-4768-8da6-af337a8caa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dm_ts128 = sort_dm(dm_ts128)\n",
    "sorted_values_ts128 = sorted_dm_ts128.iloc[:len(sorted_dm_ts128), :len(sorted_dm_ts128)].values\n",
    "sorted_dm_os128 = sort_dm(dm_os128)\n",
    "sorted_values_os128 = sorted_dm_os128.iloc[:len(sorted_dm_os128), :len(sorted_dm_os128)].values\n",
    "sorted_dm_os256 = sort_dm(dm_os256)\n",
    "sorted_values_os256 = sorted_dm_os256.iloc[:len(sorted_dm_os256), :len(sorted_dm_os256)].values\n",
    "sorted_dm_tbcr_testset, sorted_values_tbcr_testset = resort_baseline(dm_tbcr_testset, sorted_dm_ts128, 'raw_index')\n",
    "sorted_dm_tcrdist_testset, sorted_values_tcrdist_testset = resort_baseline(dm_tcrdist_testset, sorted_dm_ts128, 'raw_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d1f89-a134-421c-9f74-5f9dbb126ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dm_ts128_notrp = sort_dm(dm_ts128_notrp)\n",
    "sorted_values_ts128_notrp = sorted_dm_ts128_notrp.iloc[:len(sorted_dm_ts128_notrp), :len(sorted_dm_ts128_notrp)].values\n",
    "\n",
    "sorted_dm_os128_notrp = sort_dm(dm_os128_notrp)\n",
    "sorted_values_os128_notrp = sorted_dm_os128_notrp.iloc[:len(sorted_dm_ts128_notrp), :len(sorted_dm_ts128_notrp)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde611d-22cd-47b1-ba80-dd6ac9a8f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pepmap = sorted_dm_ts128_notrp.groupby('peptide').agg(count=('raw_index','count'))\n",
    "pepmap['idx']=pepmap['count'].cumsum()\n",
    "pepmap['tick']=pepmap['idx']-pepmap['count'].iloc[0]+3\n",
    "tickmarks = pepmap['tick'].to_dict() \n",
    "idxs = pepmap['idx'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf26511-c772-44f8-8e7c-24157bc0fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(sorted_values_ts128_notrp[sorted_values_ts128_notrp!=0], q=[.1,.2,.3,.4,.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d4c90d-a0d6-4289-86e7-46f08c8ee3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8  # Total characters including decimal point\n",
    "float_number = 12.34\n",
    "formatted_number = f\"{float_number:0<{N}}\"\n",
    "print(formatted_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb30d4c-fb19-46f0-bee3-d1561ffc3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prune_heatmap(values, threshold, title, \n",
    "                       filename='delete',\n",
    "                       sorted_dm=sorted_dm_ts128_notrp,\n",
    "                       cmap='icefire', color='g', addline=True):\n",
    "    #plotline stuff\n",
    "    pepmap = sorted_dm.groupby('peptide').agg(count=('raw_index','count'))\n",
    "    pepmap['idx']=pepmap['count'].cumsum()\n",
    "    pepmap['tick']=pepmap['idx']-pepmap['count'].iloc[0]+3\n",
    "    tickmarks = pepmap['tick'].to_dict() \n",
    "    idxs = pepmap['idx'].to_dict()\n",
    "    \n",
    "    f,ax = plt.subplots(1,2, figsize=(16,16), width_ratios=(16.5/17, 0.5/17))\n",
    "    ax = ax.ravel()\n",
    "    ax, cbar_ax = ax[0], ax[1]\n",
    "    pruned = values.copy()\n",
    "    mask = (pruned<=threshold).astype(int)\n",
    "    pruned = pruned * mask\n",
    "    sns.heatmap(pruned, ax=ax, square=True, vmin=0, vmax=threshold, cbar_ax=cbar_ax, cmap=cmap)\n",
    "    ax.set_xticks(list(tickmarks.values()))\n",
    "    ax.set_yticks(list(tickmarks.values()))\n",
    "    ax.set_xticklabels(list(tickmarks.keys()), ha='center', fontweight='semibold', fontsize=15)\n",
    "    ax.set_yticklabels(list(tickmarks.keys()), va='center', fontweight='semibold', fontsize=15)\n",
    "    if addline:\n",
    "        for k,v in idxs.items():\n",
    "            ax.axhline(v, ls='--', lw=.9, c=color)\n",
    "            ax.axvline(v, ls='--', lw=.9, c=color)\n",
    "    # Rotate the tick labels for better readability (optional)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.set_title(title, fontweight='semibold', fontsize=17)\n",
    "    f.tight_layout()\n",
    "    f.savefig(f'../output/240618_NestedKCV_CNNVAE/notebook_figs/heatmaps/{filename}.png', dpi=150, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d38d8c-3a9f-49e7-9e3c-a587041491ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary as model_summary\n",
    "pprint(model_summary(model_ts128))\n",
    "pprint(model_summary(model_os128))\n",
    "pprint(model_summary(model_os256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ca518-9aa2-4efc-8b6e-dc217608f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vals, title in zip([sorted_values_ts128, sorted_values_os128,\n",
    "                        sorted_values_os256, sorted_values_tbcr_testset,\n",
    "                        sorted_values_tcrdist_testset, \n",
    "                        sorted_values_ts128_notrp, sorted_values_os128_notrp],\n",
    "                       ['TS128 CosTrp ', 'OS128 CosTrp',\n",
    "                        'OS256 CosTrp', 'TBCRalign', 'tcrdist3',\n",
    "                        'TS128 NoTRP', 'OS128 NoTrp']):\n",
    "\n",
    "    for q in np.arange(0.025, 0.4, 0.025):\n",
    "        threshold = np.quantile(vals, q=q)\n",
    "        t = title + f' quantile {round(q,4):0<5}'.replace('.','')\n",
    "        plot_prune_heatmap(vals, threshold, t, filename=t.replace(' ','_'),\n",
    "                            addline=True, cmap='vlag', color='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b73f0-7c22-464e-9675-ece102ce69fa",
   "metadata": {},
   "source": [
    "# immrep 2023 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163491b-bd5b-4b56-a778-4f286ded3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/immrep/immrep2023_test.csv')\n",
    "test_df['rem_B3'] = test_df['CDR3b_extended'].str.replace(test_df['CDR3b'].str,'')\n",
    "test_df['rem_B3'] = test_df.apply(lambda row: row['CDR3b_extended'].replace(row['CDR3b'], ''), axis=1)\n",
    "test_df['rem_A3'] = test_df.apply(lambda row: row['CDR3a_extended'].replace(row['CDR3a'], ''), axis=1)\n",
    "test_df['rem_A3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62300fec-2fe2-4092-8b3e-07c460f9a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby('Peptide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb55f4f-f2a6-45d0-896b-98a281d70a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['rem_B3'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
