{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd969b6c-2f24-4fa0-b6ec-e85fb8ae1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABWCAYAAACHBmuvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAABuvAAAbrwFeGpEcAAAEdElEQVR4nO2azStsfxzHX2PGnSLytPA8kzykRkixtFEof4GEIqUoGzsrayvGZjILG3lYiJKFIiULC5ntlIdhPOVhUGaI4bfQmXvdezHf2/ccnV/f12oWn+Z9evU9M99zvm/L6+vrK4q4SPjuCzATSpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYAhsmanp6mrKyMubk5oyKlY9PjSyORCBMTEywtLREMBrHb7UQiET2iDEX6ygqHw3R0dOB2uwkGg+Tm5nJ/f080GgVgdXVVdqRhSJc1PDyMz+ejrKyM1tZWgsEgv56JrK6usrm5KTvWEKTKOjw8ZHFxEYvFwvX1NZOTkwAMDAyQl5cXmxsbG5MZaxhSZS0sLBCNRikuLubi4oKqqipmZ2fp7e19N7e9vc3JyYnMaEOQKmtnZweA6upqPB4PMzMzuFyudzNpaWkAbG1tyYw2BKmyAoEAABUVFdTX1/91RpN1cHAgM9oQpMq6uroCICMj48OZpKQkAEKhkMxoQ5Aq6+HhAYAfP358OGOz2d7NmgmpsqxWKwAWi+Xr4ATzPWlJvWLtFnt8fPxw5vn5GQC73S4z2hCkykpPTwfg5ubmw5lwOAxAZmamzGhDkCqrqKgIgGAw+OGM9sPudDplRhuCVFmVlZXAz/3W37i9vQXe9mJmQ6qspqYm4G3Dube39+FcbW0t+fn5MqMNQaosp9NJS0sL0WiU/v7+2CYVfv5WAX88/pgFi+yaZCgUor29Hb/fj9VqpbS0lLu7O46PjwFoaGhgfHxcZqRhSJcFb6vI6/WyvLzM0dERNpsNl8tFW1sbjY2NsuMMQxdZ/1fMt43+RpQsAZQsAZQsAZQsAZQsAZQsAZQsAUwpKxKJMDY2RlNTEy6Xi7q6Orq6ulhfX9e1U6FL10FPwuEwnZ2d+Hw+EhMTKSkp4ebmho2NDTY2NkhMTNQt23QrS6sHlJeXs7Kywvz8PGtra/T09ADw9PSkW7apVpZWD0hISGBkZIScnBweHx/xeDx4vV7d8021srR6QFVVFcXFxQQCARobG3G73QB0d3fHZj87B/hXTCVLe11dU1MDwNnZGaenp7FOxeDgYOw4bn9/X3q+qW5D7c1rYWEhANnZ2Xg8nndVAavVSjQa5fLyUnq+qWT9Xg9wOBw4HI53M9rh7a+vsWVhqtswnnqAdhqux7+iqWSJ1APimRHFVLLiqQdob8n12JyaSlY89YCXlxcAkpOTpeebSlY89QCtFZ2VlSU931SyvqoHnJ+fx2QVFBRIzzeVrK/qAVNTU7HPn7UP/xVTyfqsHrCwsMDExISu+abalAIMDQ3h9/vx+/00Nzf/UQ9ITU3l7u5Ol2xTrSx4+0ecmZmhr68Pp9PJ7u4uoVCI2tpaRkdHSUlJ0S1bHd8LYLqV9Z0oWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQL8B+8Ugojtu0b4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1.8x1.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime as dt\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import BL62_VALUES, BL62FREQ_VALUES, HLAS, AA_KEYS\n",
    "from src.utils import pkl_load, pkl_dump, get_palette\n",
    "from src.torch_utils import save_checkpoint, load_checkpoint\n",
    "from src.train_eval import predict_model, train_eval_loops\n",
    "from src.models import CDR3bVAE, PairedFVAE\n",
    "from src.metrics import reconstruction_accuracy, VAELoss, PairedVAELoss\n",
    "from src.datasets import CDR3BetaDataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "mpl.rcParams['figure.dpi'] = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9879959e-927a-4b68-9b23-b56b82c14d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>binder</th>\n",
       "      <th>peptide</th>\n",
       "      <th>original_peptide</th>\n",
       "      <th>TRAV</th>\n",
       "      <th>...</th>\n",
       "      <th>TRBJ</th>\n",
       "      <th>partition</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>allele</th>\n",
       "      <th>origin</th>\n",
       "      <th>original_index</th>\n",
       "      <th>TRBV_gene</th>\n",
       "      <th>TRBJ_gene</th>\n",
       "      <th>TRA_CDR3</th>\n",
       "      <th>TRB_CDR3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KALYS</td>\n",
       "      <td>LLKGGEQ</td>\n",
       "      <td>GTEIGGGTSYGKLT</td>\n",
       "      <td>MNHEY</td>\n",
       "      <td>SMNVEV</td>\n",
       "      <td>ASGTETQY</td>\n",
       "      <td>1</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>TRAV30*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-5*01</td>\n",
       "      <td>2</td>\n",
       "      <td>32208.0</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>TRBV27</td>\n",
       "      <td>TRBJ2-5</td>\n",
       "      <td>CGTEIGGGTSYGKLTF</td>\n",
       "      <td>CASGTETQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRGSQS</td>\n",
       "      <td>IYSNGD</td>\n",
       "      <td>AVNPANARLM</td>\n",
       "      <td>DFQATT</td>\n",
       "      <td>SNEGSKA</td>\n",
       "      <td>SARWGGGTDTQY</td>\n",
       "      <td>1</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-3*01</td>\n",
       "      <td>3</td>\n",
       "      <td>37123.0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>3820.0</td>\n",
       "      <td>TRBV20-1</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>CAVNPANARLMF</td>\n",
       "      <td>CSARWGGGTDTQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSGFNG</td>\n",
       "      <td>NVLDGL</td>\n",
       "      <td>AVGDDKII</td>\n",
       "      <td>DFQATT</td>\n",
       "      <td>SNEGSKA</td>\n",
       "      <td>SARGLDRGTNEQY</td>\n",
       "      <td>1</td>\n",
       "      <td>AVFDRKSDAK</td>\n",
       "      <td>AVFDRKSDAK</td>\n",
       "      <td>TRAV1-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>3</td>\n",
       "      <td>14961.0</td>\n",
       "      <td>HLA-A*11:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>TRBV20-1</td>\n",
       "      <td>TRBJ2-7</td>\n",
       "      <td>CAVGDDKIIF</td>\n",
       "      <td>CSARGLDRGTNEQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRGSQS</td>\n",
       "      <td>IYSNGD</td>\n",
       "      <td>AVTPGTYKYI</td>\n",
       "      <td>LGHDT</td>\n",
       "      <td>YNNKEL</td>\n",
       "      <td>ASSPGTSIFVAEQY</td>\n",
       "      <td>1</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>0</td>\n",
       "      <td>8197.0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>5933.0</td>\n",
       "      <td>TRBV3-1</td>\n",
       "      <td>TRBJ2-7</td>\n",
       "      <td>CAVTPGTYKYIF</td>\n",
       "      <td>CASSPGTSIFVAEQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRDTTYY</td>\n",
       "      <td>RNSFDEQN</td>\n",
       "      <td>AFLYNQGGKLI</td>\n",
       "      <td>SGHDY</td>\n",
       "      <td>FNNNVP</td>\n",
       "      <td>ASSPGSRGNIQY</td>\n",
       "      <td>1</td>\n",
       "      <td>RAKFKQLL</td>\n",
       "      <td>RAKFKQLL</td>\n",
       "      <td>TRAV19*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-4*01</td>\n",
       "      <td>1</td>\n",
       "      <td>23616.0</td>\n",
       "      <td>HLA-B*08:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>TRBV12-4</td>\n",
       "      <td>TRBJ2-4</td>\n",
       "      <td>CAFLYNQGGKLIF</td>\n",
       "      <td>CASSPGSRGNIQYF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A1        A2              A3      B1       B2              B3  binder  \\\n",
       "0    KALYS   LLKGGEQ  GTEIGGGTSYGKLT   MNHEY   SMNVEV        ASGTETQY       1   \n",
       "1   DRGSQS    IYSNGD      AVNPANARLM  DFQATT  SNEGSKA    SARWGGGTDTQY       1   \n",
       "2   TSGFNG    NVLDGL        AVGDDKII  DFQATT  SNEGSKA   SARGLDRGTNEQY       1   \n",
       "3   DRGSQS    IYSNGD      AVTPGTYKYI   LGHDT   YNNKEL  ASSPGTSIFVAEQY       1   \n",
       "4  TRDTTYY  RNSFDEQN     AFLYNQGGKLI   SGHDY   FNNNVP    ASSPGSRGNIQY       1   \n",
       "\n",
       "      peptide original_peptide         TRAV  ...        TRBJ partition  \\\n",
       "0   KLGGALQAK        KLGGALQAK    TRAV30*01  ...  TRBJ2-5*01         2   \n",
       "1  ELAGIGILTV       ELAGIGILTV  TRAV12-2*01  ...  TRBJ2-3*01         3   \n",
       "2  AVFDRKSDAK       AVFDRKSDAK   TRAV1-2*01  ...  TRBJ2-7*01         3   \n",
       "3  ELAGIGILTV       ELAGIGILTV  TRAV12-2*01  ...  TRBJ2-7*01         0   \n",
       "4    RAKFKQLL         RAKFKQLL    TRAV19*01  ...  TRBJ2-4*01         1   \n",
       "\n",
       "  Unnamed: 0       allele  origin original_index TRBV_gene  TRBJ_gene  \\\n",
       "0    32208.0  HLA-A*03:01     10x         2627.0    TRBV27    TRBJ2-5   \n",
       "1    37123.0  HLA-A*02:01     10x         3820.0  TRBV20-1    TRBJ2-3   \n",
       "2    14961.0  HLA-A*11:01     10x         3592.0  TRBV20-1    TRBJ2-7   \n",
       "3     8197.0  HLA-A*02:01     10x         5933.0   TRBV3-1    TRBJ2-7   \n",
       "4    23616.0  HLA-B*08:01     10x         2745.0  TRBV12-4    TRBJ2-4   \n",
       "\n",
       "           TRA_CDR3          TRB_CDR3  \n",
       "0  CGTEIGGGTSYGKLTF        CASGTETQYF  \n",
       "1      CAVNPANARLMF    CSARWGGGTDTQYF  \n",
       "2        CAVGDDKIIF   CSARGLDRGTNEQYF  \n",
       "3      CAVTPGTYKYIF  CASSPGTSIFVAEQYF  \n",
       "4     CAFLYNQGGKLIF    CASSPGSRGNIQYF  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/filtered/230927_nettcr_positives_only.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab3dceb-4eb5-4206-b1c3-d14616ceed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TRB_CDR3'].apply(len).max(), df['TRA_CDR3'].apply(len).max(), df['peptide'].apply(len).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d631f-4fd3-493c-8676-084c9143fedd",
   "metadata": {},
   "source": [
    "# paired model / datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3224ac7c-463f-43ed-8146-6c69d986388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import PairedFVAE\n",
    "from src.datasets import PairedDataset\n",
    "from torch.utils.data import SequentialSampler\n",
    "sample = df.sample(3)\n",
    "dataset = PairedDataset(sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(5, SequentialSampler)\n",
    "model = PairedFVAE(max_len_b=23, max_len_a=25, max_len_pep=12, use_a=True, use_b=True, use_pep=True, use_v=False, use_j=False, hidden_dim=10, latent_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4757a279-14c0-40c9-9fa5-df33867a22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the slicing etc works\n",
    "x_true = dataset.x\n",
    "x_hat, mu, logvar = model(x_true)\n",
    "seq_hat, v_hat, j_hat = model.reconstruct_hat(x_hat)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d4fbf6dc-f60c-474b-a102-17b99c994455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  0, 16, 16, 16, 16],\n",
       "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  0, 16, 16, 16, 16],\n",
       "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "125b47ae-c425-49eb-9969-69af6fd44302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.082269087433815, 0, 0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import reconstruction_accuracy\n",
    "reconstruction_accuracy(seq_true, seq_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "207ca046-cc3d-4fff-90b6-55df18931cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=(seq_true!=20).float()\n",
    "true_lens=mask.sum(dim=1)\n",
    "((seq_true==seq_hat).float() * mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba59461b-bb23-4a8c-b0ef-a54912453eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSASDNMVGAYEQYF\n",
      "CSAEDNMIGANEQYF\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import AA_KEYS\n",
    "from random import randint\n",
    "\n",
    "def apply_mutation(seq, n):\n",
    "    seq = list(seq)  # Convert the sequence to a list of characters\n",
    "    prev_idx = None\n",
    "    idx = prev_idx\n",
    "    for _ in range(n):\n",
    "        while idx == prev_idx:\n",
    "            idx = randint(0, len(seq) - 1)\n",
    "        letter = seq[idx]\n",
    "        while letter == seq[idx]:\n",
    "            letter = AA_KEYS[randint(0, len(AA_KEYS) - 1)]\n",
    "        seq[idx] = letter\n",
    "        prev_idx = idx\n",
    "\n",
    "    return ''.join(seq)  # Convert the list of characters back to a string\n",
    "\n",
    "seq = 'CSASDNMVGAYEQYF'\n",
    "mutated_seq = apply_mutation(seq, 3)\n",
    "print(seq)\n",
    "print(mutated_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a260aff9-e1df-424e-8577-13c18d0e0b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6213971972465515, 0, 0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Doing a fake dataset with small mutations and check the reconstruction accuracy\n",
    "false_sample = sample.copy()\n",
    "false_sample['TRB_CDR3'] = false_sample['TRB_CDR3'].apply(apply_mutation, n=6)\n",
    "false_sample['TRA_CDR3'] = false_sample['TRA_CDR3'].apply(apply_mutation, n=7)\n",
    "false_sample['peptide'] = false_sample['peptide'].apply(apply_mutation, n=2)\n",
    "dataset = PairedDataset(sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(5, SequentialSampler)\n",
    "false_dataset = PairedDataset(false_sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "x_true = dataset.x\n",
    "x_hat = false_dataset.x\n",
    "\n",
    "seq_hat, v_hat, j_hat = model.reconstruct_hat(x_hat)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "reconstruction_accuracy(seq_true, seq_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69aecd0d-5a22-4a20-9461-277c5c420f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairedFVAE(23,25,12,use_pep=True, use_v=False, use_j=False)\n",
    "x_seq_recon, _, _ = model.slice_x(x_hat)\n",
    "x_seq_true, _, _ = model.slice_x(x_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "044963e7-bb69-4b2b-aefc-a6acf3daf5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 60])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5208c3c1-acd0-4c06-a4fe-487bf0565090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 0]) tensor([[ 4.,  9.,  1., 15.,  7.,  0.,  7., 15., 18.,  5., 10., 16., 13., 20.,\n",
      "         20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [ 4.,  0., 19., 15.,  7.,  7., 18.,  5., 11., 19., 16., 13., 20., 20.,\n",
      "         20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [ 4.,  0., 12., 15.,  7.,  6.,  7.,  7., 15.,  5.,  7.,  2., 10.,  9.,\n",
      "         13., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.]]) tensor([[ 0., 19., 13.,  3.,  1., 11., 15.,  3.,  0., 11., 20., 20.],\n",
      "        [ 6., 10.,  0.,  7.,  9.,  7.,  9., 10., 16., 19., 20., 20.],\n",
      "        [ 7.,  9., 10.,  7., 13., 19., 13., 16., 10., 20., 20., 20.]])\n"
     ]
    }
   ],
   "source": [
    "from src.models import PairedFVAE\n",
    "max_len_b=0\n",
    "max_len_a=25\n",
    "max_len_pep=12\n",
    "use_b=False\n",
    "use_a=True\n",
    "use_pep=True\n",
    "dataset = PairedDataset(sample, max_len_b, max_len_a, max_len_pep, pad_scale=-20, use_a=use_a, use_b=use_b, use_pep=use_pep, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(len(sample), SequentialSampler)\n",
    "x_true = dataset.x\n",
    "model = PairedFVAE(max_len_b, max_len_a, max_len_pep, use_b=use_b, use_a=use_a, use_pep=use_pep)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "print(seq_true[:, :max_len_b].shape, seq_true[:, max_len_b:max_len_b+max_len_a], seq_true[:, max_len_b+max_len_a:])\n",
    "results = predict_model(model, dataset, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "64e394e1-0840-4bcd-acbf-b311baedbaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDR3bVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=511, out_features=255, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=255, out_features=128, bias=True)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (encoder_mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (encoder_logvar): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (decoder_sequence): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=255, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=255, out_features=460, bias=True)\n",
       "  )\n",
       "  (decoder_v): Linear(in_features=128, out_features=51, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0892cf7b-fb43-4eb3-8086-a41253ea0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from src.models import CDR3bVAE\n",
    "from src.datasets import CDR3BetaDataset\n",
    "max_len_b=23\n",
    "dataset = CDR3BetaDataset(sample, max_len_b, use_v=True, use_j=False, pad_scale=-20,v_dim=51,cdr3b_col='TRB_CDR3')\n",
    "loader = dataset.get_dataloader(len(sample), SequentialSampler)\n",
    "x_true = dataset.x\n",
    "model = CDR3bVAE(max_len_b, use_v=True, use_j=False, v_dim=51)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "results2 = predict_model(model, dataset, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1c9b5448-5350-42f8-9db2-702216ac2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['cdr3a_col']='123'\n",
    "args['cdr3b_col']='None'\n",
    "args['use_a'] = not (args['cdr3a_col']==\"None\")\n",
    "args['use_b'] = not (args['cdr3b_col']==\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "062265a3-6b60-4d49-97af-b9ffaa5f42b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntm = {'x':0.125, 'b':.623, 'c':.2350}\n",
    "np.sum([x for x in ntm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce60f18-b00c-4e4e-a26b-a29fdd9a4ca2",
   "metadata": {},
   "source": [
    "# Concat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5696c592-4e8a-4652-9062-c36f1d5c913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A2'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84707ca7-3da3-4c50-97aa-06c5098ba11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4437007e-f40d-4d01-871f-ae2ded62cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 7\n",
      "A2 8\n",
      "A3 22\n",
      "B1 6\n",
      "B2 7\n",
      "B3 23\n"
     ]
    }
   ],
   "source": [
    "for c in ['A1', 'A2', 'A3', 'B1', 'B2', 'B3']:\n",
    "    print(c, df[c].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28b76be0-807d-4fb7-98eb-879fdb1a1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import encode_batch\n",
    "\n",
    "b3 = encode_batch(df['B3'], max_len=23, encoding='BL50LO', pad_scale=-20)\n",
    "a3 = encode_batch(df['A3'], max_len=22, encoding='BL50LO', pad_scale=-20)\n",
    "a2 = encode_batch(df['B2'], max_len=8, encoding='BL50LO', pad_scale=-20)\n",
    "b2 = encode_batch(df['B2'], max_len=7, encoding='BL50LO', pad_scale=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2d2b3a1-e3e2-4b24-81ba-6e294b4437fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 7\n",
      "A2 8\n",
      "A3 22\n",
      "B1 6\n",
      "B2 7\n",
      "B3 23\n"
     ]
    }
   ],
   "source": [
    "print('A1', df['A1'].apply(len).max())\n",
    "print('A2', df['A2'].apply(len).max())\n",
    "print('A3', df['A3'].apply(len).max())\n",
    "print('B1', df['B1'].apply(len).max())\n",
    "print('B2', df['B2'].apply(len).max())\n",
    "print('B3', df['B3'].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "885f9541-2eda-4691-8c55-c8054273d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_first = torch.cat([b3, a3], dim=1).flatten(start_dim=1)\n",
    "flat_first = torch.cat([b3.flatten(start_dim=1), a3.flatten(start_dim=1)], dim=1)\n",
    "assert (cat_first==flat_first).all(), 'Wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9434e1d8-0f84-4a2c-a972-62a40ee1a9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.,  -2.,  -1.,  -2.,  -1.,  -1.,  -1.,   0.,  -2.,  -1.,  -2.,  -1.,\n",
       "          -1.,  -3.,  -1.,   1.,   0.,  -3.,  -2.,   0.],\n",
       "        [  1.,  -1.,   1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,  -3.,  -3.,   0.,\n",
       "          -2.,  -3.,  -1.,   5.,   2.,  -4.,  -2.,  -2.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   0.,   0.,   2.,  -3.,   2.,   6.,  -3.,   0.,  -4.,  -3.,   1.,\n",
       "          -2.,  -3.,  -1.,  -1.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   1.,   0.,   0.,  -3.,   7.,   2.,  -2.,   1.,  -3.,  -2.,   2.,\n",
       "           0.,  -4.,  -1.,   0.,  -1.,  -1.,  -1.,  -3.],\n",
       "        [ -2.,  -1.,  -2.,  -3.,  -3.,  -1.,  -2.,  -3.,   2.,  -1.,  -1.,  -2.,\n",
       "           0.,   4.,  -3.,  -2.,  -2.,   2.,   8.,  -1.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   0.,   0.,   2.,  -3.,   2.,   6.,  -3.,   0.,  -4.,  -3.,   1.,\n",
       "          -2.,  -3.,  -1.,  -1.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [ -1.,  -4.,  -3.,  -4.,  -2.,  -3.,  -4.,  -4.,  -4.,   5.,   2.,  -3.,\n",
       "           2.,   0.,  -3.,  -3.,  -1.,  -3.,  -1.,   4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [  1.,  -1.,   1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,  -3.,  -3.,   0.,\n",
       "          -2.,  -3.,  -1.,   5.,   2.,  -4.,  -2.,  -2.],\n",
       "        [ -2.,  -1.,  -2.,  -3.,  -3.,  -1.,  -2.,  -3.,   2.,  -1.,  -1.,  -2.,\n",
       "           0.,   4.,  -3.,  -2.,  -2.,   2.,   8.,  -1.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [ -1.,   3.,   0.,  -1.,  -3.,   2.,   1.,  -2.,   0.,  -3.,  -3.,   6.,\n",
       "          -2.,  -4.,  -1.,   0.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [ -2.,  -3.,  -4.,  -4.,  -2.,  -2.,  -3.,  -4.,  -3.,   2.,   5.,  -3.,\n",
       "           3.,   1.,  -4.,  -3.,  -1.,  -2.,  -1.,   1.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_first.view(-1, 23+22, 20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "352c452f-5bff-46b1-8242-ddad4f384508",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import CDR3bVAE, FullTCRVAE\n",
    "model = CDR3bVAE(max_len = 23+22, pad_scale=-20, use_v=False, use_j=False)\n",
    "seq_hat, _, _ = model.reconstruct_hat(flat_first)\n",
    "seq, v, j = model.slice_x(flat_first)\n",
    "(seq_hat != 20).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34268783-46b7-4fce-b7ea-08ba10968370",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m max_len_b2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m max_len_b3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([x\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3]]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxd\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: xd"
     ]
    }
   ],
   "source": [
    "max_len_a1=0\n",
    "max_len_a2=0\n",
    "max_len_a3=0\n",
    "max_len_b1=0\n",
    "max_len_b2=0\n",
    "max_len_b3=0\n",
    "\n",
    "assert not all([x==0 for x in [max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3]]), 'xd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a076dbe-8151-4887-8d23-f572cc235eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import FullTCRVAE\n",
    "from src.datasets import FullTCRDataset\n",
    "from torch.utils.data import SequentialSampler\n",
    "fulltcr_dataset = FullTCRDataset(df, 7, 8, 22, 6, 7, 23, pad_scale=-20)\n",
    "fulltcr_loader = fulltcr_dataset.get_dataloader(1024, SequentialSampler)\n",
    "fulltcr_model = FullTCRVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b94ad740-75d8-4bfc-bea8-68c80b8ae0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfulltcr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/tclustr/src/models.py:47\u001b[0m, in \u001b[0;36mNetParent.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Work around, so we can get model.device for all NetParent\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNetParent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "fulltcr_model.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7dc71-60b9-4e50-98d5-e202077f379b",
   "metadata": {},
   "source": [
    "# Latent dim control (additional loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6894c3df-2f4c-47f7-b3e5-68d3df8bcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_subset = fulltcr_dataset.x[fulltcr_dataset.df.query('peptide==\"GILGFVFTL\"').index]\n",
    "z = fulltcr_model.embed(x_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06ce6669-411e-4314-8be4-74086606b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[ -1.,   3.,   0.,  ..., -20., -20., -20.],\n",
      "        [ -2.,  -2.,   2.,  ..., -20., -20., -20.],\n",
      "        [  0.,  -1.,   0.,  ..., -20., -20., -20.],\n",
      "        ...,\n",
      "        [ -2.,  -2.,   2.,  ..., -20., -20., -20.],\n",
      "        [ -1.,  -1.,   7.,  ..., -20., -20., -20.],\n",
      "        [ -2.,  -2.,   2.,  ..., -20., -20., -20.]])\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(fulltcr_loader):\n",
    "    print(i, x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a87fcf39-181b-416d-9e31-0963afb93968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.datasets.FullTCRDataset at 0x108003f90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b02f6abe-f49b-4af6-b55f-9815c5eb1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.metrics failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/riwa/Documents/code/tclustr/src/metrics.py\", line 235, in <module>\n",
      "    class TripleVAELoss(VAELoss):\n",
      "  File \"/Users/riwa/Documents/code/tclustr/src/metrics.py\", line 236, in TripleVAELoss\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.2331,  0.6798,  1.2645, -0.2473,  0.6084,  0.1823,  0.2082, -0.1631,\n",
       "         1.5483, -0.1914, -1.3046, -1.0642,  0.3633, -0.0941,  0.5933,  1.8078,\n",
       "        -1.2973,  2.1205,  1.6201, -2.5718,  1.4542, -0.2927,  0.6241,  0.9395,\n",
       "         0.8390, -0.0289, -0.1067, -3.6086,  0.5269, -0.7022,  1.0120, -0.4022,\n",
       "        -0.3717, -2.2359,  0.7792, -0.8685, -1.0450, -1.5682, -1.7087, -1.0641,\n",
       "        -0.2204, -0.3764, -1.0976,  0.7779, -0.9610,  0.4613,  0.2907,  0.2122,\n",
       "        -0.4083,  0.1400,  1.3919,  0.4340, -1.6895, -0.7093,  0.7120,  2.0495,\n",
       "         1.7948, -0.3105, -0.3771,  0.9735,  1.2006, -0.4415,  0.0934, -0.2468],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3eb659-e5f7-4bb9-a2e1-026363100247",
   "metadata": {},
   "source": [
    "# vmap tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "0fd1d9b6-15b3-4105-8411-c703b0bedfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentative pepmap that should be saved forever\n",
    "PEPMAP = {k:i for i,k in enumerate(sorted(df.peptide.unique()))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e5aeddfc-ab9a-482f-bb72-e581b9bb5a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.datasets import VAEDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def get_same_spec_idx(row, df):\n",
    "    current_idx = row.name\n",
    "    pep = row['peptide']\n",
    "    return [x for x in df.query('peptide==@pep').index if x != current_idx]\n",
    "\n",
    "\n",
    "def pad_and_stack(list_of_lists, padding_value=-1):\n",
    "    # Determine the maximum length\n",
    "    max_length = max(len(sublist) for sublist in list_of_lists)\n",
    "\n",
    "    # Create a NumPy array filled with the padding value\n",
    "    padded_lists = np.full((len(list_of_lists), max_length), padding_value)\n",
    "\n",
    "    # Copy each sub-list into the padded array\n",
    "    for i, sublist in enumerate(list_of_lists):\n",
    "        padded_lists[i, :len(sublist)] = sublist\n",
    "\n",
    "    return torch.from_numpy(padded_lists)\n",
    "    \n",
    "class TEST(VAEDataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 df, max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3,\n",
    "                 encoding='BL50LO', pad_scale=None,\n",
    "                 a1_col='A1', a2_col='A2', a3_col='A3', b1_col='B1', b2_col='B2', b3_col='B3'):\n",
    "        super(TEST, self).__init__()\n",
    "        # TODO : Current behaviour If max_len_x = 0, then don't use that chain...\n",
    "        #        Is that the most elegant way to do this ?\n",
    "        assert not all([x == 0 for x in [max_len_a1, max_len_a2, max_len_a3,\n",
    "                                         max_len_b1, max_len_b2, max_len_b3]]), \\\n",
    "            'All loops max_len are 0! No chains will be added'\n",
    "\n",
    "        x_seq = []\n",
    "        self.max_len_a1 = max_len_a1\n",
    "        self.max_len_a2 = max_len_a2\n",
    "        self.max_len_a3 = max_len_a3\n",
    "        self.max_len_b1 = max_len_b1\n",
    "        self.max_len_b2 = max_len_b2\n",
    "        self.max_len_b3 = max_len_b3\n",
    "        self.use_a1 = not (max_len_a1 == 0)\n",
    "        self.use_a2 = not (max_len_a2 == 0)\n",
    "        self.use_a3 = not (max_len_a3 == 0)\n",
    "        self.use_b1 = not (max_len_b1 == 0)\n",
    "        self.use_b2 = not (max_len_b2 == 0)\n",
    "        self.use_b3 = not (max_len_b3 == 0)\n",
    "\n",
    "        # bad double loop because brain slow\n",
    "        for max_len, seq_col in zip([max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3],\n",
    "                                    [a1_col, a2_col, a3_col, b1_col, b2_col, b3_col]):\n",
    "            if max_len != 0:\n",
    "                df['len_q'] = df[seq_col].apply(len)\n",
    "                df = df.query('len_q <= @max_len')\n",
    "        for max_len, seq_col in zip([max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3],\n",
    "                                    [a1_col, a2_col, a3_col, b1_col, b2_col, b3_col]):\n",
    "            if max_len != 0:\n",
    "                x_seq.append(encode_batch(df[seq_col], max_len, encoding, pad_scale).flatten(start_dim=1))\n",
    "\n",
    "        self.df = df.drop(columns=['len_q']).reset_index(drop=True)\n",
    "        self.x = torch.cat(x_seq, dim=1)\n",
    "        idx_list = df.apply(get_same_spec_idx, df=df, axis=1).to_list()\n",
    "        self.idx_tensor = pad_and_stack(idx_list, padding_value=-1)\n",
    "        self.labels = torch.from_numpy(df['peptide'].map(PEPMAP).values)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.idx_tensor[idx], self.labels[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "9e3a1a81-ab18-4cf7-abca-05bb9e068506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/riwa/Documents/code/tclustr/data/Matrices/231031_nettcr_pep_map.pkl saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/riwa/Documents/code/tclustr/src/datasets.py\", line 5, in <module>\n",
      "    from src.data_processing import encode_batch, V_MAP, J_MAP, PEP_MAP\n",
      "ImportError: cannot import name 'PEP_MAP' from 'src.data_processing' (/Users/riwa/Documents/code/tclustr/src/data_processing.py)\n",
      "]\n",
      "[autoreload of src.train_eval failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1004, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/riwa/Documents/code/tclustr/src/train_eval.py\", line 84\n",
      "    if criterion.__class__.__name__ == 'CombinedVAELoss' and:\n",
      "                                                            ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Saving PEPMAP to be re-used\n",
    "pkl_dump(PEPMAP, '../data/Matrices/231031_nettcr_pep_map.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b4949363-6738-4d35-87d5-530bd69962b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import FullTCRVAE\n",
    "model = FullTCRVAE(7,8,22,6,7,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "94898ae3-4c98-4127-babd-ce9e697c63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = TEST(df, 7,8,22,6,7,23,pad_scale=-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829290e1-3029-4786-9e08-828040618663",
   "metadata": {},
   "source": [
    "## Use global idx for entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "832c38a6-2d69-4d6f-ab6d-96a7ea9092a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1460]) torch.Size([256, 1124])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(27093)\n",
    "loader = dataset.get_dataloader(256, RandomSampler)\n",
    "for x, idx, labels in loader:\n",
    "    print(x.shape, idx.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966cbed-53a4-4b64-8992-424950daed55",
   "metadata": {},
   "source": [
    "Reasoning : Here, we take a single index, figure out what to do to get the similar Z latent tensor for a given item, then use torch.vmap to apply it to all the items in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "86af3b0a-d300-47f8-b376-3a6beab38112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([715, 1460]) tensor([[  0.,  -1.,   0.,  ..., -20., -20., -20.],\n",
      "        [  5.,  -2.,  -1.,  ..., -20., -20., -20.],\n",
      "        [  1.,  -1.,   1.,  ..., -20., -20., -20.],\n",
      "        ...,\n",
      "        [  0.,  -1.,   0.,  ..., -20., -20., -20.],\n",
      "        [  0.,  -1.,   0.,  ..., -20., -20., -20.],\n",
      "        [  0.,  -1.,   0.,  ..., -20., -20., -20.]])\n",
      "torch.Size([715, 64]) tensor([[ 0.9176,  0.1794,  0.9044,  ..., -0.7415,  1.0966,  0.8663],\n",
      "        [ 1.2953,  0.5653,  1.2924,  ..., -0.1195,  1.1858,  1.5396],\n",
      "        [ 1.9437,  0.1443,  0.0648,  ..., -0.9411,  2.1519,  0.5631],\n",
      "        ...,\n",
      "        [ 2.1478,  0.8220,  0.1268,  ..., -0.1212,  1.7150,  1.5651],\n",
      "        [ 1.9482,  1.3227, -0.3979,  ..., -0.7113,  1.5373,  1.9503],\n",
      "        [ 1.5420,  0.1140,  0.4547,  ..., -0.0208,  1.4899,  0.8553]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# For a single item, unpad the index tensor in order to get all the idxs that are with the same specificity as the given item (here item is idx==0)\n",
    "unpadded = idx[0][idx[0]!=-1]\n",
    "pad_len = len(idx[0][idx[0]==-1])\n",
    "# This here takes the unpadded index tensor to index the dataset, then take the first item (x) using [0]\n",
    "similar = loader.dataset[unpadded][0]\n",
    "# here, the given item we indexed had 933 similar Xs\n",
    "print(similar.shape, similar)\n",
    "model.eval()\n",
    "z_item = model.embed(x[0:1])\n",
    "z_batch = model.embed(x)\n",
    "z_similar = model.embed(similar)\n",
    "print(z_similar.shape, z_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ab9f5333-3438-4abb-bf59-9b429bec22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z_all = model.embed(dataset.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07d458-70f9-4af1-b806-3d08dae127c3",
   "metadata": {},
   "source": [
    "## Use batched pairwise distances and triplet loss ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f2b2da10-3ebc-4665-8a3a-870aeb9df722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity, CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ddb66146-56bb-4d2f-97d6-c1c926373d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_loss = CosineEmbeddingLoss()\n",
    "\n",
    "cos_loss(z_batch, z_batch[::], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "baa8eab4-478b-4723-9f8a-ccc64eb642c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_cosine_distance(embedding_matrix, *args, **kwargs):\n",
    "    # Compute the dot product of the embedding matrix\n",
    "    dot_product = torch.mm(embedding_matrix, embedding_matrix.t())\n",
    "    \n",
    "    # Compute the L2 norms of the vectors\n",
    "    norms = torch.norm(embedding_matrix, p=2, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute the pairwise cosine distances\n",
    "    cosine_distance_matrix = 1 - dot_product / (norms * norms.t())\n",
    "    \n",
    "    return cosine_distance_matrix\n",
    "\n",
    "cosine_distance_matrix = compute_cosine_distance(z_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ff718aa3-08c5-42b9-97be-c48d40fac816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836065573770493 0.0 0.0 0.01639344262295082\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import CombinedVAELoss\n",
    "criterion = CombinedVAELoss(weight_kld = 0.05, weight_seq=3, weight_vae=1, weight_triplet=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "e0358ffe-9b5b-4fba-83cc-edaa3a22c24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0178, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import TripletLoss\n",
    "\n",
    "triplet = TripletLoss(dist_type='cosine', margin=0.05)\n",
    "triplet(z_batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "243dd886-358d-447f-a7d4-7e1d0efd4453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(71.1716, grad_fn=<DivBackward0>),\n",
       " tensor(0.0012, grad_fn=<DivBackward0>),\n",
       " tensor(0.0067, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(x_hat, x, mu, logvar, z_batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "42befb93-36b8-4007-8f85-b666529a21d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1921e-07,  8.8525e-02,  1.4484e-01,  ...,  1.6952e-01,\n",
       "          1.1687e-01,  1.4104e-01],\n",
       "        [ 8.8525e-02, -1.1921e-07,  8.8099e-02,  ...,  1.6081e-01,\n",
       "          1.4339e-01,  1.6584e-01],\n",
       "        [ 1.4484e-01,  8.8099e-02, -1.1921e-07,  ...,  1.7315e-01,\n",
       "          9.2561e-02,  1.3772e-01],\n",
       "        ...,\n",
       "        [ 1.6952e-01,  1.6081e-01,  1.7315e-01,  ..., -2.3842e-07,\n",
       "          1.5152e-01,  2.1792e-01],\n",
       "        [ 1.1687e-01,  1.4339e-01,  9.2561e-02,  ...,  1.5152e-01,\n",
       "         -1.1921e-07,  5.8871e-02],\n",
       "        [ 1.4104e-01,  1.6584e-01,  1.3772e-01,  ...,  2.1792e-01,\n",
       "          5.8871e-02,  0.0000e+00]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = compute_cosine_distance\n",
    "test(z_batch, z_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "3f2f24e5-8b9d-4fa6-96bf-68913ff42125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1921e-07,  8.8525e-02,  1.4484e-01,  ...,  1.6952e-01,\n",
       "          1.1687e-01,  1.4104e-01],\n",
       "        [ 8.8525e-02, -1.1921e-07,  8.8099e-02,  ...,  1.6081e-01,\n",
       "          1.4339e-01,  1.6584e-01],\n",
       "        [ 1.4484e-01,  8.8099e-02, -1.1921e-07,  ...,  1.7315e-01,\n",
       "          9.2561e-02,  1.3772e-01],\n",
       "        ...,\n",
       "        [ 1.6952e-01,  1.6081e-01,  1.7315e-01,  ..., -2.3842e-07,\n",
       "          1.5152e-01,  2.1792e-01],\n",
       "        [ 1.1687e-01,  1.4339e-01,  9.2561e-02,  ...,  1.5152e-01,\n",
       "         -1.1921e-07,  5.8871e-02],\n",
       "        [ 1.4104e-01,  1.6584e-01,  1.3772e-01,  ...,  2.1792e-01,\n",
       "          5.8871e-02,  0.0000e+00]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_type = 'cosine'\n",
    "p = 1 if dist_type=='l1' else 2 if dist_type=='l2' else None\n",
    "compute_cosine_distance(z_batch, z_batch, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "b5b3bd76-c205-4127-8d80-138cf6ffb775",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'up_with' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[548], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mup_with\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'up_with' is not defined"
     ]
    }
   ],
   "source": [
    "up_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "776eaf0c-a3b5-4281-a5a1-ca882698ad36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1921e-07,  8.8525e-02,  1.4484e-01,  8.6070e-02,  1.2365e-01,\n",
       "         9.4377e-02,  9.2447e-02,  1.4498e-01,  2.0667e-01,  4.1107e-02,\n",
       "         4.9342e-02,  1.1338e-01,  1.3825e-01,  1.3562e-01,  5.9261e-02,\n",
       "         9.1015e-02,  3.9438e-02,  1.1745e-01,  1.3014e-01,  9.0559e-02,\n",
       "         1.0822e-01,  1.1863e-01,  1.2915e-01,  2.6091e-01,  7.9152e-02,\n",
       "         1.0801e-01,  1.1053e-01,  9.7344e-02,  6.5381e-02,  1.4941e-01,\n",
       "         1.2490e-01,  1.4857e-01,  1.3122e-01,  7.7253e-02,  1.2720e-01,\n",
       "         1.6437e-01,  1.1458e-01,  5.6446e-02,  5.6843e-02,  8.4044e-02,\n",
       "         4.2943e-02,  8.2702e-02,  4.8154e-02,  1.0479e-01,  1.0309e-01,\n",
       "         1.6739e-01,  1.2356e-01,  1.0505e-01,  9.3499e-02,  7.8227e-02,\n",
       "         1.4517e-01,  1.2957e-01,  1.6339e-01,  4.3252e-02,  5.3720e-02,\n",
       "         7.2856e-02,  1.0537e-01,  5.4271e-02,  1.4579e-01,  1.3248e-01,\n",
       "         1.0790e-01,  1.2080e-01,  3.8989e-02,  1.0927e-01,  7.8304e-02,\n",
       "         1.0553e-01,  7.9875e-02,  1.2455e-01,  1.2525e-01,  1.4287e-01,\n",
       "         1.4997e-01,  1.0183e-01,  1.6515e-01,  1.2150e-01,  1.4490e-01,\n",
       "         1.4268e-01,  1.2605e-01,  9.1548e-02,  4.8372e-02,  1.4783e-01,\n",
       "         7.1725e-02,  1.3679e-01,  1.2885e-01,  1.0317e-01,  9.0550e-02,\n",
       "         9.8241e-02,  1.1605e-01,  1.0837e-01,  1.2701e-01,  9.1921e-02,\n",
       "         9.8108e-02,  1.1477e-01,  6.8969e-02,  1.5178e-01,  1.6614e-01,\n",
       "         5.0413e-02,  1.0253e-01,  1.1289e-01,  1.1944e-01,  1.6456e-01,\n",
       "         7.2987e-02,  4.3402e-02,  1.3542e-01,  8.5613e-02,  1.0652e-01,\n",
       "         1.4530e-01,  8.1956e-02,  8.1797e-02,  1.4510e-01,  1.2900e-01,\n",
       "         1.2886e-01,  1.2581e-01,  1.0379e-01,  8.2144e-02,  1.1827e-01,\n",
       "         8.1700e-02,  1.1849e-01,  1.3682e-01,  1.0005e-01,  1.3685e-01,\n",
       "         1.9035e-01,  6.3278e-02,  6.1216e-02,  8.5685e-02,  4.2140e-02,\n",
       "         1.5600e-01,  1.4140e-01,  1.3850e-01,  1.0026e-01,  1.0379e-01,\n",
       "         4.3027e-02,  1.5661e-01,  1.0494e-01,  9.5515e-02,  1.0631e-01,\n",
       "         1.0409e-01,  1.1095e-01,  1.0772e-01,  1.0706e-01,  1.2552e-01,\n",
       "         1.3308e-01,  3.6309e-02,  1.2085e-01,  4.5886e-02,  1.4124e-01,\n",
       "         1.0803e-01,  8.3790e-02,  1.2514e-01,  1.1121e-01,  1.3867e-01,\n",
       "         9.1753e-02,  9.2761e-02,  6.8047e-02,  6.3916e-02,  1.0054e-01,\n",
       "         9.3037e-02,  1.2309e-01,  1.5219e-01,  1.1386e-01,  1.3131e-01,\n",
       "         1.0022e-01,  1.0089e-01,  1.1002e-01,  5.0507e-02,  2.3893e-01,\n",
       "         1.2923e-01,  8.9061e-02,  1.1506e-01,  9.8960e-02,  2.0512e-01,\n",
       "         1.5114e-01,  1.1121e-01,  1.0794e-01,  1.4811e-01,  9.1093e-02,\n",
       "         4.0770e-02,  1.2665e-01,  1.0236e-01,  3.8921e-02,  1.4611e-01,\n",
       "         1.4617e-01,  9.0275e-02,  1.0420e-01,  6.2552e-02,  1.1187e-01,\n",
       "         6.3438e-02,  1.4473e-01,  1.3947e-01,  1.4393e-01,  1.4026e-01,\n",
       "         8.5470e-02,  1.1315e-01,  9.2500e-02,  1.3488e-01,  5.0652e-02,\n",
       "         9.6737e-02,  1.4667e-01,  1.4422e-01,  1.8863e-01,  1.4628e-01,\n",
       "         1.3363e-01,  1.7374e-01,  9.0792e-02,  1.5901e-01,  9.9866e-02,\n",
       "         7.2612e-02,  6.5174e-02,  1.2548e-01,  9.1364e-02,  8.9076e-02,\n",
       "         8.9669e-02,  1.4960e-01,  8.4521e-02,  7.2419e-02,  1.2297e-01,\n",
       "         1.7786e-01,  1.3892e-01,  1.3579e-01,  1.3959e-01,  1.2895e-01,\n",
       "         1.1425e-01,  1.1049e-01,  7.2031e-02,  1.1784e-01,  1.2994e-01,\n",
       "         1.3597e-01,  1.2249e-01,  1.6053e-01,  1.0782e-01,  1.8770e-01,\n",
       "         6.1211e-02,  1.1390e-01,  1.3785e-01,  1.6437e-01,  8.2981e-02,\n",
       "         9.2364e-02,  1.7357e-01,  1.7353e-01,  8.9851e-02,  1.6993e-01,\n",
       "         8.4953e-02,  1.3671e-01,  8.7536e-02,  1.2708e-01,  1.3005e-01,\n",
       "         1.1661e-01,  1.1324e-01,  1.8799e-01,  4.0829e-02,  8.2027e-02,\n",
       "         8.1875e-02,  8.0471e-02,  6.1121e-02,  1.6952e-01,  1.1687e-01,\n",
       "         1.4104e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "5f9d90e1-924f-4906-89d4-b2ade20fb70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1921e-07,  8.8525e-02,  1.4483e-01,  8.6070e-02,  1.2365e-01,\n",
       "         9.4377e-02,  9.2446e-02,  1.4498e-01,  2.0667e-01,  4.1106e-02,\n",
       "         4.9342e-02,  1.1338e-01,  1.3825e-01,  1.3562e-01,  5.9261e-02,\n",
       "         9.1015e-02,  3.9438e-02,  1.1745e-01,  1.3014e-01,  9.0559e-02,\n",
       "         1.0822e-01,  1.1863e-01,  1.2915e-01,  2.6091e-01,  7.9152e-02,\n",
       "         1.0801e-01,  1.1053e-01,  9.7343e-02,  6.5381e-02,  1.4941e-01,\n",
       "         1.2490e-01,  1.4857e-01,  1.3122e-01,  7.7253e-02,  1.2720e-01,\n",
       "         1.6437e-01,  1.1458e-01,  5.6446e-02,  5.6843e-02,  8.4044e-02,\n",
       "         4.2943e-02,  8.2703e-02,  4.8154e-02,  1.0479e-01,  1.0309e-01,\n",
       "         1.6739e-01,  1.2356e-01,  1.0505e-01,  9.3498e-02,  7.8227e-02,\n",
       "         1.4517e-01,  1.2957e-01,  1.6339e-01,  4.3252e-02,  5.3720e-02,\n",
       "         7.2857e-02,  1.0537e-01,  5.4271e-02,  1.4579e-01,  1.3248e-01,\n",
       "         1.0790e-01,  1.2080e-01,  3.8989e-02,  1.0927e-01,  7.8304e-02,\n",
       "         1.0553e-01,  7.9875e-02,  1.2455e-01,  1.2525e-01,  1.4287e-01,\n",
       "         1.4997e-01,  1.0183e-01,  1.6515e-01,  1.2150e-01,  1.4490e-01,\n",
       "         1.4268e-01,  1.2605e-01,  9.1548e-02,  4.8372e-02,  1.4783e-01,\n",
       "         7.1725e-02,  1.3679e-01,  1.2885e-01,  1.0317e-01,  9.0550e-02,\n",
       "         9.8241e-02,  1.1605e-01,  1.0837e-01,  1.2701e-01,  9.1921e-02,\n",
       "         9.8107e-02,  1.1477e-01,  6.8969e-02,  1.5178e-01,  1.6614e-01,\n",
       "         5.0413e-02,  1.0253e-01,  1.1289e-01,  1.1944e-01,  1.6456e-01,\n",
       "         7.2986e-02,  4.3402e-02,  1.3542e-01,  8.5613e-02,  1.0652e-01,\n",
       "         1.4530e-01,  8.1956e-02,  8.1797e-02,  1.4510e-01,  1.2900e-01,\n",
       "         1.2886e-01,  1.2581e-01,  1.0379e-01,  8.2144e-02,  1.1827e-01,\n",
       "         8.1700e-02,  1.1849e-01,  1.3682e-01,  1.0005e-01,  1.3685e-01,\n",
       "         1.9035e-01,  6.3279e-02,  6.1217e-02,  8.5685e-02,  4.2140e-02,\n",
       "         1.5600e-01,  1.4140e-01,  1.3850e-01,  1.0026e-01,  1.0379e-01,\n",
       "         4.3027e-02,  1.5661e-01,  1.0494e-01,  9.5515e-02,  1.0631e-01,\n",
       "         1.0409e-01,  1.1095e-01,  1.0772e-01,  1.0706e-01,  1.2552e-01,\n",
       "         1.3308e-01,  3.6309e-02,  1.2085e-01,  4.5885e-02,  1.4124e-01,\n",
       "         1.0803e-01,  8.3790e-02,  1.2514e-01,  1.1121e-01,  1.3867e-01,\n",
       "         9.1753e-02,  9.2760e-02,  6.8047e-02,  6.3915e-02,  1.0054e-01,\n",
       "         9.3037e-02,  1.2309e-01,  1.5219e-01,  1.1386e-01,  1.3131e-01,\n",
       "         1.0022e-01,  1.0089e-01,  1.1002e-01,  5.0507e-02,  2.3893e-01,\n",
       "         1.2923e-01,  8.9061e-02,  1.1506e-01,  9.8960e-02,  2.0512e-01,\n",
       "         1.5114e-01,  1.1121e-01,  1.0794e-01,  1.4811e-01,  9.1093e-02,\n",
       "         4.0770e-02,  1.2665e-01,  1.0236e-01,  3.8921e-02,  1.4611e-01,\n",
       "         1.4617e-01,  9.0275e-02,  1.0420e-01,  6.2552e-02,  1.1187e-01,\n",
       "         6.3438e-02,  1.4473e-01,  1.3947e-01,  1.4393e-01,  1.4026e-01,\n",
       "         8.5470e-02,  1.1315e-01,  9.2500e-02,  1.3488e-01,  5.0652e-02,\n",
       "         9.6737e-02,  1.4667e-01,  1.4422e-01,  1.8863e-01,  1.4628e-01,\n",
       "         1.3363e-01,  1.7374e-01,  9.0791e-02,  1.5901e-01,  9.9866e-02,\n",
       "         7.2612e-02,  6.5174e-02,  1.2548e-01,  9.1364e-02,  8.9076e-02,\n",
       "         8.9669e-02,  1.4960e-01,  8.4521e-02,  7.2419e-02,  1.2297e-01,\n",
       "         1.7786e-01,  1.3892e-01,  1.3579e-01,  1.3959e-01,  1.2895e-01,\n",
       "         1.1425e-01,  1.1049e-01,  7.2031e-02,  1.1784e-01,  1.2994e-01,\n",
       "         1.3597e-01,  1.2249e-01,  1.6053e-01,  1.0782e-01,  1.8770e-01,\n",
       "         6.1212e-02,  1.1390e-01,  1.3785e-01,  1.6437e-01,  8.2981e-02,\n",
       "         9.2364e-02,  1.7357e-01,  1.7353e-01,  8.9851e-02,  1.6993e-01,\n",
       "         8.4953e-02,  1.3671e-01,  8.7536e-02,  1.2708e-01,  1.3005e-01,\n",
       "         1.1661e-01,  1.1324e-01,  1.8799e-01,  4.0828e-02,  8.2027e-02,\n",
       "         8.1875e-02,  8.0472e-02,  6.1121e-02,  1.6952e-01,  1.1687e-01,\n",
       "         1.4104e-01], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = CosineSimilarity()\n",
    "1-cos(z_batch[0], z_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b6964e80-d673-41bf-a1ca-d82fc8603db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distances1 = torch.cdist(z_batch, z_batch)\n",
    "pairwise_distances2 = torch.nn.functional.pairwise_distance(z_batch[0], z_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc197f0-8424-4fb6-8804-a4fd4e0ec621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f1f444ac-0143-43cf-8707-0288ee4a0f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 5.1177, 6.7114, 5.1391, 6.1053, 5.4939, 5.1972, 6.6448, 7.5363,\n",
       "        3.5968, 4.2440, 5.9266, 6.4634, 6.3715, 4.2044, 5.3600, 3.4410, 5.8228,\n",
       "        6.1673, 5.3943, 5.6196, 6.0244, 6.1504, 8.3342, 4.8248, 5.6472, 5.6581,\n",
       "        5.3302, 4.5688, 6.7650, 6.2608, 6.6244, 6.2698, 4.8138, 6.2009, 6.8383,\n",
       "        6.3650, 4.2736, 4.1638, 5.1422, 3.6609, 5.0608, 3.9235, 5.5264, 5.4719,\n",
       "        6.9015, 6.1706, 5.5241, 5.4852, 4.8182, 6.6400, 6.5492, 6.7787, 3.6688,\n",
       "        4.2372, 4.6404, 5.5282, 4.0215, 6.5536, 6.2898, 5.6694, 5.9250, 3.4652,\n",
       "        5.7096, 4.8583, 5.6490, 5.2844, 6.0828, 6.1250, 6.4515, 6.7158, 5.4626,\n",
       "        6.8416, 5.9888, 6.6957, 6.4350, 6.0354, 5.1977, 4.0061, 6.6097, 4.6880,\n",
       "        6.2462, 6.0792, 5.6378, 5.1446, 5.4127, 6.1163, 5.6377, 6.1255, 5.2098,\n",
       "        5.3811, 5.8612, 4.6756, 6.5816, 7.0530, 4.0043, 5.5882, 5.7639, 5.8755,\n",
       "        6.8871, 4.8207, 3.6901, 6.2548, 5.0299, 5.5976, 6.5596, 5.0891, 4.9015,\n",
       "        6.4481, 6.1801, 6.0944, 6.0346, 5.5414, 5.2895, 5.9577, 4.9202, 5.9306,\n",
       "        6.4178, 5.4733, 6.3091, 7.5762, 4.7029, 4.2625, 5.0525, 3.7300, 6.8304,\n",
       "        6.4480, 6.3805, 5.6190, 5.5274, 3.7725, 6.9829, 5.5970, 5.2882, 5.6759,\n",
       "        5.4964, 5.7108, 5.6529, 5.6155, 6.2092, 6.3376, 3.5005, 5.8966, 3.8782,\n",
       "        6.5944, 5.8140, 5.0210, 6.0325, 5.7192, 6.4252, 5.4067, 5.2066, 4.4993,\n",
       "        4.4437, 5.4864, 5.2203, 6.0250, 6.6830, 5.8023, 6.1785, 6.0285, 5.5782,\n",
       "        5.9921, 3.8880, 8.0272, 6.2673, 5.4778, 5.8349, 5.3898, 7.6209, 6.5787,\n",
       "        5.6879, 5.6122, 6.5692, 5.3039, 3.7187, 6.1972, 5.4584, 3.5165, 6.5649,\n",
       "        6.6219, 5.4380, 5.5285, 4.6826, 5.6890, 4.3436, 6.5577, 6.4537, 6.4293,\n",
       "        6.3812, 5.0111, 5.7456, 5.2026, 6.3115, 3.9508, 5.3509, 6.7300, 6.4021,\n",
       "        7.2328, 6.7055, 6.3262, 6.9872, 5.1597, 7.0144, 5.6576, 4.9514, 4.3970,\n",
       "        6.0324, 5.1754, 5.4847, 5.1567, 6.5142, 5.3583, 4.6676, 5.9678, 7.1601,\n",
       "        6.5277, 6.4850, 6.4041, 6.2002, 5.7901, 5.9431, 4.6107, 5.8374, 6.1350,\n",
       "        6.3989, 6.3947, 6.8356, 5.6935, 7.2912, 4.3914, 5.7979, 6.8591, 6.8658,\n",
       "        4.9913, 5.2122, 7.4321, 7.3788, 5.1470, 6.9037, 5.0243, 6.3534, 5.0998,\n",
       "        6.0710, 6.1530, 5.9537, 5.8755, 7.4919, 3.7769, 4.9310, 4.9428, 4.9055,\n",
       "        4.7983, 6.9833, 5.8539, 6.4508], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "faab54c9-9217-446b-85aa-2b98bfaba140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6e89b20c-21c1-4039-8e12-884a3257d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, pairwise distances can be whatever.\n",
    "pairwise_distances1 = torch.cdist(z_batch, z_batch)\n",
    "\n",
    "# these below are the parts that matter for the implementation\n",
    "mask_positive = torch.eq(labels.unsqueeze(0), labels.unsqueeze(1)).float()\n",
    "mask_negative = 1 - mask_positive\n",
    "\n",
    "margin = 1.0\n",
    "# Compute the positive and negative distances\n",
    "positive_distances = mask_positive * pairwise_distances\n",
    "negative_distances = mask_negative * pairwise_distances\n",
    "\n",
    "# Calculate the triplet loss\n",
    "loss = torch.relu(positive_distances - negative_distances + margin)\n",
    "loss = loss.mean()\n",
    "return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "20728838-e724-4a05-a638-fec10d8903e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.0 0.0 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import CombinedVAELoss\n",
    "criterion = CombinedVAELoss()\n",
    "criterion.__class__.__name__ == 'CombinedVAELoss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "127811c4-25f1-41bb-9860-126eed33dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 5.1177, 6.7114,  ..., 6.9833, 5.8539, 6.4508],\n",
       "        [5.1177, 0.0000, 5.1668,  ..., 6.4702, 6.2941, 6.8121],\n",
       "        [6.7114, 5.1668, 0.0000,  ..., 7.1702, 5.2849, 0.0000],\n",
       "        ...,\n",
       "        [6.9833, 6.4702, 7.1702,  ..., 0.0000, 6.2330, 7.3809],\n",
       "        [5.8539, 6.2941, 5.2849,  ..., 6.2330, 0.0000, 4.0400],\n",
       "        [6.4508, 6.8121, 0.0000,  ..., 7.3809, 4.0400, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances1 * mask_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b3b8c3b6-cbbc-48a8-b338-60072dbe6e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 6.4403],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 6.4403,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances1 * mask_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9be42aa4-a609-4b70-ad17-705e5b21ad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1138,  0.6592,  1.0491,  ..., -0.6828,  1.6321,  2.7155],\n",
       "        [ 0.4566,  0.2783,  0.6465,  ..., -0.4741,  1.1475,  2.5910],\n",
       "        [ 1.2872,  0.4077,  0.7408,  ..., -0.4852,  1.6835,  1.5436],\n",
       "        ...,\n",
       "        [ 1.0215,  1.4980,  0.0328,  ..., -0.4786,  0.8880,  1.2802],\n",
       "        [ 2.0577,  0.7814,  0.2786,  ..., -0.2874,  1.6500,  0.9614],\n",
       "        [ 2.1224,  0.3473,  0.1631,  ..., -0.9703,  1.3913,  0.5789]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "12b66a8e-0e29-49b2-8c80-3f6b11e0046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TCRSpecificDataset\n",
    "\n",
    "dataset = TCRSpecificDataset(df, 7,8,22,6,7,23, pad_scale=-20)\n",
    "loader = dataset.get_dataloader(256, RandomSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4baae36b-dc83-4dde-82e7-6176e74bd2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "c169998f-8f42-438c-ad35-b678d9c615f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, labels = x.pop(0), x.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4d20dd49-a338-41d2-bb57-6c58c3a1cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1460]), torch.Size([256]))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "639fb21c-e6f0-4591-8f14-a5c1c4ca3306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(criterion, 'triplet_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "cccece1c-d4d8-4430-bf33-84e7db67efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat, mu, logvar = model(x)\n",
    "z = model.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0a9cbc19-24aa-4204-8b20-6e2bf11006dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon, kld, tripl = criterion(x_hat, x, mu, logvar, z, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147039a-d7e5-4bd4-9753-ab0bf9f11524",
   "metadata": {},
   "source": [
    "# testing other arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "80a6e217-6a50-4021-99ff-5dfa47c46f62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step must be greater than zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[565], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mz_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: step must be greater than zero"
     ]
    }
   ],
   "source": [
    "z_batch[::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2de5b1c4-e468-46f0-ba8a-3a6bfa562b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "dc9cf731-5197-43b8-a85f-97ed5458f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = [200]\n",
    "num_latent = 20\n",
    "# Initialize lists for holding hidden layers\n",
    "encoderlayers = nn.ModuleList()\n",
    "encodernorms = nn.ModuleList()\n",
    "decoderlayers = nn.ModuleList()\n",
    "decodernorms = nn.ModuleList()\n",
    "# Input dims\n",
    "input_size=100\n",
    "### Layers\n",
    "# Hidden layers\n",
    "for nin, nout in zip([input_size] + num_hidden, num_hidden):\n",
    "    encoderlayers.append(nn.Linear(nin, nout))\n",
    "    encodernorms.append(nn.BatchNorm1d(nout))\n",
    "\n",
    "# Latent layers\n",
    "mu = nn.Linear(num_hidden[-1], num_latent)  # mu layer\n",
    "var = nn.Linear(num_hidden[-1], num_latent)  # logvariance layer\n",
    "\n",
    "# Decoding layers\n",
    "for nin, nout in zip(\n",
    "    [num_latent] + num_hidden[::-1], num_hidden[::-1]\n",
    "):\n",
    "    decoderlayers.append(nn.Linear(nin, nout))\n",
    "    decodernorms.append(nn.BatchNorm1d(nout))\n",
    "\n",
    "# Reconstruction - output layers\n",
    "out = nn.Linear(num_hidden[0], input_size)  # to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "ef6ff68b-e191-4677-9332-1c601d405f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_batch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "628fce0f-10ec-40ee-b67c-0bcacd4cb8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ModuleList(\n",
       "   (0): Linear(in_features=100, out_features=200, bias=True)\n",
       " ),\n",
       " Linear(in_features=200, out_features=20, bias=True),\n",
       " Linear(in_features=200, out_features=20, bias=True),\n",
       " ModuleList(\n",
       "   (0): Linear(in_features=20, out_features=200, bias=True)\n",
       " ),\n",
       " Linear(in_features=200, out_features=100, bias=True))"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderlayers, mu, var, decoderlayers, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "b7466c26-7910-4cea-8932-c6c148f2136e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the data in the data loader and returns the encoded matrix.\n",
    "\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "                mean latent vector\n",
    "                log-variance latent vector\n",
    "        \"\"\"\n",
    "        # Hidden layers\n",
    "        for encoderlayer, encodernorm in zip(self.encoderlayers, self.encodernorms):\n",
    "            x = encoderlayer(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropoutlayer(x)\n",
    "            x = encodernorm(x)\n",
    "\n",
    "        return self.mu(x), self.var(x)\n",
    "def decode(\n",
    "        self, x: torch.Tensor\n",
    "    ) -> tuple[Optional[list[torch.Tensor]], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Decode to the input space from the latent space\n",
    "\n",
    "        Args:\n",
    "            x: sample from latent space distribution\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "                cat_out:\n",
    "                    list of reconstructions of every categorical data class\n",
    "                con_out:\n",
    "                    reconstruction of continuous data\n",
    "        \"\"\"\n",
    "        for decoderlayer, decodernorm in zip(self.decoderlayers, self.decodernorms):\n",
    "            x = decoderlayer(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropoutlayer(x)\n",
    "            x = decodernorm(x)\n",
    "\n",
    "        reconstruction = self.out(x)\n",
    "\n",
    "        # Decompose reconstruction to categorical and continuous variables\n",
    "        # if both types are in the input\n",
    "        cat_out, con_out = None, None\n",
    "        if self.num_categorical > 0:\n",
    "            cat_out = self.decompose_categorical(reconstruction)\n",
    "        if self.num_continuous > 0:\n",
    "            con_out = reconstruction.narrow(\n",
    "                1, self.num_categorical, self.num_continuous\n",
    "            )\n",
    "\n",
    "        return cat_out, con_out\n",
    "\n",
    "def forward(\n",
    "        self, tensor: torch.Tensor\n",
    "    ) -> tuple[list[torch.Tensor], torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward propagate through the VAE network\n",
    "\n",
    "        Args:\n",
    "            tensor (torch.Tensor): input data\n",
    "\n",
    "        Returns:\n",
    "            (tuple): a tuple containing:\n",
    "                cat_out (list): list of reconstructions of every categorical\n",
    "                    data class\n",
    "                con_out (torch.Tensor): reconstructions of continuous data\n",
    "                mu (torch.Tensor): mean latent vector\n",
    "                logvar (torch.Tensor): mean log-variance vector\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(tensor)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        cat_out, con_out = self.decode(z)\n",
    "\n",
    "        return cat_out, con_out, mu, logvar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
