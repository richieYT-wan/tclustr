{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd969b6c-2f24-4fa0-b6ec-e85fb8ae1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABWCAYAAACHBmuvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAABuvAAAbrwFeGpEcAAAEdElEQVR4nO2azStsfxzHX2PGnSLytPA8kzykRkixtFEof4GEIqUoGzsrayvGZjILG3lYiJKFIiULC5ntlIdhPOVhUGaI4bfQmXvdezHf2/ccnV/f12oWn+Z9evU9M99zvm/L6+vrK4q4SPjuCzATSpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYAhsmanp6mrKyMubk5oyKlY9PjSyORCBMTEywtLREMBrHb7UQiET2iDEX6ygqHw3R0dOB2uwkGg+Tm5nJ/f080GgVgdXVVdqRhSJc1PDyMz+ejrKyM1tZWgsEgv56JrK6usrm5KTvWEKTKOjw8ZHFxEYvFwvX1NZOTkwAMDAyQl5cXmxsbG5MZaxhSZS0sLBCNRikuLubi4oKqqipmZ2fp7e19N7e9vc3JyYnMaEOQKmtnZweA6upqPB4PMzMzuFyudzNpaWkAbG1tyYw2BKmyAoEAABUVFdTX1/91RpN1cHAgM9oQpMq6uroCICMj48OZpKQkAEKhkMxoQ5Aq6+HhAYAfP358OGOz2d7NmgmpsqxWKwAWi+Xr4ATzPWlJvWLtFnt8fPxw5vn5GQC73S4z2hCkykpPTwfg5ubmw5lwOAxAZmamzGhDkCqrqKgIgGAw+OGM9sPudDplRhuCVFmVlZXAz/3W37i9vQXe9mJmQ6qspqYm4G3Dube39+FcbW0t+fn5MqMNQaosp9NJS0sL0WiU/v7+2CYVfv5WAX88/pgFi+yaZCgUor29Hb/fj9VqpbS0lLu7O46PjwFoaGhgfHxcZqRhSJcFb6vI6/WyvLzM0dERNpsNl8tFW1sbjY2NsuMMQxdZ/1fMt43+RpQsAZQsAZQsAZQsAZQsAZQsAZQsAUwpKxKJMDY2RlNTEy6Xi7q6Orq6ulhfX9e1U6FL10FPwuEwnZ2d+Hw+EhMTKSkp4ebmho2NDTY2NkhMTNQt23QrS6sHlJeXs7Kywvz8PGtra/T09ADw9PSkW7apVpZWD0hISGBkZIScnBweHx/xeDx4vV7d8021srR6QFVVFcXFxQQCARobG3G73QB0d3fHZj87B/hXTCVLe11dU1MDwNnZGaenp7FOxeDgYOw4bn9/X3q+qW5D7c1rYWEhANnZ2Xg8nndVAavVSjQa5fLyUnq+qWT9Xg9wOBw4HI53M9rh7a+vsWVhqtswnnqAdhqux7+iqWSJ1APimRHFVLLiqQdob8n12JyaSlY89YCXlxcAkpOTpeebSlY89QCtFZ2VlSU931SyvqoHnJ+fx2QVFBRIzzeVrK/qAVNTU7HPn7UP/xVTyfqsHrCwsMDExISu+abalAIMDQ3h9/vx+/00Nzf/UQ9ITU3l7u5Ol2xTrSx4+0ecmZmhr68Pp9PJ7u4uoVCI2tpaRkdHSUlJ0S1bHd8LYLqV9Z0oWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQL8B+8Ugojtu0b4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1.8x1.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime as dt\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import BL62_VALUES, BL62FREQ_VALUES, HLAS, AA_KEYS\n",
    "from src.utils import pkl_load, pkl_dump, get_palette\n",
    "from src.torch_utils import save_checkpoint, load_checkpoint\n",
    "from src.train_eval import predict_model, train_eval_loops\n",
    "from src.models import CDR3bVAE, PairedFVAE\n",
    "from src.metrics import reconstruction_accuracy, VAELoss, PairedVAELoss\n",
    "from src.datasets import CDR3BetaDataset, PairedDataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "mpl.rcParams['figure.dpi'] = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9879959e-927a-4b68-9b23-b56b82c14d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>binder</th>\n",
       "      <th>peptide</th>\n",
       "      <th>original_peptide</th>\n",
       "      <th>TRAV</th>\n",
       "      <th>...</th>\n",
       "      <th>TRBJ</th>\n",
       "      <th>partition</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>allele</th>\n",
       "      <th>origin</th>\n",
       "      <th>original_index</th>\n",
       "      <th>TRBV_gene</th>\n",
       "      <th>TRBJ_gene</th>\n",
       "      <th>TRA_CDR3</th>\n",
       "      <th>TRB_CDR3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KALYS</td>\n",
       "      <td>LLKGGEQ</td>\n",
       "      <td>GTEIGGGTSYGKLT</td>\n",
       "      <td>MNHEY</td>\n",
       "      <td>SMNVEV</td>\n",
       "      <td>ASGTETQY</td>\n",
       "      <td>1</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>TRAV30*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-5*01</td>\n",
       "      <td>2</td>\n",
       "      <td>32208.0</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>TRBV27</td>\n",
       "      <td>TRBJ2-5</td>\n",
       "      <td>CGTEIGGGTSYGKLTF</td>\n",
       "      <td>CASGTETQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRGSQS</td>\n",
       "      <td>IYSNGD</td>\n",
       "      <td>AVNPANARLM</td>\n",
       "      <td>DFQATT</td>\n",
       "      <td>SNEGSKA</td>\n",
       "      <td>SARWGGGTDTQY</td>\n",
       "      <td>1</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-3*01</td>\n",
       "      <td>3</td>\n",
       "      <td>37123.0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>3820.0</td>\n",
       "      <td>TRBV20-1</td>\n",
       "      <td>TRBJ2-3</td>\n",
       "      <td>CAVNPANARLMF</td>\n",
       "      <td>CSARWGGGTDTQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSGFNG</td>\n",
       "      <td>NVLDGL</td>\n",
       "      <td>AVGDDKII</td>\n",
       "      <td>DFQATT</td>\n",
       "      <td>SNEGSKA</td>\n",
       "      <td>SARGLDRGTNEQY</td>\n",
       "      <td>1</td>\n",
       "      <td>AVFDRKSDAK</td>\n",
       "      <td>AVFDRKSDAK</td>\n",
       "      <td>TRAV1-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>3</td>\n",
       "      <td>14961.0</td>\n",
       "      <td>HLA-A*11:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>TRBV20-1</td>\n",
       "      <td>TRBJ2-7</td>\n",
       "      <td>CAVGDDKIIF</td>\n",
       "      <td>CSARGLDRGTNEQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRGSQS</td>\n",
       "      <td>IYSNGD</td>\n",
       "      <td>AVTPGTYKYI</td>\n",
       "      <td>LGHDT</td>\n",
       "      <td>YNNKEL</td>\n",
       "      <td>ASSPGTSIFVAEQY</td>\n",
       "      <td>1</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>ELAGIGILTV</td>\n",
       "      <td>TRAV12-2*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-7*01</td>\n",
       "      <td>0</td>\n",
       "      <td>8197.0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>5933.0</td>\n",
       "      <td>TRBV3-1</td>\n",
       "      <td>TRBJ2-7</td>\n",
       "      <td>CAVTPGTYKYIF</td>\n",
       "      <td>CASSPGTSIFVAEQYF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRDTTYY</td>\n",
       "      <td>RNSFDEQN</td>\n",
       "      <td>AFLYNQGGKLI</td>\n",
       "      <td>SGHDY</td>\n",
       "      <td>FNNNVP</td>\n",
       "      <td>ASSPGSRGNIQY</td>\n",
       "      <td>1</td>\n",
       "      <td>RAKFKQLL</td>\n",
       "      <td>RAKFKQLL</td>\n",
       "      <td>TRAV19*01</td>\n",
       "      <td>...</td>\n",
       "      <td>TRBJ2-4*01</td>\n",
       "      <td>1</td>\n",
       "      <td>23616.0</td>\n",
       "      <td>HLA-B*08:01</td>\n",
       "      <td>10x</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>TRBV12-4</td>\n",
       "      <td>TRBJ2-4</td>\n",
       "      <td>CAFLYNQGGKLIF</td>\n",
       "      <td>CASSPGSRGNIQYF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A1        A2              A3      B1       B2              B3  binder  \\\n",
       "0    KALYS   LLKGGEQ  GTEIGGGTSYGKLT   MNHEY   SMNVEV        ASGTETQY       1   \n",
       "1   DRGSQS    IYSNGD      AVNPANARLM  DFQATT  SNEGSKA    SARWGGGTDTQY       1   \n",
       "2   TSGFNG    NVLDGL        AVGDDKII  DFQATT  SNEGSKA   SARGLDRGTNEQY       1   \n",
       "3   DRGSQS    IYSNGD      AVTPGTYKYI   LGHDT   YNNKEL  ASSPGTSIFVAEQY       1   \n",
       "4  TRDTTYY  RNSFDEQN     AFLYNQGGKLI   SGHDY   FNNNVP    ASSPGSRGNIQY       1   \n",
       "\n",
       "      peptide original_peptide         TRAV  ...        TRBJ partition  \\\n",
       "0   KLGGALQAK        KLGGALQAK    TRAV30*01  ...  TRBJ2-5*01         2   \n",
       "1  ELAGIGILTV       ELAGIGILTV  TRAV12-2*01  ...  TRBJ2-3*01         3   \n",
       "2  AVFDRKSDAK       AVFDRKSDAK   TRAV1-2*01  ...  TRBJ2-7*01         3   \n",
       "3  ELAGIGILTV       ELAGIGILTV  TRAV12-2*01  ...  TRBJ2-7*01         0   \n",
       "4    RAKFKQLL         RAKFKQLL    TRAV19*01  ...  TRBJ2-4*01         1   \n",
       "\n",
       "  Unnamed: 0       allele  origin original_index TRBV_gene  TRBJ_gene  \\\n",
       "0    32208.0  HLA-A*03:01     10x         2627.0    TRBV27    TRBJ2-5   \n",
       "1    37123.0  HLA-A*02:01     10x         3820.0  TRBV20-1    TRBJ2-3   \n",
       "2    14961.0  HLA-A*11:01     10x         3592.0  TRBV20-1    TRBJ2-7   \n",
       "3     8197.0  HLA-A*02:01     10x         5933.0   TRBV3-1    TRBJ2-7   \n",
       "4    23616.0  HLA-B*08:01     10x         2745.0  TRBV12-4    TRBJ2-4   \n",
       "\n",
       "           TRA_CDR3          TRB_CDR3  \n",
       "0  CGTEIGGGTSYGKLTF        CASGTETQYF  \n",
       "1      CAVNPANARLMF    CSARWGGGTDTQYF  \n",
       "2        CAVGDDKIIF   CSARGLDRGTNEQYF  \n",
       "3      CAVTPGTYKYIF  CASSPGTSIFVAEQYF  \n",
       "4     CAFLYNQGGKLIF    CASSPGSRGNIQYF  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/filtered/230927_nettcr_positives_only.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab3dceb-4eb5-4206-b1c3-d14616ceed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TRB_CDR3'].apply(len).max(), df['TRA_CDR3'].apply(len).max(), df['peptide'].apply(len).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d631f-4fd3-493c-8676-084c9143fedd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# paired model / datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3224ac7c-463f-43ed-8146-6c69d986388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import PairedFVAE\n",
    "from src.datasets import PairedDataset\n",
    "from torch.utils.data import SequentialSampler\n",
    "sample = df.sample(3)\n",
    "dataset = PairedDataset(sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(5, SequentialSampler)\n",
    "model = PairedFVAE(max_len_b=23, max_len_a=25, max_len_pep=12, use_a=True, use_b=True, use_pep=True, use_v=False, use_j=False, hidden_dim=10, latent_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4757a279-14c0-40c9-9fa5-df33867a22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the slicing etc works\n",
    "x_true = dataset.x\n",
    "x_hat, mu, logvar = model(x_true)\n",
    "seq_hat, v_hat, j_hat = model.reconstruct_hat(x_hat)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d4fbf6dc-f60c-474b-a102-17b99c994455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  0, 16, 16, 16, 16],\n",
       "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  0, 16, 16, 16, 16],\n",
       "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "125b47ae-c425-49eb-9969-69af6fd44302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.082269087433815, 0, 0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import reconstruction_accuracy\n",
    "reconstruction_accuracy(seq_true, seq_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "207ca046-cc3d-4fff-90b6-55df18931cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=(seq_true!=20).float()\n",
    "true_lens=mask.sum(dim=1)\n",
    "((seq_true==seq_hat).float() * mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba59461b-bb23-4a8c-b0ef-a54912453eb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSASDNMVGAYEQYF\n",
      "CSAEDNMIGANEQYF\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import AA_KEYS\n",
    "from random import randint\n",
    "\n",
    "def apply_mutation(seq, n):\n",
    "    seq = list(seq)  # Convert the sequence to a list of characters\n",
    "    prev_idx = None\n",
    "    idx = prev_idx\n",
    "    for _ in range(n):\n",
    "        while idx == prev_idx:\n",
    "            idx = randint(0, len(seq) - 1)\n",
    "        letter = seq[idx]\n",
    "        while letter == seq[idx]:\n",
    "            letter = AA_KEYS[randint(0, len(AA_KEYS) - 1)]\n",
    "        seq[idx] = letter\n",
    "        prev_idx = idx\n",
    "\n",
    "    return ''.join(seq)  # Convert the list of characters back to a string\n",
    "\n",
    "seq = 'CSASDNMVGAYEQYF'\n",
    "mutated_seq = apply_mutation(seq, 3)\n",
    "print(seq)\n",
    "print(mutated_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a260aff9-e1df-424e-8577-13c18d0e0b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6213971972465515, 0, 0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Doing a fake dataset with small mutations and check the reconstruction accuracy\n",
    "false_sample = sample.copy()\n",
    "false_sample['TRB_CDR3'] = false_sample['TRB_CDR3'].apply(apply_mutation, n=6)\n",
    "false_sample['TRA_CDR3'] = false_sample['TRA_CDR3'].apply(apply_mutation, n=7)\n",
    "false_sample['peptide'] = false_sample['peptide'].apply(apply_mutation, n=2)\n",
    "dataset = PairedDataset(sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(5, SequentialSampler)\n",
    "false_dataset = PairedDataset(false_sample, 23, 25, 12, pad_scale=-20, use_a=True, use_b=True, use_pep=True, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "x_true = dataset.x\n",
    "x_hat = false_dataset.x\n",
    "\n",
    "seq_hat, v_hat, j_hat = model.reconstruct_hat(x_hat)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "reconstruction_accuracy(seq_true, seq_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69aecd0d-5a22-4a20-9461-277c5c420f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairedFVAE(23,25,12,use_pep=True, use_v=False, use_j=False)\n",
    "x_seq_recon, _, _ = model.slice_x(x_hat)\n",
    "x_seq_true, _, _ = model.slice_x(x_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "044963e7-bb69-4b2b-aefc-a6acf3daf5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 60])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5208c3c1-acd0-4c06-a4fe-487bf0565090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 0]) tensor([[ 4.,  9.,  1., 15.,  7.,  0.,  7., 15., 18.,  5., 10., 16., 13., 20.,\n",
      "         20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [ 4.,  0., 19., 15.,  7.,  7., 18.,  5., 11., 19., 16., 13., 20., 20.,\n",
      "         20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.],\n",
      "        [ 4.,  0., 12., 15.,  7.,  6.,  7.,  7., 15.,  5.,  7.,  2., 10.,  9.,\n",
      "         13., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.]]) tensor([[ 0., 19., 13.,  3.,  1., 11., 15.,  3.,  0., 11., 20., 20.],\n",
      "        [ 6., 10.,  0.,  7.,  9.,  7.,  9., 10., 16., 19., 20., 20.],\n",
      "        [ 7.,  9., 10.,  7., 13., 19., 13., 16., 10., 20., 20., 20.]])\n"
     ]
    }
   ],
   "source": [
    "from src.models import PairedFVAE\n",
    "max_len_b=0\n",
    "max_len_a=25\n",
    "max_len_pep=12\n",
    "use_b=False\n",
    "use_a=True\n",
    "use_pep=True\n",
    "dataset = PairedDataset(sample, max_len_b, max_len_a, max_len_pep, pad_scale=-20, use_a=use_a, use_b=use_b, use_pep=use_pep, cdr3b_col='TRB_CDR3', cdr3a_col='TRA_CDR3')\n",
    "loader = dataset.get_dataloader(len(sample), SequentialSampler)\n",
    "x_true = dataset.x\n",
    "model = PairedFVAE(max_len_b, max_len_a, max_len_pep, use_b=use_b, use_a=use_a, use_pep=use_pep)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "print(seq_true[:, :max_len_b].shape, seq_true[:, max_len_b:max_len_b+max_len_a], seq_true[:, max_len_b+max_len_a:])\n",
    "results = predict_model(model, dataset, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "64e394e1-0840-4bcd-acbf-b311baedbaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDR3bVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=511, out_features=255, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=255, out_features=128, bias=True)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (encoder_mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (encoder_logvar): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): SELU()\n",
       "  )\n",
       "  (decoder_sequence): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=255, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=255, out_features=460, bias=True)\n",
       "  )\n",
       "  (decoder_v): Linear(in_features=128, out_features=51, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0892cf7b-fb43-4eb3-8086-a41253ea0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from src.models import CDR3bVAE\n",
    "from src.datasets import CDR3BetaDataset\n",
    "max_len_b=23\n",
    "dataset = CDR3BetaDataset(sample, max_len_b, use_v=True, use_j=False, pad_scale=-20,v_dim=51,cdr3b_col='TRB_CDR3')\n",
    "loader = dataset.get_dataloader(len(sample), SequentialSampler)\n",
    "x_true = dataset.x\n",
    "model = CDR3bVAE(max_len_b, use_v=True, use_j=False, v_dim=51)\n",
    "seq_true, v_true, j_true = model.reconstruct_hat(x_true)\n",
    "results2 = predict_model(model, dataset, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1c9b5448-5350-42f8-9db2-702216ac2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['cdr3a_col']='123'\n",
    "args['cdr3b_col']='None'\n",
    "args['use_a'] = not (args['cdr3a_col']==\"None\")\n",
    "args['use_b'] = not (args['cdr3b_col']==\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "062265a3-6b60-4d49-97af-b9ffaa5f42b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntm = {'x':0.125, 'b':.623, 'c':.2350}\n",
    "np.sum([x for x in ntm.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce60f18-b00c-4e4e-a26b-a29fdd9a4ca2",
   "metadata": {},
   "source": [
    "# Concat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5696c592-4e8a-4652-9062-c36f1d5c913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A2'].apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28b76be0-807d-4fb7-98eb-879fdb1a1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import encode_batch\n",
    "\n",
    "b3 = encode_batch(df['B3'], max_len=23, encoding='BL50LO', pad_scale=-20)\n",
    "a3 = encode_batch(df['A3'], max_len=22, encoding='BL50LO', pad_scale=-20)\n",
    "a2 = encode_batch(df['B2'], max_len=8, encoding='BL50LO', pad_scale=-20)\n",
    "b2 = encode_batch(df['B2'], max_len=7, encoding='BL50LO', pad_scale=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2d2b3a1-e3e2-4b24-81ba-6e294b4437fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 7\n",
      "A2 8\n",
      "A3 22\n",
      "B1 6\n",
      "B2 7\n",
      "B3 23\n"
     ]
    }
   ],
   "source": [
    "print('A1', df['A1'].apply(len).max())\n",
    "print('A2', df['A2'].apply(len).max())\n",
    "print('A3', df['A3'].apply(len).max())\n",
    "print('B1', df['B1'].apply(len).max())\n",
    "print('B2', df['B2'].apply(len).max())\n",
    "print('B3', df['B3'].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "885f9541-2eda-4691-8c55-c8054273d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_first = torch.cat([b3, a3], dim=1).flatten(start_dim=1)\n",
    "flat_first = torch.cat([b3.flatten(start_dim=1), a3.flatten(start_dim=1)], dim=1)\n",
    "assert (cat_first==flat_first).all(), 'Wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9434e1d8-0f84-4a2c-a972-62a40ee1a9a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.,  -2.,  -1.,  -2.,  -1.,  -1.,  -1.,   0.,  -2.,  -1.,  -2.,  -1.,\n",
       "          -1.,  -3.,  -1.,   1.,   0.,  -3.,  -2.,   0.],\n",
       "        [  1.,  -1.,   1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,  -3.,  -3.,   0.,\n",
       "          -2.,  -3.,  -1.,   5.,   2.,  -4.,  -2.,  -2.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   0.,   0.,   2.,  -3.,   2.,   6.,  -3.,   0.,  -4.,  -3.,   1.,\n",
       "          -2.,  -3.,  -1.,  -1.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   1.,   0.,   0.,  -3.,   7.,   2.,  -2.,   1.,  -3.,  -2.,   2.,\n",
       "           0.,  -4.,  -1.,   0.,  -1.,  -1.,  -1.,  -3.],\n",
       "        [ -2.,  -1.,  -2.,  -3.,  -3.,  -1.,  -2.,  -3.,   2.,  -1.,  -1.,  -2.,\n",
       "           0.,   4.,  -3.,  -2.,  -2.,   2.,   8.,  -1.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [ -1.,   0.,   0.,   2.,  -3.,   2.,   6.,  -3.,   0.,  -4.,  -3.,   1.,\n",
       "          -2.,  -3.,  -1.,  -1.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [ -1.,  -4.,  -3.,  -4.,  -2.,  -3.,  -4.,  -4.,  -4.,   5.,   2.,  -3.,\n",
       "           2.,   0.,  -3.,  -3.,  -1.,  -3.,  -1.,   4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [  1.,  -1.,   1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,  -3.,  -3.,   0.,\n",
       "          -2.,  -3.,  -1.,   5.,   2.,  -4.,  -2.,  -2.],\n",
       "        [ -2.,  -1.,  -2.,  -3.,  -3.,  -1.,  -2.,  -3.,   2.,  -1.,  -1.,  -2.,\n",
       "           0.,   4.,  -3.,  -2.,  -2.,   2.,   8.,  -1.],\n",
       "        [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,  -2.,\n",
       "          -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "        [ -1.,   3.,   0.,  -1.,  -3.,   2.,   1.,  -2.,   0.,  -3.,  -3.,   6.,\n",
       "          -2.,  -4.,  -1.,   0.,  -1.,  -3.,  -2.,  -3.],\n",
       "        [ -2.,  -3.,  -4.,  -4.,  -2.,  -2.,  -3.,  -4.,  -3.,   2.,   5.,  -3.,\n",
       "           3.,   1.,  -4.,  -3.,  -1.,  -2.,  -1.,   1.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,  -1.,\n",
       "          -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "        [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "         -20., -20., -20., -20., -20., -20., -20., -20.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_first.view(-1, 23+22, 20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "352c452f-5bff-46b1-8242-ddad4f384508",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import CDR3bVAE, FullTCRVAE\n",
    "model = CDR3bVAE(max_len = 23+22, pad_scale=-20, use_v=False, use_j=False)\n",
    "seq_hat, _, _ = model.reconstruct_hat(flat_first)\n",
    "seq, v, j = model.slice_x(flat_first)\n",
    "(seq_hat != 20).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34268783-46b7-4fce-b7ea-08ba10968370",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m max_len_b2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m max_len_b3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([x\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3]]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxd\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: xd"
     ]
    }
   ],
   "source": [
    "max_len_a1=0\n",
    "max_len_a2=0\n",
    "max_len_a3=0\n",
    "max_len_b1=0\n",
    "max_len_b2=0\n",
    "max_len_b3=0\n",
    "\n",
    "assert not all([x==0 for x in [max_len_a1, max_len_a2, max_len_a3, max_len_b1, max_len_b2, max_len_b3]]), 'xd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a076dbe-8151-4887-8d23-f572cc235eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import FullTCRVAE\n",
    "from src.datasets import FullTCRDataset\n",
    "from torch.utils.data import SequentialSampler\n",
    "fulltcr_dataset = FullTCRDataset(df, 7, 8, 22, 6, 7, 23, pad_scale=-20)\n",
    "fulltcr_loader = fulltcr_dataset.get_dataloader(1024, SequentialSampler)\n",
    "fulltcr_model = FullTCRVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b94ad740-75d8-4bfc-bea8-68c80b8ae0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfulltcr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/tclustr/src/models.py:47\u001b[0m, in \u001b[0;36mNetParent.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Work around, so we can get model.device for all NetParent\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNetParent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "fulltcr_model.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894c3df-2f4c-47f7-b3e5-68d3df8bcd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
