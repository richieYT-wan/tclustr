{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76862371-4c85-4a82-879c-4a6fed0876a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABWCAYAAACHBmuvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAABuvAAAbrwFeGpEcAAAEdElEQVR4nO2azStsfxzHX2PGnSLytPA8kzykRkixtFEof4GEIqUoGzsrayvGZjILG3lYiJKFIiULC5ntlIdhPOVhUGaI4bfQmXvdezHf2/ccnV/f12oWn+Z9evU9M99zvm/L6+vrK4q4SPjuCzATSpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYAhsmanp6mrKyMubk5oyKlY9PjSyORCBMTEywtLREMBrHb7UQiET2iDEX6ygqHw3R0dOB2uwkGg+Tm5nJ/f080GgVgdXVVdqRhSJc1PDyMz+ejrKyM1tZWgsEgv56JrK6usrm5KTvWEKTKOjw8ZHFxEYvFwvX1NZOTkwAMDAyQl5cXmxsbG5MZaxhSZS0sLBCNRikuLubi4oKqqipmZ2fp7e19N7e9vc3JyYnMaEOQKmtnZweA6upqPB4PMzMzuFyudzNpaWkAbG1tyYw2BKmyAoEAABUVFdTX1/91RpN1cHAgM9oQpMq6uroCICMj48OZpKQkAEKhkMxoQ5Aq6+HhAYAfP358OGOz2d7NmgmpsqxWKwAWi+Xr4ATzPWlJvWLtFnt8fPxw5vn5GQC73S4z2hCkykpPTwfg5ubmw5lwOAxAZmamzGhDkCqrqKgIgGAw+OGM9sPudDplRhuCVFmVlZXAz/3W37i9vQXe9mJmQ6qspqYm4G3Dube39+FcbW0t+fn5MqMNQaosp9NJS0sL0WiU/v7+2CYVfv5WAX88/pgFi+yaZCgUor29Hb/fj9VqpbS0lLu7O46PjwFoaGhgfHxcZqRhSJcFb6vI6/WyvLzM0dERNpsNl8tFW1sbjY2NsuMMQxdZ/1fMt43+RpQsAZQsAZQsAZQsAZQsAZQsAZQsAUwpKxKJMDY2RlNTEy6Xi7q6Orq6ulhfX9e1U6FL10FPwuEwnZ2d+Hw+EhMTKSkp4ebmho2NDTY2NkhMTNQt23QrS6sHlJeXs7Kywvz8PGtra/T09ADw9PSkW7apVpZWD0hISGBkZIScnBweHx/xeDx4vV7d8021srR6QFVVFcXFxQQCARobG3G73QB0d3fHZj87B/hXTCVLe11dU1MDwNnZGaenp7FOxeDgYOw4bn9/X3q+qW5D7c1rYWEhANnZ2Xg8nndVAavVSjQa5fLyUnq+qWT9Xg9wOBw4HI53M9rh7a+vsWVhqtswnnqAdhqux7+iqWSJ1APimRHFVLLiqQdob8n12JyaSlY89YCXlxcAkpOTpeebSlY89QCtFZ2VlSU931SyvqoHnJ+fx2QVFBRIzzeVrK/qAVNTU7HPn7UP/xVTyfqsHrCwsMDExISu+abalAIMDQ3h9/vx+/00Nzf/UQ9ITU3l7u5Ol2xTrSx4+0ecmZmhr68Pp9PJ7u4uoVCI2tpaRkdHSUlJ0S1bHd8LYLqV9Z0oWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQL8B+8Ugojtu0b4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1.8x1.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime as dt\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import BL62_VALUES, BL62FREQ_VALUES, HLAS, AA_KEYS\n",
    "from src.metrics import reconstruction_accuracy, VAELoss\n",
    "from src.utils import pkl_load, pkl_dump, get_palette\n",
    "from src.torch_utils import save_checkpoint, load_checkpoint\n",
    "from src.train_eval import predict_model, train_eval_loops\n",
    "from src.models import FullFVAE\n",
    "from src.datasets import CDR3BetaDataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "mpl.rcParams['figure.dpi'] = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff43714a-feff-43e9-a6dc-806eb47fcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "Fold: 0Best valid seq acc: 0.9381558377693086\n",
      "Best valid V acc: 0.9215917117965623\n",
      "Best valid J acc: 0.993407110901813\n",
      "\n",
      "1\n",
      "Fold: 1Best valid seq acc: 0.9566856574804349\n",
      "Best valid V acc: 0.819038642789821\n",
      "Best valid J acc: 0.9957587181903864\n",
      "\n",
      "2\n",
      "Fold: 2Best valid seq acc: 0.9571465191206466\n",
      "Best valid V acc: 0.8235571260306243\n",
      "Best valid J acc: 0.9967020023557126\n",
      "\n",
      "3\n",
      "Fold: 3Best valid seq acc: 0.949859586027519\n",
      "Best valid V acc: 0.7937293729372937\n",
      "Best valid J acc: 0.9896275341819897\n",
      "\n",
      "4\n",
      "Fold: 4Best valid seq acc: 0.9535165230573757\n",
      "Best valid V acc: 0.9065817409766455\n",
      "Best valid J acc: 0.9900920028308563\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'\\n{i}')\n",
    "    %cat ../output/FirstTest_230926_1923_bb76k/FirstTestKFOLD_bb76k_KFold_{i}_230926_1923_bb76k/args_FirstTestKFOLD_bb76k_KFold_{i}_230926_1923_bb76k.txt | tail -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ff744-08db-4359-9ab5-e6e7596cf099",
   "metadata": {},
   "source": [
    "Probly don't need to have that much weight on J gene but for V gene 2.5 seems good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9e9a390-c777-4369-88de-b4b9a4299610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.png\n",
      "args_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.txt\n",
      "checkpoint_best_fold00_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.pt\n",
      "train_losses_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.pkl\n",
      "train_metrics_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.pkl\n",
      "valid_losses_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.pkl\n",
      "valid_metrics_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.pkl\n",
      "valid_predictions_kcv_230921_nettcr_immrepnegs_noswap_f00_FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k.csv\n"
     ]
    }
   ],
   "source": [
    "%ls ../output/FirstTest_230926_1923_bb76k/FirstTestKFOLD_bb76k_KFold_0_230926_1923_bb76k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a79c1-fe06-45e9-a3e7-44584571ca82",
   "metadata": {},
   "source": [
    "# Reloading models and preds from KCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b60f7366-c3bb-4d66-b93a-059c6cd7287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kcv_df.TRBV_gene.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "559b5089-7692-4a6d-9231-a82ed103aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init stuff\n",
    "kcv_df = pd.read_csv('../data/filtered/230921_nettcr_immrepnegs_noswap.csv')\n",
    "test_df = pd.read_csv('../data/filtered/230921_vdjdb_mcpas_filtered_concat_cdr3b_vjgenes')\n",
    "# Re-init / write down params here ; Taken from the args.txt\n",
    "max_len, encoding, pad_scale = 23, 'BL50LO', -20\n",
    "cdr3b_col, v_col, j_col = 'B3', 'TRBV_gene', 'TRBJ_gene'\n",
    "use_v, use_j, v_dim, j_dim = True, True, 51, 13\n",
    "hidden_dim, latent_dim = 256, 128\n",
    "lr, weight_decay = 5e-4, 1e-4\n",
    "loss_weights = {'weight_seq':3, 'weight_kld':1, 'weight_v':2.5, 'weight_j':2}\n",
    "n_epochs, batch_size = 2000, 256\n",
    "# Remaking dataset-loaders\n",
    "total_dataset = CDR3BetaDataset(kcv_df, max_len, encoding, pad_scale, cdr3b_col, use_v, use_j, v_col, j_col, v_dim, j_dim, v_map=None, j_map = None)\n",
    "total_loader = total_dataset.get_dataloader(batch_size, RandomSampler)\n",
    "test_dataset = CDR3BetaDataset(kcv_df, max_len, encoding, pad_scale, cdr3b_col, use_v, use_j, v_col, j_col, v_dim, j_dim, v_map= total_dataset.v_map, j_map = total_dataset.j_map)\n",
    "test_loader = test_dataset.get_dataloader(batch_size, SequentialSampler)\n",
    "folder = '../output/FirstTest_230926_1923_bb76k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3db74-a38a-4cae-8a68-ec554d42996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out, I didn't think that different partitions in the train dataset would have different v/j maps.\n",
    "# As such, I need to save it here and reload it everytime (HARDCODED BAD BEHAVIOUR BUT NO WORKAROUND BECAUSE I NEED TO MAKE SURE THINGS MATCH BETWEEN FOLDS)\n",
    "# Also need to fix the weights on V and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c020283-70b8-48c0-ad8d-898d5b43d751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/riwa/Documents/code/tclustr/data/Matrices/230927_nettcr_dataset_vmap.pkl saved.\n",
      "/Users/riwa/Documents/code/tclustr/data/Matrices/230927_nettcr_dataset_jmap.pkl saved.\n"
     ]
    }
   ],
   "source": [
    "pkl_dump(total_dataset.v_map, '../data/Matrices/230927_nettcr_dataset_vmap.pkl')\n",
    "pkl_dump(total_dataset.j_map, '../data/Matrices/230927_nettcr_dataset_jmap.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e39ff86-13c8-4f33-a412-6c83fc2c7042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['encoder.0.weight', 'encoder.0.bias', 'encoder.2.weight', 'encoder.2.bias', 'encoder_mu.weight', 'encoder_mu.bias', 'encoder_logvar.weight', 'encoder_logvar.bias', 'decoder.0.weight', 'decoder.0.bias', 'decoder.2.weight', 'decoder.2.bias', 'decoder_sequence.0.weight', 'decoder_sequence.0.bias', 'decoder_sequence.2.weight', 'decoder_sequence.2.bias', 'decoder_v.weight', 'decoder_v.bias', 'decoder_j.weight', 'decoder_j.bias'])\n",
      "0\n",
      "torch.Size([261, 523])\n",
      "odict_keys(['encoder.0.weight', 'encoder.0.bias', 'encoder.2.weight', 'encoder.2.bias', 'encoder_mu.weight', 'encoder_mu.bias', 'encoder_logvar.weight', 'encoder_logvar.bias', 'decoder.0.weight', 'decoder.0.bias', 'decoder.2.weight', 'decoder.2.bias', 'decoder_sequence.0.weight', 'decoder_sequence.0.bias', 'decoder_sequence.2.weight', 'decoder_sequence.2.bias', 'decoder_v.weight', 'decoder_v.bias', 'decoder_j.weight', 'decoder_j.bias'])\n",
      "3\n",
      "torch.Size([261, 523])\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for i in range(5):\n",
    "    fn = f'{folder}FirstTestKFOLD_bb76k_KFold_{i}_230926_1923_bb76k/checkpoint_best_fold{i:02}_kcv_230921_nettcr_immrepnegs_noswap_f{i:02}_FirstTestKFOLD_bb76k_KFold_{i}_230926_1923_bb76k.pt'\n",
    "    try:\n",
    "        models[i] = load_checkpoint(FullFVAE(max_len, encoding, pad_scale, 20, use_v, use_j, v_dim, j_dim, nn.SELU(), hidden_dim, latent_dim), fn)\n",
    "    except:\n",
    "        print(i)\n",
    "        d = torch.load(fn)\n",
    "        print(d['encoder.0.weight'].shape)\n",
    "    # might as well retrain all folds with adjusted v/j/kld weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aeca283-73b4-40f9-84ef-35c3c6461b58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: FullFVAE(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=524, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (encoder_mu): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (encoder_logvar): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (decoder): Sequential(\n",
       "     (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (decoder_sequence): Sequential(\n",
       "     (0): Linear(in_features=256, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=460, bias=True)\n",
       "   )\n",
       "   (decoder_v): Linear(in_features=256, out_features=51, bias=True)\n",
       "   (decoder_j): Linear(in_features=256, out_features=13, bias=True)\n",
       " ),\n",
       " 2: FullFVAE(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=524, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (encoder_mu): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (encoder_logvar): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (decoder): Sequential(\n",
       "     (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (decoder_sequence): Sequential(\n",
       "     (0): Linear(in_features=256, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=460, bias=True)\n",
       "   )\n",
       "   (decoder_v): Linear(in_features=256, out_features=51, bias=True)\n",
       "   (decoder_j): Linear(in_features=256, out_features=13, bias=True)\n",
       " ),\n",
       " 4: FullFVAE(\n",
       "   (encoder): Sequential(\n",
       "     (0): Linear(in_features=524, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (encoder_mu): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (encoder_logvar): Linear(in_features=256, out_features=128, bias=True)\n",
       "   (decoder): Sequential(\n",
       "     (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): SELU()\n",
       "   )\n",
       "   (decoder_sequence): Sequential(\n",
       "     (0): Linear(in_features=256, out_features=262, bias=True)\n",
       "     (1): SELU()\n",
       "     (2): Linear(in_features=262, out_features=460, bias=True)\n",
       "   )\n",
       "   (decoder_v): Linear(in_features=256, out_features=51, bias=True)\n",
       "   (decoder_j): Linear(in_features=256, out_features=13, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
