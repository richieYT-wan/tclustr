{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573eb6bc-1a4d-4339-9399-6520bfe6e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAuCAYAAABeUotNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACXElEQVR4nO2WQUrrUBSG/4ZCoW1iSLVIkdBBAx1kCQEX0ImgoMsQHAbp3IkrcJCZIELpuIXuQ0vNSKOI3CSVSMXj5DWQUmrPI6m8Rz7I4B6Sky83Nzd/gYgI/wDSbwusSy6aNrlo2uSiaZOLps1fi768vKDVamE0GqWoswJi4nkeWZZFkiQRADo8PKTZbMZtw4Yt2m63qVwuk+M4BICazSZdXFxk4ZagQLR+KLm/v4dhGHBdF7quo1Ao4Pz8HI7jwHXdxLm+78P3/Xj89fWF6XQKWZbRaDQgScxVx3mqXq9HmqbFYwB0dXVFAOjt7S1x7v7+PgFYeozHY/aMFjkPFQQBKpVKolYqlQAAYRhCVdW43u/3EzMqhIBpmgAATdN4swmAJVqpVPD+/p6ofXx8AABkWU7UFUWBoiiJ8Rz2awdzezJNE6+vr/A8L649PDxgb28PW1tb7Juz4K4Vy7Lo5OSEfN+Pv/put/vjdUKIeI0KIdhrlC369PRER0dHVKvVaGdnh87Ozujz8/PH66IoItu2ybZtiqKILcrann6T//9fv2ly0bTZiOjz8zMODg6gqio0TYOqqhgOh6weGxE9Pj5GtVrF7e0tZFmGEAI3Nze8JuwNjcnd3R0BoMvLS9J1na6vrwkA1et1Vp/MReeJ6/HxMQ7Y+POHWkxcq8j81c8T1+7uLorFZAYKw3DtPpmLLktccxYT1yoyF12WuABge3ublbgyFzUMA5Zl4fT0FEEQYDKZAAA6nQ6vUUbfUILFxAWABoMBq0eentImF02bXDRtctG0yUXTJhdNm2/tMzRBDgOZWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1x1 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Load models together\n",
    "from src.torch_utils import load_model_full\n",
    "from src.utils import get_class_initcode_keys\n",
    "from torch.utils.data import SequentialSampler\n",
    "from src.datasets import *\n",
    "from src.models import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, add_median_labels, get_palette\n",
    "from src.data_processing import BL62_VALUES, BL62FREQ_VALUES, HLAS, AA_KEYS\n",
    "from src.utils import pkl_load, pkl_dump, get_palette\n",
    "from src.sim_utils import make_dist_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.torch_utils import save_checkpoint, load_checkpoint\n",
    "from src.train_eval import predict_model, train_eval_loops\n",
    "from src.models import FullTCRVAE, TwoStageVAECLF\n",
    "from src.multimodal_datasets import MultimodalMarginalLatentDataset\n",
    "from src.multimodal_models import BSSVAE, JMVAE\n",
    "from src.multimodal_train_eval import predict_multimodal\n",
    "from src.metrics import reconstruction_accuracy, VAELoss, TripletLoss, CombinedVAELoss, compute_cosine_distance\n",
    "from src.datasets import TCRSpecificDataset, FullTCRDataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "mpl.rcParams['figure.dpi'] = 180\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a947472f-bd0d-418f-bd74-663295e2b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44e902f-d527-4281-b8d6-7feaa08d5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_noswap = pd.read_csv('../data/multimodal/240326_nettcr_paired_NOswaps.csv')\n",
    "new_df_wswap = pd.read_csv('../data/multimodal/240326_nettcr_paired_withswaps.csv')\n",
    "new_df_filt = pd.read_csv('../data/filtered/240418_nettcr_expanded_20binders_17pep_POSONLY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002a4fb-fe69-4b93-b251-5fd850cf6fe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# fct defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6670b831-0876-49df-9b9d-ff33d96f6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_df(model, df, dataset_params:dict=None):\n",
    "    \n",
    "    # Init dataset and pred fct depending on model type\n",
    "    dataset_params = dict(max_len_a1=7, max_len_a2=8, max_len_a3=22,\n",
    "                          max_len_b1=6, max_len_b2=7, max_len_b3=23, max_len_pep=0,\n",
    "                          encoding='BL50LO', pad_scale=-20,\n",
    "                          a1_col='A1', a2_col='A2', a3_col='A3', b1_col='B1', b2_col='B2', b3_col='B3',\n",
    "                          pep_col='peptide') if dataset_params is None else dataset_params\n",
    "    \n",
    "    if hasattr(model, 'vae'):\n",
    "        model = model.vae\n",
    "        if model.max_len>7+8+22+6+7+23:\n",
    "            dataset_params['max_len_pep']=12\n",
    "        else:\n",
    "            dataset_params['max_len_pep']=0\n",
    "            \n",
    "    dataset_params['add_positional_encoding'] = model.add_positional_encoding\n",
    "\n",
    "    if type(model) == FullTCRVAE:\n",
    "        print(dataset_params)\n",
    "        dataset = FullTCRDataset(df, **dataset_params)\n",
    "        dataloader = dataset.get_dataloader(512, SequentialSampler)\n",
    "        latent_df = predict_model(model, dataset, dataloader)\n",
    "        \n",
    "    elif type(model) in [BSSVAE, JMVAE]:\n",
    "        pred_fct = predict_multimodal\n",
    "        dataset_params['pair_only'] = True\n",
    "        dataset_params['return_pair'] = type(model)==JMVAE\n",
    "        dataset_params['modality']='tcr'\n",
    "        dataset = MultimodalMarginalLatentDataset(model, df, **dataset_params)\n",
    "        latent_df = df.copy()\n",
    "        zdim = dataset.z.shape[1]\n",
    "        latent_df[[f'z_{i}' for i in range(zdim)]] = dataset.z\n",
    "\n",
    "    return latent_df\n",
    "\n",
    "def get_distances_labels_from_latent(latent_df, label_col='peptide', seq_cols= ('A1','A2','A3','B1','B2','B3')):\n",
    "    # Columns for making distmatrix\n",
    "    rest_cols = list(x for x in latent_df.columns if x in ['peptide', 'original_peptide','origin', 'binder'])\n",
    "    # Getting distmatrix and arrays\n",
    "    dist_matrix = make_dist_matrix(latent_df, label_col, seq_cols, cols=rest_cols)\n",
    "    dist_array = dist_matrix.iloc[:len(dist_matrix), :len(dist_matrix)].values\n",
    "    # Getting label encoder and features for computing metrics\n",
    "    features = latent_df[[z for z in latent_df.columns if z.startswith('z_')]].values\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = latent_df[label_col].values\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    return dist_matrix, dist_array, features, labels, encoded_labels, label_encoder\n",
    "\n",
    "def get_merged_distances_labels(dist_matrix, original_df, index_tcr_df, label_col='peptide', query_subset=None):\n",
    "    # Assumes a square matrix with no other columns, and that the original_df and index_tcr_df match\n",
    "    merged = pd.merge(index_tcr_df, original_df[[x for x in original_df.columns if x in['seq_id','peptide','partition','binder','origin','fulltcr']]],\n",
    "         left_on=['q_index', 'tcr'], right_on=['seq_id','fulltcr'])\n",
    "    \n",
    "    assert((merged['seq_id']==merged['q_index']).all() and (merged['tcr']==merged['fulltcr']).all()),'fuck'\n",
    "    merged = merged.set_index('q_index')[[x for x in merged.columns if x in ['peptide','partition','binder','origin']]]\n",
    "    merged_dist_matrix = pd.merge(dist_matrix, merged, left_index=True,right_index=True)\n",
    "    extra_cols = merged_dist_matrix.columns.difference(dist_matrix.columns)\n",
    "    \n",
    "    if query_subset is not None:\n",
    "        query = merged_dist_matrix.query(query_subset)\n",
    "        merged_dist_matrix = query[list(str(x) for x in query.index)+list(extra_cols)]\n",
    "    \n",
    "    return merged_dist_matrix, extra_cols\n",
    "\n",
    "def get_distances_labels_from_distmatrix(dist_matrix, original_df, index_tcr_df, label_col='peptide', query_subset=None):\n",
    "    merged_dist_matrix, extra_cols = get_merged_distances_labels(dist_matrix, original_df, index_tcr_df, label_col, query_subset)\n",
    "    dist_array = merged_dist_matrix.iloc[:,:-len(extra_cols)].values\n",
    "    features = torch.randn([dist_array.shape[0], 3])\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = merged_dist_matrix[label_col].values\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    return merged_dist_matrix, dist_array, features, labels, encoded_labels, label_encoder\n",
    "\n",
    "def cluster_all_thresholds(dist_array, features, labels, encoded_labels, label_encoder,\n",
    "                           decimals=5, n_points=1500):\n",
    "    # Getting clustering at all thresholds\n",
    "    limits = get_linspace(dist_array, decimals, n_points)\n",
    "    results = []\n",
    "    for t in tqdm(limits):\n",
    "        c = AgglomerativeClustering(n_clusters=None, metric='precomputed', distance_threshold=t, linkage='complete')\n",
    "        c.fit(dist_array)\n",
    "        results.append(get_all_metrics(t, features, c, dist_array, labels, encoded_labels, label_encoder))\n",
    "    results = pd.DataFrame(results)\n",
    "    results['retention'] = (dist_array.shape[0]-results['n_singletons']) / dist_array.shape[0]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e89d6e-41dc-4d0e-95c6-b36b7173711d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_model(folder, map_location='cpu'):\n",
    "    pt = glob.glob(folder+'/*checkpoint_best*.pt')\n",
    "    pt = [x for x in pt if 'interval' not in x][0]\n",
    "    js = glob.glob(folder+'/*checkpoint*.json')[0]\n",
    "    model = load_model_full(pt, js, map_location='cpu')\n",
    "    # Extract the vae part if the model comes from a two stage VAE\n",
    "    if type(model)==TwoStageVAECLF:\n",
    "        model = model.vae\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_purity(counts):\n",
    "    # Purity in absolute % of a cluster, taking the majority label \n",
    "    # high = better\n",
    "    sorted_counts = dict(sorted(counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_counts[list(sorted_counts.keys())[0]] / sum(sorted_counts.values())\n",
    "    \n",
    "def get_mixity(counts):\n",
    "    # how many different labels are inside a cluster, weighted by the number of members\n",
    "    # low = better\n",
    "    return len(counts.keys()) / sum(counts.values())\n",
    "    \n",
    "def get_coherence(dist_array):\n",
    "    # Assumes dist_array is the subset of the distance array for a given cluster label\n",
    "    # mean distance within a cluster\n",
    "    # low = better\n",
    "\n",
    "    # get upper triangle mask without the diagonale\n",
    "    mask = np.triu(np.ones(dist_array.shape), k=0) - np.eye(dist_array.shape[0])\n",
    "    flat_array = dist_array[mask==1]\n",
    "    return np.mean(flat_array)\n",
    "\n",
    "def get_purity_mixity_coherence(cluster_label:int, \n",
    "                                true_labels:list, \n",
    "                                pred_labels:list, \n",
    "                                dist_array:np.array,\n",
    "                                label_encoder):\n",
    "    \"\"\"\n",
    "        For a given cluster label (int) returned by clustering.labels_, \n",
    "        Return the purity, mixity, coherence, cluster_size, and scale (==cluster_size/total_size)\n",
    "        scale should be used to get a weighted average metric at the end\n",
    "    \"\"\"\n",
    "    indices = np.where(pred_labels==cluster_label)[0]\n",
    "    cluster_size = len(indices)\n",
    "    if cluster_size<=1:\n",
    "        # return np.nan, np.nan, np.nan, 1, 1/len(true_labels)\n",
    "        return {'purity':np.nan, 'coherence':np.nan, 'cluster_size':1}\n",
    "\n",
    "    # Query the subset of the true labels belonging to this cluster using indices \n",
    "    # Convert to int label encodings in order to use np.bincount to get purity and mixity\n",
    "    subset = true_labels[indices]\n",
    "    encoded_subset = label_encoder.transform(subset)\n",
    "    counts = {i:k for i,k in enumerate(np.bincount(encoded_subset)) if k>0}\n",
    "    purity = get_purity(counts)\n",
    "    # mixity = get_mixity(counts)\n",
    "    # index the distance matrix and return the mean distance within this cluster (i.e. coherence)\n",
    "    coherence = get_coherence(dist_array[indices][:, indices])\n",
    "    \n",
    "    # return purity, mixity, coherence, cluster_size, cluster_size / len(true_labels)\n",
    "    return {'purity':purity, 'coherence':coherence, 'cluster_size':cluster_size}\n",
    "\n",
    "def get_all_metrics(t, features, c, array, true_labels, encoded_labels, label_encoder):\n",
    "    n_cluster = np.sum((np.bincount(c.labels_)>1))\n",
    "    n_singletons = (np.bincount(c.labels_)==1).sum()\n",
    "    try:\n",
    "        s_score = silhouette_score(features, c.labels_, metric='cosine')\n",
    "    except:\n",
    "        s_score = np.nan\n",
    "    try:\n",
    "        c_score = ch_score(features, c.labels_)\n",
    "    except:\n",
    "        c_score = np.nan\n",
    "    try:\n",
    "        d_score = db_score(features, c.labels_)\n",
    "    except:\n",
    "        d_score = np.nan\n",
    "    try:\n",
    "        ari_score = adjusted_rand_score(encoded_labels, c.labels_)\n",
    "    except:\n",
    "        ari_score = np.nan\n",
    "    \n",
    "    xd = pd.concat([pd.DataFrame(get_purity_mixity_coherence(k, true_labels, c.labels_, array, label_encoder), index=[0])\n",
    "                    for k in set(c.labels_)]).dropna()\n",
    "    mean_purity = xd['purity'].mean()\n",
    "    mean_coherence = xd['coherence'].mean()\n",
    "    mean_cs = xd['cluster_size'].mean()\n",
    "    nc_07 = len(xd.query('purity>=0.7'))\n",
    "    return {'threshold':t, \n",
    "            'n_cluster':n_cluster, 'n_singletons':n_singletons,\n",
    "            'n_cluster_over_70p':nc_07,\n",
    "            'mean_purity':xd['purity'].mean(), \n",
    "            'min_purity':xd['purity'].min(), \n",
    "            'max_purity':xd['purity'].max(), \n",
    "            'mean_coherence':xd['coherence'].mean(), \n",
    "            'min_coherence':xd['coherence'].min(), \n",
    "            'max_coherence':xd['coherence'].max(), \n",
    "            'mean_cluster_size': xd['cluster_size'].mean(),\n",
    "            'min_cluster_size': xd['cluster_size'].min(),\n",
    "            'max_cluster_size': xd['cluster_size'].max(),\n",
    "            'silhouette':s_score,\n",
    "            'ch_index':c_score, 'db_index':d_score, 'ARI':ari_score}\n",
    "\n",
    "def get_bounds(array, decimals=5):\n",
    "    lower_bound = array[array>0].min()\n",
    "    upper_bound = array.max()\n",
    "    factor = 10 ** decimals\n",
    "    return np.floor(lower_bound * factor)/factor, np.ceil(upper_bound*factor)/factor\n",
    "\n",
    "\n",
    "def get_linspace(array, decimals=5, n_points=1500):\n",
    "    return np.round(np.linspace(*get_bounds(array, decimals), n_points), decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bacd23-bfd4-4de0-8618-368a386d4a46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def vae_clustering_pipeline(model_folder, input_df, name, dataset_params=None, n_points=500):\n",
    "    model = get_model(model_folder, map_location='cpu')\n",
    "    latent_df = get_latent_df(model, input_df, dataset_params)\n",
    "    dist_matrix, dist_array, features, labels, encoded_labels, label_encoder = get_distances_labels(latent_df)\n",
    "    results = cluster_all_thresholds(dist_array, features, labels, encoded_labels, label_encoder, n_points=n_points)\n",
    "    results['input_type'] = name\n",
    "    return results\n",
    "\n",
    "def plot_pipeline(results, b, plot_title = 'None', fig_fn = None, filter=None, palette=None, more=False, add_cluster_size=False):\n",
    "    runs = pd.concat([b, results])\n",
    "    # plotting options\n",
    "    if filter is None:\n",
    "        filter = ['TBCRalign', 'KernelSim', 'tcrdist3'] + list(results.input_type.unique())\n",
    "\n",
    "    if palette is None:\n",
    "        palette='gnuplot2'\n",
    "    if more:\n",
    "        palette = get_palette(palette, n_colors=len(filter)-3)\n",
    "    else:\n",
    "        palette = sns.color_palette(palette, n_colors=len(filter)-3)\n",
    "\n",
    "    sns.set_palette(palette)\n",
    "    f,a = plt.subplots(1, 1, figsize=(9,9))\n",
    "    a.set_xlim([0,1])\n",
    "    a.set_ylim([0,1])\n",
    "    a.set_xlabel('Retention', fontweight='semibold', fontsize=14)\n",
    "    a.set_ylabel('Avg Purity', fontweight='semibold', fontsize=14)\n",
    "    # Setting major ticks\n",
    "    major_ticks = np.arange(0, 1.1, 0.1)\n",
    "    a.set_xticks(major_ticks)\n",
    "    a.set_yticks(major_ticks)\n",
    "    # Setting minor ticks\n",
    "    minor_ticks = np.arange(0, 1.1, 0.05)\n",
    "    a.set_xticks(minor_ticks, minor=True)\n",
    "    a.set_yticks(minor_ticks, minor=True)\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    print(runs.duplicated().any())\n",
    "    if add_cluster_size:\n",
    "        ax2 = a.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_yscale('log', base=2)\n",
    "        \n",
    "    for i, input_type in enumerate(filter):\n",
    "        query = runs.query('input_type==@input_type')\n",
    "        retentions = query['retention'].values[1:-1]\n",
    "        purities = query['mean_purity'].values[1:-1]\n",
    "        print(input_type, '\\t', round(get_retpur_auc(retentions, purities),4))\n",
    "        ls = '-' if i%2==0 else '--'\n",
    "        if add_cluster_size:\n",
    "            cluster_sizes = query['mean_cluster_size'].values[1:-1]\n",
    "        # Plotting baselines with fixed styles colors etc\n",
    "        if input_type==\"TBCRalign\":\n",
    "            a.plot(retentions, purities, label='TBCRalign', ls=':', c='k', lw=1.)\n",
    "            if add_cluster_size:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='x', lw=0.5, s=8, c='k')\n",
    "        elif input_type==\"KernelSim\":\n",
    "            a.plot(retentions, purities, label='KernelSim', ls=':', c='m', lw=1.)\n",
    "            if add_cluster_size:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='v', lw=0.1, s=8, c='m')\n",
    "        elif input_type==\"tcrdist3\":\n",
    "            a.plot(retentions, purities, label='tcrdist3', ls=':', c='y', lw=1.)\n",
    "            if add_cluster_size:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='*', lw=0.1, s=8, c='y')\n",
    "        # Plotting the actual things\n",
    "        else:\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_').replace('_',' ').replace('checkpoint best',''), ls=ls, lw=1.)\n",
    "            if add_cluster_size:\n",
    "                ax2.scatter(retentions, cluster_sizes, label=input_type.lstrip('_'), marker='+', lw=1.15, s=12)\n",
    "        \n",
    "    a.axhline(0.6, label='60% purity cut-off', ls=':', lw=.75, c='m')\n",
    "    a.axhline(0.7, label='70% purity cut-off', ls=':', lw=.75, c='c')\n",
    "    a.axhline(0.8, label='80% purity cut-off', ls=':', lw=.75, c='y')\n",
    "    \n",
    "    a.legend(title='distance matrix', title_fontproperties={'size':14, 'weight':'semibold'}, prop={'weight':'semibold','size':12})\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    f.suptitle(f'{plot_title}', fontweight='semibold', fontsize=15)\n",
    "    f.tight_layout()\n",
    "    if fig_fn is not None:\n",
    "        f.savefig(f'../output/240411_ClusteringTests/{fig_fn}.png', dpi=200)\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5874d8-1cb3-47be-ab7d-faa39ab6d26e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_curve_clustersizes(run, filter=None):\n",
    "    if filter is None:\n",
    "        filter = run.input_type.unique()\n",
    "    else:\n",
    "        if ['TBCRalign'] not in filter:\n",
    "            filter = ['TBCRalign']+filter\n",
    "        if ['tcrdist3'] not in filter:\n",
    "            filter = ['tcrdist3']+filter\n",
    "            \n",
    "    sns.set_palette('gnuplot2', n_colors=len(filter)-2)\n",
    "    f,a = plt.subplots(1, 1, figsize=(13,9))\n",
    "    a.set_xlim([0,1])\n",
    "    a.set_ylim([0,1])\n",
    "    a.set_xlabel('Retention', fontweight='semibold', fontsize=14)\n",
    "    a.set_ylabel('Avg Purity', fontweight='semibold', fontsize=14)\n",
    "    # Setting major ticks\n",
    "    major_ticks = np.arange(0, 1.1, 0.1)\n",
    "    a.set_xticks(major_ticks)\n",
    "    a.set_yticks(major_ticks)\n",
    "    # Setting minor ticks\n",
    "    minor_ticks = np.arange(0, 1.1, 0.05)\n",
    "    a.set_xticks(minor_ticks, minor=True)\n",
    "    a.set_yticks(minor_ticks, minor=True)\n",
    "    plt.grid(which='both', linestyle='--', linewidth=0.5)\n",
    "    ax2 = a.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.set_yscale('log', base=2)\n",
    "    \n",
    "    markers = ['*', '.', '+', 'h', 's', '3', 'v', 'o', 'x', 'p']\n",
    "    print(len(filter))\n",
    "    for i,input_type in enumerate(filter):\n",
    "        query = run.query('input_type==@input_type')\n",
    "        retentions = query['retention'].values\n",
    "        purities = query['mean_purity'].values\n",
    "        clustersizes = query['mean_cluster_size']\n",
    "        if input_type==\"TBCRalign\":\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls='-.', c='g', lw=1.)\n",
    "            ax2.scatter(retentions, clustersizes, label=input_type.lstrip('_'), marker='x', lw=0.5, s=8, c='g')\n",
    "        elif input_type==\"tcrdist3\":\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls='-.', c='y', lw=1.)\n",
    "            ax2.scatter(retentions, clustersizes, label=input_type.lstrip('_'), marker='v', lw=0.1, s=8, c='y')\n",
    "        else:\n",
    "            a.plot(retentions, purities, label=input_type.lstrip('_'), ls='--', lw=1.)\n",
    "            ax2.scatter(retentions, clustersizes, label=input_type.lstrip('_'), marker='+', lw=1.15, s=12)\n",
    "        \n",
    "    a.axhline(0.6, label='60% purity cut-off', ls=':', lw=.75, c='m')\n",
    "    a.axhline(0.7, label='70% purity cut-off', ls=':', lw=.75, c='c')\n",
    "    a.axhline(0.8, label='80% purity cut-off', ls=':', lw=.75, c='y')\n",
    "    \n",
    "    a.legend(title='distance matrix', bbox_to_anchor=(1.1, 0.85),\n",
    "             title_fontproperties={'size':14, 'weight':'semibold'}, prop={'weight':'semibold','size':12})\n",
    "    \n",
    "    ax2.legend(title='Mean cluster size', bbox_to_anchor=(1.1, 0.35),\n",
    "             title_fontproperties={'size':14, 'weight':'semibold'}, prop={'weight':'semibold','size':12})\n",
    "    \n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfb253-8885-4c20-99f6-d134608c2057",
   "metadata": {},
   "source": [
    "# reload baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d24ebbac-c754-43a9-aa73-226df1a1f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_noswap['tcr'] = new_df_noswap['A1']+new_df_noswap['A2']+new_df_noswap['A3']+new_df_noswap['B1']+new_df_noswap['B2']+new_df_noswap['B3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07720f-4ee2-403f-a270-640f9d7c77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv('../data/filtered/231205_nettcr_old_26pep_with_swaps.csv').query('binder==1').reset_index(drop=True)\n",
    "new_df = pd.read_csv('../data/multimodal/240326_nettcr_paired_withswaps.csv').query('binder==1').reset_index(drop=True)\n",
    "old_df['seq_id'] = range(len(old_df))\n",
    "new_df['seq_id'] = range(len(new_df))\n",
    "# saving split CDRs for tbcr_alignas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "344faa95-c364-4c18-896e-be98511963b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'seq_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/pqfhzdzx689fgftqcgjrgbcw0000gp/T/ipykernel_13692/2279242200.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TBCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtbcr_dm140\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/240411_ClusteringTests/dist_matrices/OUTPUT_tbcralign_distmatrix_140peps.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtcr_index140\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../output/240411_ClusteringTests/dist_matrices/OUTPUT_index_tcrs_140pep.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m tbcr_dm, _, _, _, _, _ = get_distances_labels_from_distmatrix(tbcr_dm140, new_df_noswap, tcr_index140, label_col='peptide', \n\u001b[0m\u001b[1;32m      5\u001b[0m                                                               query_subset='partition != 6')\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# tbcr = cluster_all_thresholds(dist_array, features, labels, encoded_labels, label_encoder, n_points=500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tbcr['input_type'] = 'TBCRalign'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/62/pqfhzdzx689fgftqcgjrgbcw0000gp/T/ipykernel_13692/426014367.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dist_matrix, original_df, index_tcr_df, label_col, query_subset)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_distances_labels_from_distmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_tcr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmerged_dist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_merged_distances_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_tcr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mdist_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_dist_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/62/pqfhzdzx689fgftqcgjrgbcw0000gp/T/ipykernel_13692/426014367.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dist_matrix, original_df, index_tcr_df, label_col, query_subset)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_merged_distances_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_tcr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Assumes a square matrix with no other columns, and that the original_df and index_tcr_df match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     merged = pd.merge(index_tcr_df, original_df[[x for x in original_df.columns if x in['seq_id','peptide','partition','binder','origin','fulltcr']]],\n\u001b[0m\u001b[1;32m     53\u001b[0m          left_on=['q_index', 'tcr'], right_on=['seq_id','fulltcr'])\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tcr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fulltcr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fuck'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'seq_id'"
     ]
    }
   ],
   "source": [
    "# TBCR\n",
    "tbcr_dm140 = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/OUTPUT_tbcralign_distmatrix_140peps.csv', index_col=0)\n",
    "tcr_index140 = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/OUTPUT_index_tcrs_140pep.txt')\n",
    "tbcr_dm, _, _, _, _, _ = get_distances_labels_from_distmatrix(tbcr_dm140, new_df_noswap, tcr_index140, label_col='peptide', \n",
    "                                                              query_subset='partition != 6')\n",
    "\n",
    "tbcr_dm140_labeled = tbcr_dm140.merge(new_df_noswap.set_index('tcr').merge(tcr_index140.set_index('tcr'), left_index=True, right_index=True).drop_duplicates(['q_index']).reset_index().set_index('q_index')[['peptide','original_peptide','binder','partition', 'raw_index']],\n",
    "                                      left_index=True, right_index=True)\n",
    "tbcr_dm140_labeled.to_csv('../output/240411_ClusteringTests/dist_matrices/2404XX_OUTPUT_tbcralign_distmatrix_140peps_labeled.csv')\n",
    "tbcr_dm140_part0 = tbcr_dm140_labeled.query('partition==0 and peptide in @new_df_filt.peptide.unique()')\n",
    "tbcr_dm140_part0 = tbcr_dm140_part0[[str(x) for x in tbcr_dm140_part0.index.to_list()] + ['peptide','binder','partition','raw_index']]\n",
    "# tbcr = cluster_all_thresholds(dist_array, features, labels, encoded_labels, label_encoder, n_points=500)\n",
    "# tbcr['input_type'] = 'TBCRalign'\n",
    "# baselines_valid.append(tbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85795b71-a9bf-4400-b0a0-8ecb7f44464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel\n",
    "kernel_dm140 = pd.read_csv('../output/240411_ClusteringTests/dist_matrices/OUTPUT_distmatrix_kernelsim_140peps_labelled.csv')\n",
    "kernel_dm140_part0 = kernel_dm140.query('partition==0 and peptide in @new_df_filt.peptide.unique()')\n",
    "kernel_dm140_part0 = kernel_dm140_part0[kernel_dm140_part0['db'].to_list() + ['origin', 'peptide', 'binder', 'partition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b49f39c3-b13a-49ad-ab09-061936b3a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dm_140, dm_140_part0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72f75f4a-1307-48a4-997b-f5b13b724e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbcr_array = tbcr_dm140_part0.iloc[:len(tbcr_dm140_part0), :len(tbcr_dm140_part0)].values\n",
    "ker_array = kernel_dm140_part0.iloc[:len(kernel_dm140_part0), :len(kernel_dm140_part0)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6b180cb-0a77-4148-bb1a-2045fc76b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcrdist3_newfilt = pkl_load('../output/240411_ClusteringTests/dist_matrices/240422_new_df_filt_tcrdist3.csv')\n",
    "id_newfilt = pd.read_csv('../output/240411_ClusteringTests/240422_new_df_filt_tcrdist3_LABELS.csv').drop(columns=['Unnamed: 0'])\n",
    "id_newfilt_validonly = id_newfilt.query('partition==0')\n",
    "labels_newfilt_validonly = id_newfilt_validonly['peptide'].values\n",
    "tcrdist_array = tcrdist3_newfilt[id_newfilt_validonly.index][:, id_newfilt_validonly.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912075e-828d-4077-a4c8-59eaefe1cda8",
   "metadata": {},
   "source": [
    "# Minimum spanning trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7198d031-15a8-457c-81d9-503817cc5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined model by taking the dist matrix for tbcr and model and do 1-dist then multiply and do 1- (mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343074f-7add-4230-8366-bd99c7e8b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using that best cos model\n",
    "model = get_model('../output/240404_TCRONLY_onetwostage_smallLARGE/240404_2342_ExpData_TCRONLY_1stage_LARGE_256h_100l_CosTrp_KFold_0_SmCosTCRP1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2b608-6eb9-44a2-b325-248b3e2a49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph(a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
