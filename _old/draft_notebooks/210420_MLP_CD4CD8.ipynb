{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arabic-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Allows relative imports\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports from files\n",
    "from src.preprocessing import *\n",
    "from src.VAE_train import *\n",
    "from vae_cel.vae_cel import *\n",
    "from clf.clf_train_eval_helpers import * \n",
    "from src.embedding_visualisation import * \n",
    "from src.loss_metrics import *\n",
    "from src.pickling import *\n",
    "from src.datasets import *\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#checking gpu status\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "#Plot and stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Ignore warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-brown",
   "metadata": {},
   "source": [
    "### Reloading VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medical-minnesota",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model succesfully loaded from ../output/HyperbolicContinueTraining/LOWERBETA_DirectlyMax/BEST_VAE_tune-weighted0.5_latent100_Pad-before_Annealing-None-gamma1.0.pth.tar:\n",
      "\tepoch: 74\n"
     ]
    }
   ],
   "source": [
    "from src.torch_util import *\n",
    "vae = VAE_cel(latent_dim = 100, aa_dim = 25)\n",
    "vae = load_model(vae, '../output/HyperbolicContinueTraining/LOWERBETA_DirectlyMax/BEST_VAE_tune-weighted0.5_latent100_Pad-before_Annealing-None-gamma1.0.pth.tar')\n",
    "vae.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-escape",
   "metadata": {},
   "source": [
    "##### hidden preprocessing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "chicken-yellow",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# No need to rerun this cell, just read the next\n",
    "cd_db = pd.read_csv('../training_data_new/db/cd4_cd8_db.csv')\n",
    "print(len(cd_db.query('v_gene != \"unresolved\" and j_gene != \"unresolved\"'))/len(cd_db))\n",
    "cd_db = cd_db.query('v_gene != \"unresolved\" and j_gene != \"unresolved\"')\n",
    "cd_db = cd_db.query('not v_gene.str.contains(\"or\")')\n",
    "cd_db['v'] = cd_db['v_gene'].apply(lambda x: int(x.split('V')[1].split('-')[0])-1)\n",
    "cd_db['j'] = cd_db['j_gene'].apply(lambda x: int(x.split('J')[1].split('-')[0])-1)\n",
    "cd_db= cd_db.query('cdr3_amino_acid.str.len()<=23')\n",
    "cd_db.to_csv('../training_data_new/db/cd4_cd8_db.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "appreciated-failure",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13318acda54a400fbd94707c03b21289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = cd_db[['cdr3_amino_acid','v','j']].values\n",
    "embedding_df = pd.DataFrame(columns = ['z_'+str(i) for i in range(100)])\n",
    "vae.eval()\n",
    "vae.to('cuda')\n",
    "for batch in tqdm(list(chunks(vals, 2**14))):\n",
    "    b = batch_aa_vj(batch, 23, 0.5, 'before',True, False, 'cuda')\n",
    "    with torch.no_grad():\n",
    "        z = vae.embed(b)\n",
    "    embedding_df = embedding_df.append(pd.DataFrame(data = z.cpu().numpy(), \n",
    "                                                    columns = ['z_'+str(i) for i in range(100)]),\n",
    "                                       ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternate-ivory",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MLP_binary(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, activation = nn.SELU(), p_drop = 0.5):\n",
    "        super(MLP_binary, self).__init__()\n",
    "        if p_drop >0 and p_drop <1:\n",
    "            self.drop = nn.Dropout(p_drop)\n",
    "        else: \n",
    "            self.drop = nn.Identity()\n",
    "            \n",
    "        self.input_layers = nn.Sequential(nn.Linear(100, 256),\n",
    "                                          nn.BatchNorm1d(256),\n",
    "                                          activation,\n",
    "                                          self.drop,\n",
    "                                          nn.Linear(256, 512),\n",
    "                                          nn.BatchNorm1d(512),\n",
    "                                          activation,\n",
    "                                          self.drop,\n",
    "                                          nn.Linear(512, n_hidden),\n",
    "                                          activation,\n",
    "                                          self.drop)\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(n_hidden, n_hidden))\n",
    "            layers.append(activation)\n",
    "            layers.append(self.drop) \n",
    "        \n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        self.output = nn.Sequential(nn.Linear(n_hidden, n_hidden//2),\n",
    "                                    nn.BatchNorm1d(n_hidden//2),\n",
    "                                    activation,\n",
    "                                    self.drop,\n",
    "                                    \n",
    "                                    nn.Linear(n_hidden//2, 10),\n",
    "                                    activation,\n",
    "                                    \n",
    "                                    nn.Linear(10, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layers(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output(x) #No activation because I want to return logits for the BCELoss\n",
    "        return x.view(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-communication",
   "metadata": {},
   "source": [
    "# VAE: cd8 vs cd4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "blocked-shakespeare",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e7ab9e9290>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Already pre_labeled&embedded & subsetted DF\n",
    "#df = pd.read_csv('../training_data_new/db/cd4_cd8_db.csv')\n",
    "# Restricting to spleen only like in the Sonnia paper\n",
    "subset = df.query('sample_name.str.contains(\"Spleen\") and `cell-type` != \"Treg\"')\n",
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bizarre-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>cdr3_amino_acid</th>\n",
       "      <th>v_gene</th>\n",
       "      <th>j_gene</th>\n",
       "      <th>cell-type</th>\n",
       "      <th>v</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1D_6265_Spleen_CD8+</td>\n",
       "      <td>CASSQGDRATYEQYF</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ02-05</td>\n",
       "      <td>cd8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1D_6265_Spleen_CD8+</td>\n",
       "      <td>CASSQGPSSETQYF</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ02-05</td>\n",
       "      <td>cd8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1D_6265_Spleen_CD8+</td>\n",
       "      <td>CASSQGRGNQPRHF</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ01-05</td>\n",
       "      <td>cd8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1D_6265_Spleen_CD8+</td>\n",
       "      <td>CASSQVWDSFTDTQYF</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ02-03</td>\n",
       "      <td>cd8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1D_6265_Spleen_CD8+</td>\n",
       "      <td>CASSQGSYNSPLHF</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ01-06</td>\n",
       "      <td>cd8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sample_name   cdr3_amino_acid      v_gene      j_gene cell-type  \\\n",
       "0  T1D_6265_Spleen_CD8+   CASSQGDRATYEQYF  TCRBV04-01  TCRBJ02-05       cd8   \n",
       "1  T1D_6265_Spleen_CD8+    CASSQGPSSETQYF  TCRBV04-01  TCRBJ02-05       cd8   \n",
       "2  T1D_6265_Spleen_CD8+    CASSQGRGNQPRHF  TCRBV04-01  TCRBJ01-05       cd8   \n",
       "3  T1D_6265_Spleen_CD8+  CASSQVWDSFTDTQYF  TCRBV04-01  TCRBJ02-03       cd8   \n",
       "4  T1D_6265_Spleen_CD8+    CASSQGSYNSPLHF  TCRBV04-01  TCRBJ01-06       cd8   \n",
       "\n",
       "   v  j  \n",
       "0  3  1  \n",
       "1  3  1  \n",
       "2  3  0  \n",
       "3  3  1  \n",
       "4  3  0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = pd.read_csv('../training_data_new/db/cd8_tconv_subset.csv')\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "induced-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670315, array(['cd8', 'Tconv'], dtype=object))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.to_csv('../training_data_new/db/cd8_tconv_subset.csv', index=False)\n",
    "len(subset), subset['cell-type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cubic-classic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model succesfully loaded from ../output/HyperbolicContinueTraining/LOWERBETA_DirectlyMax/BEST_VAE_tune-weighted0.5_latent100_Pad-before_Annealing-None-gamma1.0.pth.tar:\n",
      "\tepoch: 74\n"
     ]
    }
   ],
   "source": [
    "from src.torch_util import *\n",
    "vae = VAE_cel(latent_dim = 100, aa_dim = 25)\n",
    "vae = load_model(vae, '../output/HyperbolicContinueTraining/LOWERBETA_DirectlyMax/BEST_VAE_tune-weighted0.5_latent100_Pad-before_Annealing-None-gamma1.0.pth.tar')\n",
    "vae.to(device);\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "binding-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f949f2abe2c404980ea420e65343c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(            sample_name   cdr3_amino_acid      v_gene      j_gene cell-type  \\\n",
       " 0  T1D_6265_Spleen_CD8+   CASSQGDRATYEQYF  TCRBV04-01  TCRBJ02-05       cd8   \n",
       " 1  T1D_6265_Spleen_CD8+    CASSQGPSSETQYF  TCRBV04-01  TCRBJ02-05       cd8   \n",
       " 2  T1D_6265_Spleen_CD8+    CASSQGRGNQPRHF  TCRBV04-01  TCRBJ01-05       cd8   \n",
       " 3  T1D_6265_Spleen_CD8+  CASSQVWDSFTDTQYF  TCRBV04-01  TCRBJ02-03       cd8   \n",
       " 4  T1D_6265_Spleen_CD8+    CASSQGSYNSPLHF  TCRBV04-01  TCRBJ01-06       cd8   \n",
       " \n",
       "    v  j       z_0       z_1       z_2  ...      z_90      z_91      z_92  \\\n",
       " 0  3  1 -0.081669 -0.252335 -1.006883  ... -0.954688  1.651380  2.203298   \n",
       " 1  3  1 -0.282169  0.679195  0.474698  ...  0.554570 -1.690838  1.730452   \n",
       " 2  3  0  0.049712 -0.012633 -0.832655  ...  0.963157 -1.863461  0.847668   \n",
       " 3  3  1 -0.979778 -1.109508 -0.356508  ... -1.779394 -2.086255 -2.818264   \n",
       " 4  3  0  0.958953 -0.986798  0.631857  ...  0.837093 -0.051003  0.784995   \n",
       " \n",
       "        z_93      z_94      z_95      z_96      z_97      z_98      z_99  \n",
       " 0 -0.621918  1.907200  0.080188  0.579286 -1.180251 -0.006848 -1.317308  \n",
       " 1 -0.995490 -1.259593  0.302318 -0.501555 -1.751739  0.504375 -0.844571  \n",
       " 2  1.444789  0.762117  0.168986 -1.692720  0.422407 -0.240036 -1.113978  \n",
       " 3 -1.740028  1.529781  0.086944  0.202005 -1.810352 -0.561158  0.744381  \n",
       " 4 -0.761647 -1.154627  0.973157 -0.131763  0.518466 -0.883795  1.512268  \n",
       " \n",
       " [5 rows x 107 columns],\n",
       " 670315)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = subset[['cdr3_amino_acid','v','j']].values\n",
    "df = pd.DataFrame(columns = ['z_'+str(i) for i in range(100)])\n",
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ch in tqdm(list(chunks(aa, 2**15))):\n",
    "        x = batch_aa_vj(ch, 23, 0.5, 'before',True,False,'cuda')\n",
    "        emb = vae.embed(x)\n",
    "        df = df.append(pd.DataFrame(emb.cpu().numpy(), columns = df.columns), ignore_index=True)\n",
    "df = df.reset_index().drop(columns = ['index'])\n",
    "subset = subset.merge(df,left_index =True,right_index=True)#.drop(columns=['index'])\n",
    "subset.head(), len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "sized-turning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13163027830199234\n",
      "0.13163214309690222\n"
     ]
    }
   ],
   "source": [
    "# Split X into Train/Test\n",
    "subset['label']= subset['cell-type'].apply(lambda x: 1 if x == 'cd8' else 0)\n",
    "X = subset[['z_'+str(i) for i in range(100)]].values\n",
    "y = subset['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 20)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(sum(y_train)/len(y_train))\n",
    "print(sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "automated-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing XGB\n",
      "[0]\tvalidation_0-aucpr:0.17971\n",
      "[1]\tvalidation_0-aucpr:0.18757\n",
      "[2]\tvalidation_0-aucpr:0.18777\n",
      "[3]\tvalidation_0-aucpr:0.19009\n",
      "[4]\tvalidation_0-aucpr:0.19080\n",
      "[5]\tvalidation_0-aucpr:0.19202\n",
      "[6]\tvalidation_0-aucpr:0.19482\n",
      "[7]\tvalidation_0-aucpr:0.19579\n",
      "[8]\tvalidation_0-aucpr:0.19693\n",
      "[9]\tvalidation_0-aucpr:0.19694\n",
      "[10]\tvalidation_0-aucpr:0.19781\n",
      "[11]\tvalidation_0-aucpr:0.19862\n",
      "[12]\tvalidation_0-aucpr:0.19884\n",
      "[13]\tvalidation_0-aucpr:0.19919\n",
      "[14]\tvalidation_0-aucpr:0.20000\n",
      "[15]\tvalidation_0-aucpr:0.19990\n",
      "[16]\tvalidation_0-aucpr:0.20057\n",
      "[17]\tvalidation_0-aucpr:0.20023\n",
      "[18]\tvalidation_0-aucpr:0.20002\n",
      "[19]\tvalidation_0-aucpr:0.20008\n",
      "[20]\tvalidation_0-aucpr:0.19995\n",
      "[21]\tvalidation_0-aucpr:0.20025\n",
      "Classifier : xgb, ROC AUC 62.321%\n",
      "Doing log\n",
      "Classifier : log, ROC AUC 55.510%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random.seed(20)\n",
    "torch.cuda.empty_cache()\n",
    "clf['xgb'] = {'clf':xgb.XGBClassifier(n_estimators=400,\n",
    "                                      objective='binary:logistic',\n",
    "                                      missing=None, seed = 20,\n",
    "                                      n_jobs = 4, tree_method = 'gpu_hist',\n",
    "                                      max_depth = 6),\n",
    "              'roc': 0}\n",
    "\n",
    "clf['log'] = {'clf': LogisticRegressionCV(10, max_iter = 500,\n",
    "                                          cv=5, random_state=20, n_jobs = 8),\n",
    "              'roc': 0}\n",
    "\n",
    "print('Doing XGB')\n",
    "clf['xgb']['clf'].fit(X_train, y_train, verbose = True,\n",
    "                                 early_stopping_rounds = 5, \n",
    "                                 eval_metric = 'aucpr',\n",
    "                                 eval_set = [(X_test, y_test)])\n",
    "\n",
    "scores = clf['xgb']['clf'].predict_proba(X_test)[:,1]\n",
    "clf['xgb']['roc'] = roc_auc_score(y_test, scores)\n",
    "k = 'xgb'\n",
    "print(f'Classifier : {k}, ROC AUC {clf[k][\"roc\"]:.3%}')\n",
    "\n",
    "for name in ['log']:#,'rf']:\n",
    "    print(f'Doing {name}')\n",
    "    clf[name]['clf'].fit(X_train,y_train)\n",
    "    scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "    clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "    print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "consolidated-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : rf, ROC AUC 59.745%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "name = 'rf'\n",
    "clf['rf'] = {'clf': RandomForestClassifier(n_estimators=300,\n",
    "                                           min_samples_split = 200,\n",
    "                                           min_samples_leaf = 600,\n",
    "                                           verbose=1, max_depth = 8, n_jobs=8),\n",
    "             'roc': 0}\n",
    "print(f'Doing {name}')\n",
    "clf[name]['clf'].fit(X_train,y_train)\n",
    "scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eight-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../output/classifier_gridsearch/VAE_spleen_cd4cd8_clf_dict.pkl', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-seeking",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "invalid-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model succesfully loaded from ./Best_AE_model_latdim40_withSELU.pth.tar:\n",
      "\tepoch: 24\n"
     ]
    }
   ],
   "source": [
    "from src.vautoencoders import AutoEncoder\n",
    "autoencoder = AutoEncoder(seq_len=23, aa_dim = 21, latent_dim = 40)\n",
    "autoencoder = load_model(autoencoder, './Best_AE_model_latdim40_withSELU.pth.tar')\n",
    "autoencoder.to('cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "olive-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = subset[subset.columns[0:7]]\n",
    "xd['label'] = xd.apply(lambda x: 1 if x['cell-type'] == 'cd8' else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "european-weekend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ef114a751d420fa919b3b78e8687ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aa = subset.cdr3_amino_acid.values\n",
    "df2 = pd.DataFrame(columns = ['lat_'+str(i) for i in range(40)])\n",
    "autoencoder.to()\n",
    "autoencoder.eval()\n",
    "with torch.no_grad():\n",
    "    for ch in tqdm(list(chunks(aa, 2**15))):\n",
    "        x = onehot_batch(ch, 23, 1.6, 'after').to('cuda')\n",
    "        emb = autoencoder.embed(x)\n",
    "        df2 = df2.append(pd.DataFrame(emb.cpu().numpy(), columns = df2.columns))\n",
    "df2.reset_index(inplace=True)\n",
    "df2= df2.drop(columns=['index'])\n",
    "df2 = xd.merge(df2,left_index =True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "amino-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['lat_'+str(i) for i in range(40)]].values\n",
    "y = df2['label'].values\n",
    "# Split X into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 20)\n",
    "# Split Train into Train/Val\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = 0.8, random_state = 20)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "killing-point",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing XGB\n",
      "[0]\tvalidation_0-aucpr:0.15476\n",
      "[1]\tvalidation_0-aucpr:0.15830\n",
      "[2]\tvalidation_0-aucpr:0.16153\n",
      "[3]\tvalidation_0-aucpr:0.16267\n",
      "[4]\tvalidation_0-aucpr:0.16398\n",
      "[5]\tvalidation_0-aucpr:0.16415\n",
      "[6]\tvalidation_0-aucpr:0.16561\n",
      "[7]\tvalidation_0-aucpr:0.16718\n",
      "[8]\tvalidation_0-aucpr:0.16831\n",
      "[9]\tvalidation_0-aucpr:0.16886\n",
      "[10]\tvalidation_0-aucpr:0.16873\n",
      "[11]\tvalidation_0-aucpr:0.16905\n",
      "[12]\tvalidation_0-aucpr:0.16949\n",
      "[13]\tvalidation_0-aucpr:0.17027\n",
      "[14]\tvalidation_0-aucpr:0.17050\n",
      "[15]\tvalidation_0-aucpr:0.17100\n",
      "[16]\tvalidation_0-aucpr:0.17128\n",
      "[17]\tvalidation_0-aucpr:0.17270\n",
      "[18]\tvalidation_0-aucpr:0.17334\n",
      "[19]\tvalidation_0-aucpr:0.17378\n",
      "[20]\tvalidation_0-aucpr:0.17391\n",
      "[21]\tvalidation_0-aucpr:0.17434\n",
      "[22]\tvalidation_0-aucpr:0.17456\n",
      "[23]\tvalidation_0-aucpr:0.17485\n",
      "[24]\tvalidation_0-aucpr:0.17482\n",
      "[25]\tvalidation_0-aucpr:0.17495\n",
      "[26]\tvalidation_0-aucpr:0.17549\n",
      "[27]\tvalidation_0-aucpr:0.17633\n",
      "[28]\tvalidation_0-aucpr:0.17708\n",
      "[29]\tvalidation_0-aucpr:0.17750\n",
      "[30]\tvalidation_0-aucpr:0.17769\n",
      "[31]\tvalidation_0-aucpr:0.17781\n",
      "[32]\tvalidation_0-aucpr:0.17798\n",
      "[33]\tvalidation_0-aucpr:0.17826\n",
      "[34]\tvalidation_0-aucpr:0.17898\n",
      "[35]\tvalidation_0-aucpr:0.17933\n",
      "[36]\tvalidation_0-aucpr:0.17933\n",
      "[37]\tvalidation_0-aucpr:0.17938\n",
      "[38]\tvalidation_0-aucpr:0.17971\n",
      "[39]\tvalidation_0-aucpr:0.17968\n",
      "[40]\tvalidation_0-aucpr:0.17939\n",
      "[41]\tvalidation_0-aucpr:0.17915\n",
      "[42]\tvalidation_0-aucpr:0.17918\n",
      "Classifier : xgb, ROC AUC 58.706%\n",
      "Doing log\n",
      "Classifier : log, ROC AUC 54.890%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random.seed(20)\n",
    "\n",
    "clf={}\n",
    "n_estimators = [100, 150, 200, 250]\n",
    "max_depth = [4,6,8,10]\n",
    "learning_rate = [0.15, 0.3, 0.55, 0.7]\n",
    "min_child_weight = [1, 3, 5]\n",
    "max_delta_step = [0, 1, 3]\n",
    "lambda_ = [1, 5, 10, 100]\n",
    "alpha = [0, 1e-3, 1e-1, 5]\n",
    "tree_method = 'gpu_hist'\n",
    "torch.cuda.empty_cache()\n",
    "clf['xgb'] = {'clf':xgb.XGBClassifier(n_estimators=400,\n",
    "                                      objective='binary:logistic',\n",
    "                                      missing=None, seed = 20,\n",
    "                                      n_jobs = 4, tree_method = 'gpu_hist',\n",
    "                                      max_depth = 6),\n",
    "              'roc': 0}\n",
    "\n",
    "clf['log'] = {'clf': LogisticRegressionCV(10, max_iter = 300,\n",
    "                                          cv=5, random_state=20,\n",
    "                                         n_jobs = 8),\n",
    "              'roc': 0}\n",
    "\n",
    "clf['rf'] = {'clf': RandomForestClassifier(n_estimators=225,\n",
    "                                           min_samples_split = 200,\n",
    "                                           min_samples_leaf = 600,\n",
    "                                           verbose=1, max_depth = 7, n_jobs=2),\n",
    "             'roc': 0}\n",
    "\n",
    "print('Doing XGB')\n",
    "clf['xgb']['clf'].fit(X_train, y_train, verbose = True,\n",
    "                                 early_stopping_rounds = 5, \n",
    "                                 eval_metric = 'aucpr',\n",
    "                                 eval_set = [(X_test, y_test)])\n",
    "\n",
    "scores = clf['xgb']['clf'].predict_proba(X_test)[:,1]\n",
    "clf['xgb']['roc'] = roc_auc_score(y_test, scores)\n",
    "k = 'xgb'\n",
    "print(f'Classifier : {k}, ROC AUC {clf[k][\"roc\"]:.3%}')\n",
    "\n",
    "for name in ['log']:#,'rf']:\n",
    "    print(f'Doing {name}')\n",
    "    clf[name]['clf'].fit(X_train,y_train)\n",
    "    scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "    clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "    print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "conscious-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : rf, ROC AUC 57.759%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "name = 'rf'\n",
    "clf['rf'] = {'clf': RandomForestClassifier(n_estimators=300,\n",
    "                                           min_samples_split = 200,\n",
    "                                           min_samples_leaf = 600,\n",
    "                                           verbose=1, max_depth = 8, n_jobs=8),\n",
    "             'roc': 0}\n",
    "print(f'Doing {name}')\n",
    "clf[name]['clf'].fit(X_train,y_train)\n",
    "scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(y_train)/len(y_train))\n",
    "print(sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-matrix",
   "metadata": {},
   "source": [
    "# Atchley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "electric-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 23, 5)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.empty((1,23,5))\n",
    "np.concatenate([X, np.empty((10,23,5))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "induced-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import atchley_batch\n",
    "\n",
    "def get_atchley_values(df, random_state=20):\n",
    "    torch.manual_seed(random_state)\n",
    "    sequences = df.cdr3_amino_acid.values\n",
    "    X = np.empty((0, 23, 5))\n",
    "    for ch in tqdm(list(chunks(sequences, 2**15))):\n",
    "        X = np.concatenate([X, atchley_batch(sequences, 23)])\n",
    "    y = df['label'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-cooling",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MLP_Flat_Atchley(nn.Module):\n",
    "    #Reusing an architecture from Deepcat \n",
    "    def __init__(self):\n",
    "        super(MLP_Flat_Atchley, self).__init__()\n",
    "            \n",
    "        self.layers = nn.Sequential(nn.Linear(115, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.Linear(256, 512),\n",
    "                                    nn.BatchNorm1d(512),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.Linear(512, 512),\n",
    "                                    nn.BatchNorm1d(512),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.Linear(512, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                   )\n",
    "        self.output = nn.Sequential(nn.Linear(256, 64),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.Linear(64, 10),\n",
    "                                    nn.SELU(),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.Linear(10,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x.view(-1,x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        x = self.output(x)\n",
    "        return x.view(-1,)\n",
    "    \n",
    "    def reset_params(self):\n",
    "        i = 0\n",
    "        for x in self.children():\n",
    "            if x.__class__.__name__ == 'Sequential':\n",
    "                for layer in x:\n",
    "                    if hasattr(layer, 'reset_parameters'):\n",
    "                        layer.reset_parameters()\n",
    "                        layer.zero_grad()\n",
    "                        i += 1\n",
    "            if hasattr(x, 'reset_parameters'):\n",
    "                x.reset_parameters()\n",
    "                x.zero_grad()\n",
    "                i += 1\n",
    "        if i >= 1: print('Parameters reset.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "pretty-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = atchley_batch(subset.cdr3_amino_acid.values,23)\n",
    "y = subset.label.values\n",
    "# Split X into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 20)\n",
    "# Split Train into Train/Val\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = 0.8, random_state = 20)\n",
    "del X\n",
    "del y\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "X_train = X_train.reshape(-1, X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(-1, X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "amazing-friday",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing XGB\n",
      "[0]\tvalidation_0-aucpr:0.16348\n",
      "[1]\tvalidation_0-aucpr:0.16861\n",
      "[2]\tvalidation_0-aucpr:0.17264\n",
      "[3]\tvalidation_0-aucpr:0.17677\n",
      "[4]\tvalidation_0-aucpr:0.17833\n",
      "[5]\tvalidation_0-aucpr:0.18174\n",
      "[6]\tvalidation_0-aucpr:0.18207\n",
      "[7]\tvalidation_0-aucpr:0.18624\n",
      "[8]\tvalidation_0-aucpr:0.18820\n",
      "[9]\tvalidation_0-aucpr:0.18945\n",
      "[10]\tvalidation_0-aucpr:0.19008\n",
      "[11]\tvalidation_0-aucpr:0.19191\n",
      "[12]\tvalidation_0-aucpr:0.19403\n",
      "[13]\tvalidation_0-aucpr:0.19478\n",
      "[14]\tvalidation_0-aucpr:0.19503\n",
      "[15]\tvalidation_0-aucpr:0.19530\n",
      "[16]\tvalidation_0-aucpr:0.19578\n",
      "[17]\tvalidation_0-aucpr:0.19633\n",
      "[18]\tvalidation_0-aucpr:0.19681\n",
      "[19]\tvalidation_0-aucpr:0.19759\n",
      "[20]\tvalidation_0-aucpr:0.19847\n",
      "[21]\tvalidation_0-aucpr:0.20002\n",
      "[22]\tvalidation_0-aucpr:0.20000\n",
      "[23]\tvalidation_0-aucpr:0.20040\n",
      "[24]\tvalidation_0-aucpr:0.20148\n",
      "[25]\tvalidation_0-aucpr:0.20202\n",
      "[26]\tvalidation_0-aucpr:0.20243\n",
      "[27]\tvalidation_0-aucpr:0.20266\n",
      "[28]\tvalidation_0-aucpr:0.20315\n",
      "[29]\tvalidation_0-aucpr:0.20291\n",
      "[30]\tvalidation_0-aucpr:0.20353\n",
      "[31]\tvalidation_0-aucpr:0.20336\n",
      "[32]\tvalidation_0-aucpr:0.20343\n",
      "[33]\tvalidation_0-aucpr:0.20361\n",
      "[34]\tvalidation_0-aucpr:0.20373\n",
      "[35]\tvalidation_0-aucpr:0.20409\n",
      "[36]\tvalidation_0-aucpr:0.20442\n",
      "[37]\tvalidation_0-aucpr:0.20441\n",
      "[38]\tvalidation_0-aucpr:0.20447\n",
      "[39]\tvalidation_0-aucpr:0.20446\n",
      "[40]\tvalidation_0-aucpr:0.20462\n",
      "[41]\tvalidation_0-aucpr:0.20478\n",
      "[42]\tvalidation_0-aucpr:0.20520\n",
      "[43]\tvalidation_0-aucpr:0.20527\n",
      "[44]\tvalidation_0-aucpr:0.20559\n",
      "[45]\tvalidation_0-aucpr:0.20553\n",
      "[46]\tvalidation_0-aucpr:0.20566\n",
      "[47]\tvalidation_0-aucpr:0.20552\n",
      "[48]\tvalidation_0-aucpr:0.20582\n",
      "[49]\tvalidation_0-aucpr:0.20606\n",
      "[50]\tvalidation_0-aucpr:0.20626\n",
      "[51]\tvalidation_0-aucpr:0.20637\n",
      "[52]\tvalidation_0-aucpr:0.20669\n",
      "[53]\tvalidation_0-aucpr:0.20679\n",
      "[54]\tvalidation_0-aucpr:0.20691\n",
      "[55]\tvalidation_0-aucpr:0.20691\n",
      "[56]\tvalidation_0-aucpr:0.20689\n",
      "[57]\tvalidation_0-aucpr:0.20670\n",
      "[58]\tvalidation_0-aucpr:0.20673\n",
      "[59]\tvalidation_0-aucpr:0.20695\n",
      "[60]\tvalidation_0-aucpr:0.20704\n",
      "[61]\tvalidation_0-aucpr:0.20705\n",
      "[62]\tvalidation_0-aucpr:0.20731\n",
      "[63]\tvalidation_0-aucpr:0.20754\n",
      "[64]\tvalidation_0-aucpr:0.20752\n",
      "[65]\tvalidation_0-aucpr:0.20742\n",
      "[66]\tvalidation_0-aucpr:0.20767\n",
      "[67]\tvalidation_0-aucpr:0.20779\n",
      "[68]\tvalidation_0-aucpr:0.20822\n",
      "[69]\tvalidation_0-aucpr:0.20832\n",
      "[70]\tvalidation_0-aucpr:0.20837\n",
      "[71]\tvalidation_0-aucpr:0.20839\n",
      "[72]\tvalidation_0-aucpr:0.20841\n",
      "[73]\tvalidation_0-aucpr:0.20855\n",
      "[74]\tvalidation_0-aucpr:0.20857\n",
      "[75]\tvalidation_0-aucpr:0.20872\n",
      "[76]\tvalidation_0-aucpr:0.20889\n",
      "[77]\tvalidation_0-aucpr:0.20898\n",
      "[78]\tvalidation_0-aucpr:0.20895\n",
      "[79]\tvalidation_0-aucpr:0.20914\n",
      "[80]\tvalidation_0-aucpr:0.20915\n",
      "[81]\tvalidation_0-aucpr:0.20923\n",
      "[82]\tvalidation_0-aucpr:0.20938\n",
      "[83]\tvalidation_0-aucpr:0.20931\n",
      "[84]\tvalidation_0-aucpr:0.20930\n",
      "[85]\tvalidation_0-aucpr:0.20930\n",
      "[86]\tvalidation_0-aucpr:0.20931\n",
      "[87]\tvalidation_0-aucpr:0.20963\n",
      "[88]\tvalidation_0-aucpr:0.20978\n",
      "[89]\tvalidation_0-aucpr:0.20987\n",
      "[90]\tvalidation_0-aucpr:0.20980\n",
      "[91]\tvalidation_0-aucpr:0.20960\n",
      "[92]\tvalidation_0-aucpr:0.20974\n",
      "[93]\tvalidation_0-aucpr:0.21004\n",
      "[94]\tvalidation_0-aucpr:0.21008\n",
      "[95]\tvalidation_0-aucpr:0.21011\n",
      "[96]\tvalidation_0-aucpr:0.21017\n",
      "[97]\tvalidation_0-aucpr:0.21025\n",
      "[98]\tvalidation_0-aucpr:0.21019\n",
      "[99]\tvalidation_0-aucpr:0.21015\n",
      "[100]\tvalidation_0-aucpr:0.21016\n",
      "[101]\tvalidation_0-aucpr:0.21030\n",
      "[102]\tvalidation_0-aucpr:0.21031\n",
      "[103]\tvalidation_0-aucpr:0.21049\n",
      "[104]\tvalidation_0-aucpr:0.21036\n",
      "[105]\tvalidation_0-aucpr:0.21049\n",
      "[106]\tvalidation_0-aucpr:0.21044\n",
      "[107]\tvalidation_0-aucpr:0.21078\n",
      "[108]\tvalidation_0-aucpr:0.21081\n",
      "[109]\tvalidation_0-aucpr:0.21073\n",
      "[110]\tvalidation_0-aucpr:0.21082\n",
      "[111]\tvalidation_0-aucpr:0.21083\n",
      "[112]\tvalidation_0-aucpr:0.21094\n",
      "[113]\tvalidation_0-aucpr:0.21095\n",
      "[114]\tvalidation_0-aucpr:0.21084\n",
      "[115]\tvalidation_0-aucpr:0.21078\n",
      "[116]\tvalidation_0-aucpr:0.21087\n",
      "[117]\tvalidation_0-aucpr:0.21073\n",
      "Classifier : xgb, ROC AUC 63.091%\n",
      "Doing log\n",
      "Classifier : log, ROC AUC 57.813%\n",
      "Doing rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : rf, ROC AUC 60.371%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random.seed(20)\n",
    "clf={}\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "clf['xgb'] = {'clf':xgb.XGBClassifier(n_estimators=400,\n",
    "                                      objective='binary:logistic',\n",
    "                                      missing=None, seed = 20,\n",
    "                                      n_jobs = 4, tree_method = 'gpu_hist',\n",
    "                                      max_depth = 6),\n",
    "              'roc': 0}\n",
    "\n",
    "clf['log'] = {'clf': LogisticRegressionCV(10, max_iter = 300,\n",
    "                                          cv=5, random_state=20,\n",
    "                                         n_jobs = 8),\n",
    "              'roc': 0}\n",
    "\n",
    "clf['rf'] = {'clf': RandomForestClassifier(n_estimators=225,\n",
    "                                           min_samples_split = 200,\n",
    "                                           min_samples_leaf = 600,\n",
    "                                           verbose=1, max_depth = 7, n_jobs=2),\n",
    "             'roc': 0}\n",
    "\n",
    "print('Doing XGB')\n",
    "clf['xgb']['clf'].fit(X_train, y_train, verbose = True,\n",
    "                                 early_stopping_rounds = 5, \n",
    "                                 eval_metric = 'aucpr',\n",
    "                                 eval_set = [(X_test, y_test)])\n",
    "\n",
    "scores = clf['xgb']['clf'].predict_proba(X_test)[:,1]\n",
    "clf['xgb']['roc'] = roc_auc_score(y_test, scores)\n",
    "k = 'xgb'\n",
    "print(f'Classifier : {k}, ROC AUC {clf[k][\"roc\"]:.3%}')\n",
    "\n",
    "for name in ['log']:#,'rf']:\n",
    "    print(f'Doing {name}')\n",
    "    clf[name]['clf'].fit(X_train,y_train)\n",
    "    scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "    clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "    print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')\n",
    "    \n",
    "name = 'rf'\n",
    "clf['rf'] = {'clf': RandomForestClassifier(n_estimators=300,\n",
    "                                           min_samples_split = 200,\n",
    "                                           min_samples_leaf = 600,\n",
    "                                           verbose=1, max_depth = 8, n_jobs=8),\n",
    "             'roc': 0}\n",
    "print(f'Doing {name}')\n",
    "clf[name]['clf'].fit(X_train,y_train)\n",
    "scores = clf[name]['clf'].predict_proba(X_test)[:,1]\n",
    "clf[name]['roc'] = roc_auc_score(y_test,scores)\n",
    "print(f'Classifier : {name}, ROC AUC {clf[name][\"roc\"]:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ignored-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl('../output/spleenCD4CD8_clf_atchley.pkl', clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
