{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Allows relative imports\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports from files\n",
    "from src.preprocessing import *\n",
    "from src.VAE_train import *\n",
    "from vae_cel.vae_cel import *\n",
    "from src.loss_metrics import *\n",
    "from src.pickling import *\n",
    "from src.datasets import *\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#checking gpu status\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "#Plot and stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Ignore warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flush-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('../training_data_new/db/db_TRB.csv')\\\n",
    "       .query('cdr3_TRB.str.len()>10 and cdr3_TRB.str.len() <= 23')\\\n",
    "       .query('cdr3_TRB.str.endswith(\"F\") and cdr3_TRB.str.startswith(\"C\")')\n",
    "#, nrows = 100)\n",
    "em = pd.read_csv('../training_data_new/emerson_raw/batch1/emerson_batch1_626hla_parsed_tagged.tsv', \n",
    "                 sep='\\t')\\\n",
    "       .query('amino_acid.str.len()>10 and amino_acid.str.len()<=23')\\\n",
    "       .query('amino_acid.str.endswith(\"F\") and amino_acid.str.startswith(\"C\")')\n",
    "em = em[['amino_acid','v_family','j_family']]\n",
    "em = em.sample(2*len(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "popular-ability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amino_acid</th>\n",
       "      <th>v_family</th>\n",
       "      <th>j_family</th>\n",
       "      <th>db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASSRDRGNQETQYF</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASSETVDGPRAEAFF</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAISERVESETQYF</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASSSGVTGNTIYF</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASSPPGGGSSYEQYF</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032793</th>\n",
       "      <td>CSARGTGGAYGYTF</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032794</th>\n",
       "      <td>CSVDSGQGQPQHF</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032795</th>\n",
       "      <td>CSASPPTIAGGPSPYNEQFF</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032796</th>\n",
       "      <td>CSAMGLGEASYEQYF</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032797</th>\n",
       "      <td>CSSSQRPSVNTGELFF</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>naive_db</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032798 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   amino_acid  v_family  j_family        db\n",
       "0             CASSRDRGNQETQYF        27         2  naive_db\n",
       "1            CASSETVDGPRAEAFF         6         1  naive_db\n",
       "2              CAISERVESETQYF        10         2  naive_db\n",
       "3              CASSSGVTGNTIYF        18         1  naive_db\n",
       "4            CASSPPGGGSSYEQYF        18         2  naive_db\n",
       "...                       ...       ...       ...       ...\n",
       "4032793        CSARGTGGAYGYTF        20         1  naive_db\n",
       "4032794         CSVDSGQGQPQHF        29         1  naive_db\n",
       "4032795  CSASPPTIAGGPSPYNEQFF        20         2  naive_db\n",
       "4032796       CSAMGLGEASYEQYF        20         2  naive_db\n",
       "4032797      CSSSQRPSVNTGELFF         3         2  naive_db\n",
       "\n",
       "[4032798 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.concat([db2, db1.sample(frac=0.2)], ignore_index=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handy-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "em['V'] = em['v_family'].apply(lambda x : int(x.split('V')[1]))\n",
    "em['J'] = em['j_family'].apply(lambda x : int(x.split('J')[1]))\n",
    "em = em.drop(columns = ['v_family','j_family']).rename(columns = {'V':'v_family', 'J':'j_family'})\n",
    "db = db[['cdr3_TRB', 'TRBV','TRBJ']]\n",
    "db['V'] = db['TRBV'].apply(lambda x: x.split('V')[1])\n",
    "db['V'] = db['V'].apply(lambda x : int(x.split('-')[0]) if '-' in x else int(x))\n",
    "db['J'] = db['TRBJ'].apply(lambda x: x.split('J')[1])\n",
    "db['J'] = db['J'].apply(lambda x : int(x.split('-')[0]) if '-' in x else int(x))\n",
    "db = db.drop(columns=['TRBV','TRBJ']).rename(columns = {'V':'v_family', 'J':'j_family'})\n",
    "em['db'] = 'emerson_b1'\n",
    "db['db'] = 'naive_db'\n",
    "db = db.rename(columns = {'cdr3_TRB':'amino_acid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automotive-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv('../training_data_new/mixed_vj_dataset/naive_vj_parsed.tsv',\n",
    "         sep = '\\t', header = True, index = True)\n",
    "em.to_csv('../training_data_new/mixed_vj_dataset/emerson_b1_vj_parsed.tsv',\n",
    "         sep = '\\t', header = True, index = True)\n",
    "total = pd.concat([db, em], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "north-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = total.sample(frac=.75)\n",
    "test = total.loc[total.index.difference(train.index)]\n",
    "train = train.sample(4000000)\n",
    "test = test.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "composed-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['v_family'] -= 1\n",
    "    df['j_family'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "personalized-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../training_data_new/mixed_vj_dataset/mixed_vj_train.csv', header=True,\n",
    "            index=True)\n",
    "test.to_csv('../training_data_new/mixed_vj_dataset/mixed_vj_test.csv', header=True,\n",
    "           index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-convergence",
   "metadata": {},
   "source": [
    "### Recleaning Emerson repertoires for DeepRC (13.04.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "creative-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amino_acid', 'frequency', 'rel_freq', 'v_family', 'v_gene', 'd_family',\n",
       "       'd_gene', 'j_family', 'j_gene', 'filename', 'pred_cmv', 'true_cmv',\n",
       "       'age', 'sex', 'race', 'hla_a1', 'hla_a2', 'hla_b1', 'hla_b2', 'len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../training_data_new/emerson_raw/batch1/emerson_batch1_train.tsv',\n",
    "                   sep = '\\t', nrows =3)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-canal",
   "metadata": {},
   "source": [
    "#### directly encode V/J genes and then save with a smaller subset of columns to reduce size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loaded-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in ['../training_data_new/emerson_raw/batch1/emerson_batch1_test.tsv']:\n",
    "    df = pd.read_csv(fn, sep = '\\t', usecols = ['amino_acid','frequency','v_family','j_family',\n",
    "                                               'filename', 'hla_a1','hla_a2','hla_b1','hla_b2'])\n",
    "    \n",
    "    df['V'] = df['v_family'].apply(lambda x : int(x.split('V')[1]))\n",
    "    df['J'] = df['j_family'].apply(lambda x : int(x.split('J')[1]))\n",
    "    df = df.drop(columns = ['v_family','j_family'])\\\n",
    "           .rename(columns = {'V':'v_family', 'J':'j_family'})\n",
    "    df['v_family'] -= 1\n",
    "    df['j_family'] -= 1\n",
    "    df = df[['filename','amino_acid','frequency','v_family','j_family',\n",
    "             'hla_a1','hla_a2','hla_b1','hla_b2']]\n",
    "    df.to_csv(fn, sep = '\\t', header=True, index=True)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lined-passage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>amino_acid</th>\n",
       "      <th>frequency</th>\n",
       "      <th>v_family</th>\n",
       "      <th>j_family</th>\n",
       "      <th>hla_a1</th>\n",
       "      <th>hla_a2</th>\n",
       "      <th>hla_b1</th>\n",
       "      <th>hla_b2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIP00734.tsv</td>\n",
       "      <td>CASSLQGATEAFF</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A02</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>B41</td>\n",
       "      <td>B44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIP00734.tsv</td>\n",
       "      <td>CASSNPGTGGGGYTF</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>A02</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>B41</td>\n",
       "      <td>B44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename       amino_acid  frequency  v_family  j_family hla_a1  \\\n",
       "0  HIP00734.tsv    CASSLQGATEAFF   0.014656         5         0    A02   \n",
       "1  HIP00734.tsv  CASSNPGTGGGGYTF   0.007007         5         0    A02   \n",
       "\n",
       "    hla_a2 hla_b1 hla_b2  \n",
       "0  Unknown    B41    B44  \n",
       "1  Unknown    B41    B44  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../training_data_new/emerson_raw/batch1/emerson_batch1_train.tsv', sep ='\\t', usecols =['filename', 'amino_acid','frequency','v_family','j_family',\n",
    "                                'hla_a1','hla_a2','hla_b1','hla_b2'], nrows = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stable-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../training_data_new/emerson_raw/batch1/emerson_batch1_test.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.split('.tsv')[0]+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in ['../training_data_new/emerson_raw/batch1/emerson_batch1_train.tsv',\n",
    "           '../training_data_new/emerson_raw/batch1/emerson_batch1_test.tsv']:\n",
    "    df = pd.read_csv(fn, sep ='\\t', usecols= ['filename', 'amino_acid','frequency','v_family','j_family',\n",
    "                                'hla_a1','hla_a2','hla_b1','hla_b2'])\n",
    "    fn = fn.split('.tsv')[0]+'.csv'\n",
    "    df.to_csv(fn, header = True, index = False)\n",
    "    del df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-sentence",
   "metadata": {},
   "source": [
    "### Checking dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "surprising-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime as dt \n",
    "\n",
    "class xd(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class from the Emerson study (batch1), should facilitate how I handle classes etc.\n",
    "    path should contain all the necessary data (top10k_train.csv, top10k_test.csv, sample_tags)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, max_len, istrain=True, top_k = 10000,\n",
    "                 allele = 'A', pos_class = 'A01'):\n",
    "        \n",
    "        if allele != 'A' and allele != 'B':\n",
    "            raise Exception('Allele must be \"A\" or \"B\"!')\n",
    "            \n",
    "        if istrain == True : \n",
    "            fn = 'emerson_batch1_train.csv'\n",
    "            which = 'train'\n",
    "        elif istrain == False : \n",
    "            fn = 'emerson_batch1_test.csv'\n",
    "            which = 'test'\n",
    "            \n",
    "        #Reading the sample tags with the associated split-df\n",
    "        tags = pd.read_csv('../training_data_new/emerson_raw/batch1/emerson_batch1_sampletags.tsv', \n",
    "                  sep = '\\t')\\\n",
    "                 .query('dataset == @which')\\\n",
    "                 .reset_index()\n",
    "\n",
    "        #Getting the one vs rest label (must be defined at initialization)\n",
    "        if allele == 'A' : columns = ['hla_a1', 'hla_a2']\n",
    "        elif allele == 'B' : columns = ['hla_b1', 'hla_b2'] \n",
    "        # 1 if either of hla_x1 or hla_x2 is of that label \n",
    "        tags['class_label'] = tags.apply(lambda x: 1 if (x[columns[0]] == pos_class or x[columns[1]] == pos_class) else 0, axis = 1)\n",
    "        \n",
    "        #Also this is the actual iterable (i.e. one sample = one patient)\n",
    "        #saving values\n",
    "        self.patients = tags.filename.values\n",
    "        self.labels = tags.class_label.values \n",
    "        self.len = len(tags)        \n",
    "        \n",
    "        #Reading the top_K most frequent (grouped by patient) values from DF \n",
    "        df = get_patient_topk_sequences(pd.read_csv(os.path.join(path, fn))\\\n",
    "                                          .query('amino_acid.str.len() <= @max_len'), \n",
    "                                        top_k)\n",
    "        \n",
    "        #Loading the values from DF and saving to attribute\n",
    "        self.seq_filename = df.filename.values \n",
    "        self.values = df[['amino_acid', 'v_family','j_family']].values\n",
    "        self.frequency = df.frequency.values\n",
    "        self.n_per_bag = np.array([len(df.query('filename == @x')) for x in tags.filename])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1 index = 1 patient\n",
    "        patient = self.patients[index]\n",
    "        target = self.labels[index]\n",
    "        n_per_bag = self.n_per_bag[index]\n",
    "        #print(patient, type(patient))\n",
    "        #Getting the sequences associated with the patients\n",
    "        if type(patient) == str:\n",
    "            indices = np.where(self.seq_filename == patient)\n",
    "        else:\n",
    "            indices = np.empty(0,dtype=np.int64)\n",
    "            for p in patient:\n",
    "                indices = np.append(indices, np.where(self.seq_filename == p))\n",
    "        values = self.values[indices] \n",
    "        \n",
    "        #An input to DeepRC should be ((x_tuple), n_per_bag) , where x_tuple is batch_aa_vj(values)\n",
    "        #But should probly do the encoding in DeepRC or in the network\n",
    "        return values, n_per_bag, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "native-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>top_k</th>\n",
       "      <th>time_minute</th>\n",
       "      <th>time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.408663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.911530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.032257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>10000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.483328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.423070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>15000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.144351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.396336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>20000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.154159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  top_k  time_minute  time_seconds\n",
       "0  False   5000          0.0      7.408663\n",
       "0   True   5000          1.0     44.911530\n",
       "0  False  10000          0.0      8.032257\n",
       "0   True  10000          2.0     22.483328\n",
       "0  False  15000          0.0      8.423070\n",
       "0   True  15000          3.0      7.144351\n",
       "0  False  20000          0.0      9.396336\n",
       "0   True  20000          4.0     16.154159"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time it takes to load a given dataset (with top_k sequences)\n",
    "df.sort_values('top_k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "million-ownership",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR TRAIN = False, TOP_K = 20000:\n",
      "\n",
      "Time elapsed reading tags : \n",
      "\t0.0 minutes\n",
      "\t0.01097 seconds\n",
      "\n",
      "Time elapsed getting/saving label : \n",
      "\t0.0 minutes\n",
      "\t0.002992 seconds\n",
      "\n",
      "Time elapsed getting Top K : \n",
      "\t0.0 minutes\n",
      "\t6.479115 seconds\n",
      "\n",
      "Time elapsed saving values (seq/V/J/freq/n_per_bag) : \n",
      "\t0.0 minutes\n",
      "\t2.826464 seconds\n",
      "\n",
      "Time elapsed for train == False, top_k = 20000\n",
      "\t0.0 minutes\n",
      "\t9.396336 seconds\n",
      "\n",
      "\t###############\n",
      "\n",
      "FOR TRAIN = True, TOP_K = 20000:\n",
      "\n",
      "Time elapsed reading tags : \n",
      "\t0.0 minutes\n",
      "\t0.007978 seconds\n",
      "\n",
      "Time elapsed getting/saving label : \n",
      "\t0.0 minutes\n",
      "\t0.012966 seconds\n",
      "\n",
      "Time elapsed getting Top K : \n",
      "\t1.0 minutes\n",
      "\t3.9994200000000006 seconds\n",
      "\n",
      "Time elapsed saving values (seq/V/J/freq/n_per_bag) : \n",
      "\t3.0 minutes\n",
      "\t11.190397999999988 seconds\n",
      "\n",
      "Time elapsed for train == True, top_k = 20000\n",
      "\t4.0 minutes\n",
      "\t16.154158999999993 seconds\n",
      "\n",
      "\t###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame(columns = ['train','top_k','time_minute','time_seconds'])\n",
    "for t in [False, True]:\n",
    "    for top_k in [5000, 10000, 15000]:\n",
    "        print(f'FOR TRAIN = {t}, TOP_K = {top_k}:')\n",
    "        start_time = dt.now()\n",
    "        dataset = EmersonRepertoire_Dataset(path = '../training_data_new/emerson_raw/batch1/',\n",
    "                                            max_len = 23, istrain=t,\n",
    "                                            top_k = top_k, allele = 'A', pos_class = 'A01')\n",
    "        del dataset\n",
    "        end_time = dt.now()       \n",
    "        elapsed = divmod((end_time-start_time).total_seconds(), 60)\n",
    "        print(f\"\\nTime elapsed for train == {t}, top_k = {top_k}\\n\\t{elapsed[0]} minutes\\n\\t{elapsed[1]} seconds\\n\\n\\t###############\\n\")\n",
    "        df = df.append(pd.DataFrame([[t, top_k, elapsed[0], elapsed[1]]], columns = df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-refund",
   "metadata": {},
   "source": [
    "### Split/Batching ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-coordination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Allows relative imports\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports from files\n",
    "from src.preprocessing import *\n",
    "from src.VAE_train import *\n",
    "from src.vautoencoders import *\n",
    "from src.loss_metrics import *\n",
    "from src.pickling import *\n",
    "from src.datasets import *\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#checking gpu status\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "#Plot and stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Ignore warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime as dt \n",
    "\n",
    "class xd(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class from the Emerson study (batch1), should facilitate how I handle classes etc.\n",
    "    path should contain all the necessary data (top10k_train.csv, top10k_test.csv, sample_tags)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, max_len, istrain=True, top_k = 10000,\n",
    "                 allele = 'A', pos_class = 'A01'):\n",
    "        \n",
    "        if allele != 'A' and allele != 'B':\n",
    "            raise Exception('Allele must be \"A\" or \"B\"!')\n",
    "            \n",
    "        if istrain == True : \n",
    "            fn = 'emerson_batch1_train.csv'\n",
    "            which = 'train'\n",
    "        elif istrain == False : \n",
    "            fn = 'emerson_batch1_test.csv'\n",
    "            which = 'test'\n",
    "            \n",
    "        #Reading the sample tags with the associated split-df\n",
    "        tags = pd.read_csv('../training_data_new/emerson_raw/batch1/emerson_batch1_sampletags.tsv', \n",
    "                  sep = '\\t')\\\n",
    "                 .query('dataset == @which')\\\n",
    "                 .reset_index()\n",
    "\n",
    "        #Getting the one vs rest label (must be defined at initialization)\n",
    "        if allele == 'A' : columns = ['hla_a1', 'hla_a2']\n",
    "        elif allele == 'B' : columns = ['hla_b1', 'hla_b2'] \n",
    "        # 1 if either of hla_x1 or hla_x2 is of that label \n",
    "        tags['class_label'] = tags.apply(lambda x: 1 if (x[columns[0]] == pos_class or x[columns[1]] == pos_class) else 0, axis = 1)\n",
    "        \n",
    "        #Also this is the actual iterable (i.e. one sample = one patient)\n",
    "        #saving values\n",
    "        self.patients = tags.filename.values\n",
    "        self.labels = tags.class_label.values \n",
    "        self.len = len(tags)        \n",
    "        \n",
    "        #Reading the top_K most frequent (grouped by patient) values from DF \n",
    "        df = get_patient_topk_sequences(pd.read_csv(os.path.join(path, fn))\\\n",
    "                                          .query('amino_acid.str.len() <= @max_len'), \n",
    "                                        top_k)\n",
    "        \n",
    "        #Loading the values from DF and saving to attribute\n",
    "        self.seq_filename = df.filename.values \n",
    "        self.values = df[['amino_acid', 'v_family','j_family']].values\n",
    "        self.frequency = df.frequency.values\n",
    "        self.n_per_bag = np.array([len(df.query('filename == @x')) for x in tags.filename])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1 index = 1 patient\n",
    "        patient = self.patients[index]\n",
    "        target = self.labels[index]\n",
    "        n_per_bag = self.n_per_bag[index]\n",
    "        #print(patient, type(patient))\n",
    "        #Getting the sequences associated with the patients\n",
    "        if type(patient) == str:\n",
    "            indices = np.where(self.seq_filename == patient)\n",
    "        else:\n",
    "            indices = np.empty(0,dtype=np.int64)\n",
    "            for p in patient:\n",
    "                indices = np.append(indices, np.where(self.seq_filename == p))\n",
    "        \n",
    "        values = self.values[indices] \n",
    "        #An input to DeepRC should be ((x_tuple), n_per_bag) , where x_tuple is batch_aa_vj(values)\n",
    "        #But should probly do the encoding in DeepRC or in the network\n",
    "        return values, n_per_bag, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "dataset = xd(path = '../training_data_new/emerson_raw/batch1/',\n",
    "                                    max_len = 23, istrain= False,\n",
    "                                    top_k = 1000, allele = 'A', pos_class = 'A01')\n",
    "len(dataset.frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "according-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = dataset[[0,5]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "productive-sequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.xd at 0x1d3aeb67940>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pressed-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(.7*len(dataset))\n",
    "val_len = len(dataset)-train_len\n",
    "train,val = random_split(dataset, [train_len, val_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "expanded-soldier",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 39,\n",
       " 40,\n",
       " 49,\n",
       " 32,\n",
       " 22,\n",
       " 60,\n",
       " 51,\n",
       " 59,\n",
       " 44,\n",
       " 21,\n",
       " 18,\n",
       " 35,\n",
       " 45,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 53,\n",
       " 43,\n",
       " 12,\n",
       " 15,\n",
       " 31,\n",
       " 10,\n",
       " 29,\n",
       " 42,\n",
       " 58,\n",
       " 19,\n",
       " 47,\n",
       " 17,\n",
       " 24,\n",
       " 38,\n",
       " 50,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 54,\n",
       " 34,\n",
       " 3,\n",
       " 57,\n",
       " 14,\n",
       " 36,\n",
       " 41]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "theoretical-contractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 12, 19, 36]\n",
      "[2, 7, 23, 28]\n",
      "[9, 10, 42, 35]\n",
      "[14, 18, 29, 24]\n",
      "[38, 0, 5, 16]\n",
      "[6, 3, 21, 1]\n",
      "[33, 20, 26, 4]\n",
      "[30, 34, 25, 27]\n",
      "[8, 31, 17, 13]\n",
      "[15, 37, 39, 11]\n",
      "[32, 41, 40]\n"
     ]
    }
   ],
   "source": [
    "for b in BatchSampler(RandomSampler(train), batch_size = 4, drop_last = False):\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incorporated-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 38]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "separate-benchmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,d,e = dataset[[b]]\n",
    "f,g,h = dataset[b]\n",
    "c==f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
