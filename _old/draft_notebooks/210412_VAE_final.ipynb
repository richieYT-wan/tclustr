{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artistic-police",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Allows relative imports\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports from files\n",
    "from src.preprocessing import *\n",
    "from src.VAE_train import *\n",
    "from src.vautoencoders import *\n",
    "from src.loss_metrics import *\n",
    "from src.pickling import *\n",
    "from src.datasets import *\n",
    "from vae_cel.vae_cel import * \n",
    "from src.preprocessing import * \n",
    "from vae_cel.vae_cel_train import test_model\n",
    "from vae_cel.vae_cel_loss import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#checking gpu status\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "#Plot and stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# Ignore warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divine-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../training_data_new/mixed_vj_dataset/mixed_vj_test.csv')\n",
    "test_dataset = test.query('amino_acid.str.len()<=23')[['amino_acid','v_family','j_family']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "fns = [os.path.join('../output/VAE_CEL_30epochs/',x) for x in os.listdir('../output/VAE_CEL_30epochs/') if ('BEST' in x and '91' in x)]\n",
    "VAE_VJ50 = VAE_cel(seq_len = 23, aa_dim = 25, latent_dim = 50,\n",
    "                   act = nn.SELU(), v_dim = 30, j_dim = 2)\n",
    "tmp = torch.load(fns[1])\n",
    "VAE_VJ50.load_state_dict(tmp['state_dict'])\n",
    "VAE_VJ50.to(device)\n",
    "\n",
    "VAE_VJ100 = VAE_cel(seq_len = 23, aa_dim = 25, latent_dim = 100,\n",
    "                   act = nn.SELU(), v_dim = 30, j_dim = 2)\n",
    "tmp = torch.load(fns[0])\n",
    "VAE_VJ100.load_state_dict(tmp['state_dict'])\n",
    "VAE_VJ100.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "marine-going",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test set:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test set:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hamming_seq_padded</th>\n",
       "      <th>hamming_sequence</th>\n",
       "      <th>accuracy_V</th>\n",
       "      <th>accuracy_J</th>\n",
       "      <th>Criterion_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.578157</td>\n",
       "      <td>6.883565</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>7.179024e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.744953e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hamming_seq_padded hamming_sequence accuracy_V accuracy_J  Criterion_loss\n",
       "mean           4.578157         6.883565   0.999742   0.999953    7.179024e-02\n",
       "var             0.00448         0.009329        0.0        0.0    6.744953e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hamming_seq_padded</th>\n",
       "      <th>hamming_sequence</th>\n",
       "      <th>accuracy_V</th>\n",
       "      <th>accuracy_J</th>\n",
       "      <th>Criterion_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.666265</td>\n",
       "      <td>3.944656</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>4.330573e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.445374e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hamming_seq_padded hamming_sequence accuracy_V accuracy_J  Criterion_loss\n",
       "mean           2.666265         3.944656   0.999879   0.999966    4.330573e-02\n",
       "var            0.004309         0.008556        0.0        0.0    9.445374e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = VAELoss_cel()\n",
    "VAE_VJ50.to(device)\n",
    "\n",
    "#\n",
    "df1 = test_model(VAE_VJ50, criterion, test_dataset, 2**13, 23, 0.5, 'before', True, False, 'cuda')\n",
    "df2 = test_model(VAE_VJ100, criterion, test_dataset, 2**13, 23, 0.5, 'before', True, False, 'cuda')\n",
    "print('VAE50')\n",
    "display(df1)\n",
    "print('VAE100')\n",
    "display(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-williams",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07fe504de394c859986f75435724ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_latent(df, cols):\n",
    "    #vars_= [z for z in df.columns if z.startswith('PCA')]\n",
    "    vars_ = cols\n",
    "    print(f'VAE latent space representation for {cols[0]}-{cols[-1]}')\n",
    "    g = sns.PairGrid(df, x_vars = vars_,\n",
    "                     y_vars = vars_,\n",
    "                     diag_sharey=False, hue=None)\n",
    "    g.fig.suptitle(f'VAE latent space representation for {cols[0]}-{cols[-1]}', fontweight='bold')\n",
    "    g.fig.subplots_adjust(top=0.92)\n",
    "    g.map_lower(sns.scatterplot,  alpha=0.75)\n",
    "    g.map_upper(sns.kdeplot)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.add_legend()\n",
    "    \n",
    "#sns.set_palette(\"husl\", n_colors=4)\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "#vae.to(device)\n",
    "chks = chunks(range(len(test_dataset)),2**15)\n",
    "df = pd.DataFrame(columns = (['sequence'] + ['z_'+str(x) for x in list(range(100))]))\n",
    "VAE_VJ100.eval()\n",
    "\n",
    "for b in tqdm(list(chks)): \n",
    "    with torch.no_grad():\n",
    "        onehot_tuple = batch_aa_vj(test_dataset[b], 23, 0.5, 'before', \n",
    "                                   True, False, 'cpu') \n",
    "        z = VAE_VJ100.embed(onehot_tuple)\n",
    "    df_s = pd.DataFrame(test_dataset[b], columns = ['sequence','v','j'])\n",
    "    df_z = pd.DataFrame(z, columns = ['z_'+str(x) for x in list(range(100))])\n",
    "    df = df.append(df_s.join(df_z), ignore_index=True)\n",
    "\n",
    "\n",
    "chks = list(chunks(df.columns[1:],3))\n",
    "for ch in tqdm(chks):\n",
    "    plot_latent(df.sample(frac=0.15), ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "activated-punishment",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CASSQGVTPTEYFVXXXXXXXXX', 6, 1),\n",
       " ('GAISQEWEGRGCCVXXXXXXXXX', 10, 1),\n",
       " ('CASTEWGEAHTQTFXXXXXXXXX', 18, 1),\n",
       " ('CASSPGYRNTQYFXXXXXXXXXX', 1, 0),\n",
       " ('CASSQDRQLQVFXXXXXXXXXXX', 5, 1),\n",
       " ('CASAQAPNQYFXXXXXXXXXXXX', 13, 1),\n",
       " ('CAITFKFGINGGDVVYFXXXXXX', 11, 1),\n",
       " ('CASSYGQPVRDQYFXXXXXXXXX', 6, 1),\n",
       " ('CASSLEGLEAGGYTCXXXXXXXX', 5, 0),\n",
       " ('CAGSTGAGGAEAFFXXXXXXXXX', 6, 0),\n",
       " ('CASTDGIAGDQAQHFXXXXXXXX', 5, 0),\n",
       " ('CAISGPIGINRGEQFFXXXXXXX', 9, 1),\n",
       " ('CASSLEPVTETEQFCXXXXXXXX', 6, 1),\n",
       " ('CASSQSGSSASKNNQYFXXXXXX', 4, 1),\n",
       " ('CASSLRSQEVFSXXXXXXXXXXX', 3, 1),\n",
       " ('CASSQNWVTYYQQFCXXXXXXXX', 3, 1),\n",
       " ('CAGFFGLRPYEQFVXXXXXXXXX', 26, 1),\n",
       " ('CATNGTKTDPYTFXXXXXXXXXX', 11, 0),\n",
       " ('CASSIAIRVAGGELFXXXXXXXX', 4, 1),\n",
       " ('CASTLSPQGLSEEQFVXXXXXXX', 10, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = VAE_VJ100.sample_latent(20)\n",
    "decoded, sequences, x_v, x_j = VAE_VJ100.reconstruct_latent(z)\n",
    "tuples = [(a,b,c) for a,b,c in zip(sequences, x_v, x_j)]\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "stuffed-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick DeepRC dimension check\n",
    "N_per_bag = [100, 99, 86, 102] #Fake repertoire with 100, 99, 86, 102 sequences\n",
    "z = VAE_VJ100.sample_latent(sum(N_per_bag)) # dimension (N_seq, 100)\n",
    "at = nn.Linear(100,1) # this is the final layer of the \"attention network\"\n",
    "attn = at(z) #dim (N, 1), one score per sequence\n",
    "\n",
    "start_i = 0\n",
    "results = []\n",
    "#then here, slice with the number of sequence per bag \n",
    "# in order to do the Softmax PER BAG!\n",
    "for seqs in N_per_bag:\n",
    "    #Slice & softmax\n",
    "    attn_slice = torch.softmax(attn[start_i:start_i+seqs], dim=0) \n",
    "    z_slice = z[start_i:start_i+seqs]\n",
    "    weighted_avg = (z_slice*attn_slice).sum(dim=0)\n",
    "    results.append(weighted_avg)\n",
    "    start_i += seqs\n",
    "\n",
    "results = torch.stack(results, dim=0)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-newsletter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
